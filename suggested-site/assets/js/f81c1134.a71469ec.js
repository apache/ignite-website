"use strict";(globalThis.webpackChunkdocusaurus=globalThis.webpackChunkdocusaurus||[]).push([[8130],{77735:e=>{e.exports=JSON.parse('{"archive":{"blogPosts":[{"id":"/2025/12/10/ignite3-client-connections","metadata":{"permalink":"/blog/2025/12/10/ignite3-client-connections","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-12-10-ignite3-client-connections.md","source":"@site/blog/2025-12-10-ignite3-client-connections.md","title":"How many client connections can Apache Ignite 3 handle?","description":"Apache Ignite 3 manages client connections so efficiently that the scaling limits common in database-style systems simply aren\'t a factor.","date":"2025-12-11T00:00:00.000Z","tags":[{"inline":true,"label":"performance","permalink":"/blog/tags/performance"},{"inline":true,"label":"technical","permalink":"/blog/tags/technical"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"ignite3","permalink":"/blog/tags/ignite-3"}],"readingTime":2.93,"hasTruncateMarker":true,"authors":[{"name":"Pavel Tupitsyn","title":"Apache Ignite Committer","url":"https://github.com/ptupitsyn","imageURL":"https://github.com/ptupitsyn.png","key":"pavel","page":null}],"frontMatter":{"title":"How many client connections can Apache Ignite 3 handle?","authors":["pavel"],"date":"2025-12-11T00:00:00.000Z","tags":["performance","technical","ignite","ignite3"]},"unlisted":false,"nextItem":{"title":"Schema Evolution Under Operational Pressure: When Downtime Isn\'t an Option","permalink":"/blog/2025/12/09/ignite3-architecture-p3"}},"content":"Apache Ignite 3 manages client connections so efficiently that the scaling limits common in database-style systems simply aren\'t a factor.\\n\\n\x3c!-- truncate --\x3e\\n\\n## The Question\\n\\nA common capacity planning question we get from users is: \\"How many client connections can one Ignite node maintain?\\"\\n\\nWith traditional relational databases, the common knowledge is:\\n\\n- Client connection is typically single-threaded and short-lived. \\"Open -> Do work -> Close\\" is the usual pattern.\\n- The server can handle a limited number of concurrent connections.\\n  - [Postgres defaults to 100](https://www.postgresql.org/docs/current/runtime-config-connection.html#GUC-MAX-CONNECTIONS) `max_connections`.\\n  - Each connection has significant memory overhead ([a few MBs](https://blog.anarazel.de/2020/10/07/measuring-the-memory-overhead-of-a-postgres-connection/)).\\n- An external connection pool (like [PgBouncer](https://www.pgbouncer.org/)) is recommended to improve scalability.\\n\\n[Apache Ignite 3](https://ignite.apache.org/) is quite different:\\n\\n- Client connections are long-lived, multiplexed, and thread-safe. Quite often, a single client connection is enough for the entire application lifetime.\\n- On the server side, each client connection has a small memory footprint (a few KB).\\n\\nThis approach with cheap long-lived connections provides low latency and great scalability for applications:\\n\\n- The connection is always open and responds to queries immediately.\\n- Multiple queries can be executed concurrently over the same connection (multiplexing).\\n- No need for an external connection pool.\\n- Query metadata is cached by the client connection, improving performance for repeated queries.\\n\\nLet\'s see how many concurrent client connections a single Apache Ignite 3 node can handle.\\n\\n---\\n\\n## Testing Setup\\n\\n### Server\\n\\nI\'m going to use the [binary distribution](https://ignite.apache.org/download.cgi) of Apache Ignite 3.1.0 for this test.\\n\\nThe default node configuration is good enough, the only thing I changed was the logging level in `etc/ignite.java.util.logging.properties` to reduce logging overhead.\\n\\n### Client\\n\\nTo establish the connections, I\'m using the [Ignite.NET client](https://www.nuget.org/packages/Apache.Ignite/3.1.0) in a simple console app that connects to the server in a loop and keeps the connections open. After the loop we verify that all connections are still alive.\\n\\nFull program is on GitHub: [https://gist.github.com/ptupitsyn/86056d4143811ba5dde6b2d1704fa948](https://gist.github.com/ptupitsyn/86056d4143811ba5dde6b2d1704fa948)\\n\\n### Ephemeral Port Exhaustion\\n\\nIn the program you can notice the trick with multiple localhost addresses (`127.0.0.1`, `127.0.0.2`, etc). Without it, after about 28k connections, the program fails with a `SocketException (99): Cannot assign requested address`.\\n\\nBasically, every TCP connection has a source `IP:port` pair and the port is chosen from the ephemeral port range (typically 32768\u201360999 on Linux). We can\'t have more connections on the same address than the number of ephemeral ports available. Using multiple localhost addresses works around this limitation.\\n\\n---\\n\\n## Results\\n\\nI\'m starting to get weird errors and timeouts at about 250k (yes, 250 thousand) connections with default settings. At **200k connections** the system is stable and responsive, so I decided to stop the test there.\\n\\nInitial memory usage of the Apache Ignite node was about 200 MB, and with 200k active connections it was about 900 MB after a full GC, about **3.5 KB per connection**.\\n\\nVisualVM screenshot:\\n\\n![VisualVM memory usage with 200k client connections](/img/blog/2025-12-04-How-Many-Client-Connections-Can-Ignite-Handle.png)\\n\\nClient log:\\n\\n```\\nConnected 200000 connections in 00:02:49.2601996\\nVerified connectivity in 00:00:09.1446883\\n```\\n\\nNote that each connection exchanges a heartbeat message every 10 seconds, so the system is not completely idle. We have about 20k small requests per second, but this barely requires any CPU.\\n\\n---\\n\\n## Summary\\n\\nApache Ignite client connections are very lightweight, so open as many as your application requires and keep them open for the best performance!"},{"id":"/2025/12/09/ignite3-architecture-p3","metadata":{"permalink":"/blog/2025/12/09/ignite3-architecture-p3","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-12-09-ignite3-architecture-p3.md","source":"@site/blog/2025-12-09-ignite3-architecture-p3.md","title":"Schema Evolution Under Operational Pressure: When Downtime Isn\'t an Option","description":"Schema changes in traditional databases mean downtime, lost revenue, and deployment chaos across multiple systems. This piece demonstrates how Apache Ignite\'s flexible schema approach helps lets data model evolve at the pace of your business requirements.","date":"2025-12-10T00:00:00.000Z","tags":[{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"},{"inline":true,"label":"technical","permalink":"/blog/tags/technical"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"ignite3","permalink":"/blog/tags/ignite-3"}],"readingTime":8.72,"hasTruncateMarker":true,"authors":[{"name":"Michael Aglietti","title":"Apache Ignite Contributor and DevRel","url":"https://github.com/maglietti","imageURL":"https://github.com/maglietti.png","key":"maglietti","page":null}],"frontMatter":{"title":"Schema Evolution Under Operational Pressure: When Downtime Isn\'t an Option","authors":["maglietti"],"date":"2025-12-10T00:00:00.000Z","tags":["architecture","technical","ignite","ignite3"]},"unlisted":false,"prevItem":{"title":"How many client connections can Apache Ignite 3 handle?","permalink":"/blog/2025/12/10/ignite3-client-connections"},"nextItem":{"title":"Memory-First Architecture: The Foundation for High-Velocity Event Processing","permalink":"/blog/2025/12/02/ignite3-architecture-p2"}},"content":"Schema changes in traditional databases mean downtime, lost revenue, and deployment chaos across multiple systems. This piece demonstrates how Apache Ignite\'s flexible schema approach helps lets data model evolve at the pace of your business requirements.\\n\\n\x3c!-- truncate --\x3e\\n\\nYour high-velocity application runs 24/7. Customer expectations don\'t pause for maintenance windows. Functional requirements evolve continuously. Yet traditional database schema changes require downtime, coordination across teams, and careful rollback planning.\\n\\nConsider a payment processing system handling peak loads of 50,000 transactions per second. A new compliance rule requires additional fraud-detection fields. Traditional schema changes would require:\\n\\n- **Coordinate downtime** across payment processing, fraud detection, and reporting systems\\n- **Apply schema changes** to primary database, read replicas, and cache layers\\n- **Deploy application updates** that work with new schema\\n- **Validate data consistency** across all systems\\n\\n**Total downtime**: 2-4 hours. **Lost revenue**: $500K+ for a payment processor.\\n\\nApache Ignite 3 eliminates this constraint through flexible schema evolution. Schema changes apply without downtime, applications adjust automatically, and system operations continue uninterrupted.\\n\\n**The result: operational evolution without operational interruption.**\\n\\n---\\n\\n_Part 3 of 8 in the Apache Ignite 3 Architecture Series_\\n\\n---\\n\\n## The Schema Rigidity Problem at Scale\\n\\n### Traditional Schema Change Overhead\\n\\nHigh-velocity applications face schema evolution challenges that compound with scale:\\n\\n**Multi-System Schema Coordination:**\\n\\n```mermaid\\nflowchart TB\\n    subgraph \\"Schema Change Impact\\"\\n        Downtime[Planned Downtime<br/>2-4 hours]\\n        Revenue[Lost Revenue<br/>$500K+ per hour]\\n        Risk[Deployment Risk<br/>Rollback complexity]\\n    end\\n\\n    subgraph \\"Systems Requiring Updates\\"\\n        Primary[(Primary Database<br/>Schema + Data Migration)]\\n        Replica[(Read Replicas<br/>Replication Catch-up)]\\n        Cache[(Cache Layer<br/>Schema Invalidation)]\\n        Analytics[(Analytics Store<br/>ETL Pipeline Updates)]\\n        Apps[Applications<br/>Code + Config Changes]\\n    end\\n\\n    Primary --\x3e Replica\\n    Replica --\x3e Cache\\n    Cache --\x3e Analytics\\n    Analytics --\x3e Apps\\n\\n    Apps --\x3e Downtime\\n    Downtime --\x3e Revenue\\n    Revenue --\x3e Risk\\n```\\n\\n**The Compound Effect:**\\n\\n- Each system adds coordination complexity\\n- Rollback procedures multiply with system count\\n- Testing requires full integration validation\\n- Deployment windows must accommodate slowest system\\n\\n### Real-World Schema Evolution Pressure\\n\\n**E-commerce Platform Evolution** (peak traffic: 100,000 orders per second):\\n\\n**Month 1**: Basic order processing\\n\\n```sql\\nCREATE TABLE orders (\\n    order_id BIGINT PRIMARY KEY,\\n    customer_id BIGINT,\\n    product_id BIGINT,\\n    amount DECIMAL(10,2),\\n    status VARCHAR(20)\\n);\\n```\\n\\n**Month 6**: Add payment processing compliance\\n\\n```sql\\n-- Traditional approach: downtime required\\nALTER TABLE orders ADD COLUMN payment_method VARCHAR(50);\\nALTER TABLE orders ADD COLUMN payment_processor VARCHAR(30);\\nALTER TABLE orders ADD COLUMN compliance_data VARCHAR(500);\\n-- Requires: 2-hour maintenance window\\n-- Impact: $200K lost sales during downtime\\n```\\n\\n**Month 12**: International expansion requirements\\n\\n```sql\\n-- More complexity: multiple system coordination\\nALTER TABLE orders ADD COLUMN currency_code CHAR(3);\\nALTER TABLE orders ADD COLUMN exchange_rate DECIMAL(10,6);\\nALTER TABLE orders ADD COLUMN tax_jurisdiction VARCHAR(50);\\nALTER TABLE orders ADD COLUMN shipping_region VARCHAR(50);\\n-- Requires: 4-hour coordinated deployment\\n-- Impact: $800K lost sales, customer complaints\\n```\\n\\n**The Pattern**: Each functional change requires operational disruption that grows with system complexity.\\n\\n---\\n\\n## Apache Ignite Flexible Schema Architecture\\n\\n### Catalog-Driven Schema Management\\n\\nApache Ignite manages schema evolution through versioned metadata catalogs that coordinate changes across distributed nodes using hybrid logical clocks for timestamp ordering:\\n\\n**Schema Evolution Process:**\\n\\n- **Validation Phase**: New columns validated against existing schema\\n- **Atomic Update**: Schema change applied as single `NewColumnsEntry` operation\\n- **Version Management**: Applications operate against appropriate schema version\\n- **Cluster Coordination**: HybridTimestamp ensures consistent activation\\n\\n**Key Advantages:**\\n\\n- **Atomic Updates**: Schema changes apply as single operations\\n- **Version Management**: Applications can operate against different schema versions\\n- **Validation**: Automatic conflict detection and resolution\\n- **Rollback**: Schema changes are reversible without data loss\\n\\n### Time-Based Schema Consistency\\n\\nSchema changes coordinate across distributed nodes using cluster-wide timestamps:\\n\\n**Consistency Guarantees:**\\n\\n- **Point-in-Time Activation**: All nodes apply schema changes simultaneously\\n- **Transaction Safety**: In-flight operations complete with original schema\\n- **Application Compatibility**: Gradual adoption without breaking changes\\n\\nThe catalog management system uses `HybridTimestamp` values to ensure schema versions activate consistently across all cluster nodes, preventing race conditions and maintaining data integrity during schema evolution.\\n\\n---\\n\\n## Schema Evolution in Production\\n\\n### Adding Fraud Detection Fields (Real-Time)\\n\\n**Business Requirement**: New fraud detection requires additional order data fields.\\n\\n**Traditional Approach**:\\n\\n```sql\\n-- Requires 2-hour maintenance window\\nBEGIN;\\n  ALTER TABLE orders ADD COLUMN fraud_score DECIMAL(5,2);\\n  ALTER TABLE orders ADD COLUMN risk_factors VARCHAR(500);\\n  ALTER TABLE orders ADD COLUMN verification_status VARCHAR(30);\\nCOMMIT;\\n-- Update application code (coordinated deployment)\\n-- Update cache schemas (cache invalidation)\\n-- Update analytics pipelines (ETL modifications)\\n-- Test end-to-end integration\\n```\\n\\n**Apache Ignite Approach**:\\n\\n```java\\n// Schema evolution during live operations\\ntry (IgniteClient client = IgniteClient.builder().addresses(\\"cluster:10800\\").build()) {\\n    // Add fraud detection columns without downtime\\n    client.sql().execute(null, \\"\\"\\"\\n        ALTER TABLE orders ADD COLUMN (\\n            fraud_score DECIMAL(5,2) DEFAULT 0.0,\\n            risk_factors VARCHAR(500) DEFAULT \'\',\\n            verification_status VARCHAR(30) DEFAULT \'PENDING\'\\n        )\\n    \\"\\"\\");\\n\\n    // Applications immediately see new schema\\n    // Existing queries continue working\\n    // New functionality can use additional fields\\n}\\n// Application code adapts automatically\\nclient.transactions().runInTransaction(tx -> {\\n    // Existing order processing continues\\n    client.sql().execute(tx, \\"INSERT INTO orders (order_id, customer_id, amount) VALUES (?, ?, ?)\\",\\n                        orderId, customerId, amount);\\n\\n    // New fraud detection can use additional fields when ready\\n    if (fraudDetectionEnabled) {\\n        client.sql().execute(tx, \\"UPDATE orders SET fraud_score = ?, risk_factors = ? WHERE order_id = ?\\",\\n                           fraudScore, riskFactors, orderId);\\n    }\\n});\\n```\\n\\n**Result**:\\n\\n- **Downtime**: Zero\\n- **Deployment coordination**: None required\\n- **Revenue impact**: Zero\\n- **Time to production**: Minutes instead of hours\\n\\n### Unified Schema Access Across APIs\\n\\n**Here\'s how the evolved schema works seamlessly across different access patterns:**\\n\\n```java\\n// The SAME evolved schema accessible through all APIs immediately\\nTable ordersTable = client.tables().table(\\"orders\\");\\n// 1. Key-value access automatically sees new schema\\nTuple orderTuple = ordersTable.keyValueView()\\n    .get(tx, Tuple.create().set(\\"order_id\\", orderId));\\n// New fields available: orderTuple.stringValue(\\"verification_status\\")\\n// 2. SQL access uses new fraud detection fields immediately\\nResultSet<SqlRow> suspiciousOrders = client.sql().execute(tx,\\n    \\"SELECT order_id, fraud_score, risk_factors \\" +\\n    \\"FROM orders WHERE fraud_score > 0.8 AND verification_status = \'REVIEW\'\\");\\n// 3. Record access handles new fields through schema evolution\\nOrderRecord record = ordersTable.recordView()\\n    .get(tx, new OrderRecord(orderId));\\n// OrderRecord.fraudScore now available without code changes\\n```\\n\\n**Schema Evolution Benefits:**\\n\\n- **No API fragmentation**: Same schema changes work across key-value, SQL, and record APIs\\n- **No deployment coordination**: All access patterns see schema changes immediately\\n- **No data migration**: New fields populate automatically with defaults\\n- **No downtime**: Live applications continue operating during schema evolution\\n\\n**The unified schema advantage**: Schema changes apply once and work immediately across all data access patterns, eliminating the multi-system coordination that creates downtime.\\n\\n### International Expansion Schema Evolution\\n\\n**Business Requirement**: Support multiple currencies and tax jurisdictions.\\n\\n```java\\n// Progressive schema evolution for international expansion\\npublic class InternationalExpansionEvolution {\\n\\n    public void addCurrencySupport(IgniteClient client) {\\n        // Phase 1: Add currency fields (no downtime)\\n        client.sql().execute(null, \\"\\"\\"\\n            ALTER TABLE orders ADD COLUMN (\\n                currency_code CHAR(3) DEFAULT \'USD\',\\n                exchange_rate DECIMAL(10,6) DEFAULT 1.0,\\n                base_amount DECIMAL(10,2)\\n            )\\n        \\"\\"\\");\\n\\n        // Applications continue working with existing USD logic\\n        // New international orders can specify currency\\n    }\\n\\n    public void addTaxSupport(IgniteClient client) {\\n        // Phase 2: Add tax jurisdiction fields (no downtime)\\n        client.sql().execute(null, \\"\\"\\"\\n            ALTER TABLE orders ADD COLUMN (\\n                tax_jurisdiction VARCHAR(50) DEFAULT \'US-FEDERAL\',\\n                tax_rate DECIMAL(5,4) DEFAULT 0.0875,\\n                tax_amount DECIMAL(10,2) DEFAULT 0.0\\n            )\\n        \\"\\"\\");\\n\\n        // Tax calculations adapt automatically\\n    }\\n\\n    public void addShippingSupport(IgniteClient client) {\\n        // Phase 3: Add regional shipping (no downtime)\\n        client.sql().execute(null, \\"\\"\\"\\n            ALTER TABLE orders ADD COLUMN (\\n                shipping_region VARCHAR(50) DEFAULT \'DOMESTIC\',\\n                customs_data VARCHAR(500),\\n                estimated_delivery_days INT DEFAULT 3\\n            )\\n        \\"\\"\\");\\n    }\\n}\\n```\\n\\n**Business Benefits:**\\n\\n- **Continuous Deployment**: Feature releases independent of schema changes\\n- **A/B Testing**: Test international features with subset of traffic\\n- **Risk Reduction**: Gradual rollout instead of big-bang deployment\\n- **Revenue Protection**: No downtime for existing operations\\n\\n---\\n\\n## Schema Evolution Performance Impact\\n\\n### Traditional Schema Change Performance Cost\\n\\n**Large Table Schema Changes** (100M+ records):\\n\\n```sql\\n-- Traditional ALTER TABLE on 100M records\\nALTER TABLE orders ADD COLUMN fraud_score DECIMAL(5,2);\\n-- Performance impact:\\n-- - Table lock: 30-60 minutes\\n-- - I/O overhead: Rewrite entire table\\n-- - Replication lag: Hours to catch up\\n-- - Application unavailability: Complete downtime\\n```\\n\\n**Cost Analysis:**\\n\\n- **Revenue loss**: $500K-$2M per hour of downtime\\n- **Customer impact**: Service unavailable during business hours\\n- **Engineering cost**: 20+ engineer hours for coordination\\n- **Risk**: Single point of failure for rollback\\n\\n### Apache Ignite Schema Evolution Performance\\n\\n**Zero-Downtime Schema Changes** (100M+ records):\\n\\nApache Ignite\'s catalog-based approach enables rapid schema changes by updating metadata rather than restructuring data:\\n\\n**Performance Characteristics:**\\n\\n- **Schema change time**: Fast metadata operations (typically under 100ms)\\n- **Application downtime**: Zero\\n- **Throughput impact**: Minimal during change operation\\n- **Recovery time**: Immediate (no recovery needed)\\n\\nPerformance improves by separating schema metadata management from data storage, allowing schema evolution without touching existing data structures.\\n\\n---\\n\\n## Business Impact of Schema Flexibility\\n\\n### Revenue Protection\\n\\n**E-commerce Platform Example** (processing $10M/month):\\n\\n**Traditional Approach:**\\n\\n- 4 schema changes per year \xd7 3 hours downtime = 12 hours total downtime\\n- Revenue impact: $10M/month \xf7 730 hours/month \xd7 12 hours = $164K lost annually\\n- Engineering overhead: 80 hours coordination \xd7 $150/hour = $12K annually\\n- **Total cost**: $176K annually\\n\\n**Apache Ignite Approach:**\\n\\n- 4 schema changes per year \xd7 0 hours downtime = 0 hours total downtime\\n- Revenue impact: $0 lost\\n- Engineering overhead: 4 hours \xd7 $150/hour = $600 annually\\n- **Total cost**: $600 annually\\n\\n**Annual savings**: $175K+ (99.7% reduction)\\n\\n### Development Velocity Impact\\n\\n**Feature Development Acceleration:**\\n\\n```java\\n// Traditional: Schema change blocks feature development\\npublic class TraditionalFeatureDevelopment {\\n    // Week 1-2: Plan schema changes across systems\\n    // Week 3-4: Coordinate deployment windows\\n    // Week 5: Execute schema changes during downtime\\n    // Week 6-8: Deploy application changes\\n    // Week 9: Validate integration across systems\\n\\n    // Total: 9 weeks from idea to production\\n}\\n// Apache Ignite: Schema and features evolve together\\npublic class FlexibleFeatureDevelopment {\\n    public void developFeatureWithSchemaEvolution() {\\n        // Day 1: Add required schema fields\\n        client.sql().execute(null, \\"ALTER TABLE customers ADD COLUMN loyalty_tier VARCHAR(20) DEFAULT \'STANDARD\'\\");\\n\\n        // Day 1-3: Implement feature logic\\n        // Day 4: Deploy to production (no coordination needed)\\n        // Day 5: Monitor and iterate\\n\\n        // Total: 1 week from idea to production\\n    }\\n}\\n```\\n\\n**Impact**: 9x faster feature delivery through schema flexibility.\\n\\n### Competitive Advantage Through Agility\\n\\n**Market Response Speed:**\\n\\n- **Regulatory compliance**: Adapt to new requirements within hours\\n- **Customer feedback**: Implement requested features without deployment delays\\n- **Competitive pressure**: Launch counter-features without schema coordination overhead\\n\\n**Innovation Capability:**\\n\\n- **A/B testing**: Try schema variations without impacting production\\n- **Experimentation**: Add telemetry fields for new insights\\n- **Personalization**: Evolve customer data models based on behavior patterns\\n\\n---\\n\\n## The Operational Evolution Advantage\\n\\nTraditional databases force trade-offs between schema stability and operational agility. Apache Ignite eliminates this trade-off through flexible schema evolution that supports both operational stability and rapid functional expansion.\\n\\n**The principle**: Your schema should evolve as fast as your business requirements.\\n\\nWhen market demands shift daily but schema changes occur only during monthly maintenance windows, the architecture becomes the bottleneck to feature delivery. Flexible schema evolution ensures the data model advances with business needs rather than restricting them.\\n\\nFast-paced applications can\'t afford architectural constraints that slow adaptation. Schema flexibility becomes a strategic advantage when your system must evolve faster than competitors can deploy.\\n\\n---\\n\\n_Next: Part 4 explores how integrated platform performance maintains consistency across all workload types. This ensures that schema flexibility and business agility don\'t compromise the performance characteristics your application requires._"},{"id":"/2025/12/02/ignite3-architecture-p2","metadata":{"permalink":"/blog/2025/12/02/ignite3-architecture-p2","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-12-02-ignite3-architecture-p2.md","source":"@site/blog/2025-12-02-ignite3-architecture-p2.md","title":"Memory-First Architecture: The Foundation for High-Velocity Event Processing","description":"Traditional databases force a choice: fast memory access or durable storage. High-velocity applications processing 10,000+ events per second hit a wall when disk I/O adds 5-15ms to every transaction.","date":"2025-12-03T00:00:00.000Z","tags":[{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"},{"inline":true,"label":"technical","permalink":"/blog/tags/technical"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"ignite3","permalink":"/blog/tags/ignite-3"}],"readingTime":6.65,"hasTruncateMarker":true,"authors":[{"name":"Michael Aglietti","title":"Apache Ignite Contributor and DevRel","url":"https://github.com/maglietti","imageURL":"https://github.com/maglietti.png","key":"maglietti","page":null}],"frontMatter":{"title":"Memory-First Architecture: The Foundation for High-Velocity Event Processing","authors":["maglietti"],"date":"2025-12-03T00:00:00.000Z","tags":["architecture","technical","ignite","ignite3"]},"unlisted":false,"prevItem":{"title":"Schema Evolution Under Operational Pressure: When Downtime Isn\'t an Option","permalink":"/blog/2025/12/09/ignite3-architecture-p3"},"nextItem":{"title":"When Multi-System Complexity Compounds at Scale","permalink":"/blog/2025/11/25/ignite3-architecture-p1"}},"content":"Traditional databases force a choice: fast memory access or durable storage. High-velocity applications processing 10,000+ events per second hit a wall when disk I/O adds 5-15ms to every transaction.\\n\\n\x3c!-- truncate --\x3e\\n\\n**Apache Ignite eliminates this trade-off with memory-first architecture that delivers microsecond response times while maintaining full durability.**\\n\\nEvent data lives in memory for immediate access. Persistence happens asynchronously in the background. By moving operations into memory, typical 7\u201325 ms disk operations drop into the sub-millisecond range while retaining ACID guarantees.\\n\\n**Performance transformation: significant speed improvements with enterprise durability.**\\n\\n---\\n\\n_Part 2 of 8 in the Apache Ignite 3 Architecture Series_\\n\\n---\\n\\n## The Event Processing Performance Challenge\\n\\n**Traditional Database Performance Under Load**\\n\\nWhen applications process high event volumes, disk-based databases create predictable performance degradation:\\n\\n**Single Event Processing (Traditional Database):**\\n\\n```java\\n// Event processing with traditional disk-based database\\nlong startTime = System.nanoTime();\\n// 1. Check event cache (memory hit ~50\u03bcs, miss ~2ms disk fetch)\\nEventData event = cache.get(eventId);\\nif (event == null) {\\n    event = database.query(\\"SELECT * FROM events WHERE id = ?\\", eventId);  // Disk I/O: 2-10ms\\n    cache.put(eventId, event, 300);  // Cache update: ~100\u03bcs\\n}\\n// 2. Transaction processing (requires disk durability)\\ndatabase.executeTransaction(tx -> {  // WAL write + fsync: 5-15ms\\n    tx.execute(\\"INSERT INTO event_log VALUES (?, ?)\\", eventId, timestamp);\\n    tx.execute(\\"UPDATE event_counters SET count = count + 1\\");\\n});\\nlong totalTime = System.nanoTime() - startTime;\\n// Result: 7-25ms per event (dominated by disk I/O)\\n```\\n\\n**Compound Effect at Scale:**\\n\\n**Mathematical impossibility at scale:**\\n\\n- 1,000 events/sec \xd7 15ms avg = 15 seconds processing time needed per second\\n- 5,000 events/sec \xd7 15ms avg = 75 seconds processing time needed per second\\n- 10,000 events/sec \xd7 15ms avg = 150 seconds processing time needed per second\\n\\n**The constraint**: Disk I/O creates a performance ceiling on throughput regardless of CPU or memory.\\n\\n---\\n\\n## Memory-First Performance Results\\n\\n**Concrete performance improvement with Apache Ignite memory-first architecture:**\\n\\n```java\\n// Event processing with memory-first architecture\\nlong startTime = System.nanoTime();\\n// All operations happen in memory with microsecond access times\\ntry (IgniteClient client = IgniteClient.builder().addresses(\\"cluster:10800\\").build()) {\\n    client.transactions().runInTransaction(tx -> {\\n        // 1. Event data access (memory-based operations)\\n        EventData event = eventsTable.get(tx, eventId);\\n        // 2. Transaction processing (memory-based with async durability)\\n        client.sql().execute(tx, \\"INSERT INTO event_log VALUES (?, ?)\\", eventId, timestamp);\\n        client.sql().execute(tx, \\"UPDATE event_counters SET count = count + 1\\");\\n        // Transaction commits immediately to memory\\n        // Disk persistence happens asynchronously in background\\n    });\\n}\\nlong totalTime = System.nanoTime() - startTime;\\n// Result: ~200-500 microseconds per event (20x+ faster than disk-based)\\n```\\n\\n**Real-world performance characteristics:**\\n\\n- **10,000 events/sec processing**: 0.5 seconds total vs 150 seconds with disk I/O\\n- **Peak throughput**: 50,000+ events per sec achievable vs 1,000 events per sec disk limit\\n- **Consistent performance**: Sub-millisecond response times even during traffic spikes\\n- **Resource utilization**: Memory bandwidth becomes the scaling factor, not disk I/O waits\\n\\n---\\n\\n## Architecture Comparison: Disk-First vs Memory-First\\n\\n```mermaid\\nflowchart LR\\n    subgraph \\"Disk-First Architecture\\"\\n        App1[Application]\\n        Cache1[Memory Cache<br/>Limited Size]\\n        DB1[(Disk Database<br/>Primary Storage)]\\n        App1 --\x3e|1 - Check Cache| Cache1\\n        Cache1 --\x3e|2 - Cache Miss<br/>2-10ms| DB1\\n        DB1 --\x3e|3 - Disk Read<br/>5-15ms| Cache1\\n        Cache1 --\x3e|4 - Return Data| App1\\n        App1 --\x3e|5 - Write Operation| DB1\\n        DB1 --\x3e|6 - WAL + fsync<br/>5-15ms| Storage1[Disk Storage]\\n        DB1 --\x3e|7 - Invalidate| Cache1\\n    end\\n```\\n\\n```mermaid\\nflowchart LR\\n    subgraph \\"Memory-First Architecture\\"\\n        App2[Application]\\n        Memory2[Memory Storage<br/>Primary Tier]\\n        Async2[Async Persistence<br/>Background Process]\\n        App2 --\x3e|1 - All Operations<br/>Memory Speed| Memory2\\n        Memory2 --\x3e|2 - Immediate Response<br/>sub-1ms| App2\\n        Memory2 -.->|3 - Background<br/>Async Write| Async2\\n        Async2 -.->|4 - Durability<br/>No Blocking| Storage2[Disk Storage]\\n    end\\n```\\n\\n**The Fundamental Difference:**\\n\\n- **Traditional**: Memory serves disk (cache-aside pattern with cache misses)\\n- **Memory-First**: Disk serves memory (async persistence without blocking)\\n- **Performance Impact**: 5-15ms disk waits become sub-millisecond memory operations\\n- **Scalability**: Memory bandwidth scales linearly vs disk I/O bottlenecks\\n\\n---\\n\\n## Memory-First Architecture Principles\\n\\n### Off-Heap Memory Management\\n\\nApache Ignite manages memory regions directly outside the JVM heap to eliminate garbage collection interference.\\n\\n**Performance Benefits:**\\n\\n- **Predictable Access Times**: No Java GC pauses during event processing bursts\\n- **Large Memory Utilization**: Event data can consume large amounts of RAM without heap issues\\n- **Direct Memory Operations**: Reduced serialization/deserialization overhead\\n\\n### Dual Engine Strategy for Event Requirements\\n\\nApache Ignite provides two storage engines optimized for different performance requirements:\\n\\n#### Memory-Only Storage (aimem)\\n\\n- **Purpose**: Session data, real-time analytics, temporary processing results\\n- **Performance**: Memory-speed operations without disk I/O overhead\\n- **Trade-off**: Maximum speed in exchange for volatility\\n\\n#### Memory-First Persistence (aipersist)\\n\\n- **Purpose**: Financial transactions, audit logs, business-critical events\\n- **Performance**: Memory-speed access with asynchronous persistence\\n- **Trade-off**: Near-memory speed with full durability protection\\n\\n**The Evolution Solution**: Instead of choosing between fast caches and durable databases, you get both performance characteristics in the same platform based on your specific data requirements.\\n\\n---\\n\\n## Event Processing Performance Characteristics\\n\\n### Memory-First Operations\\n\\nEvent processing benefits from memory-first operations that reduce traditional I/O bottlenecks:\\n\\n**Architecture Benefits**:\\n\\n- Events stored in off-heap memory regions for fast access\\n- Multi-version storage enables concurrent read/write operations\\n- Asynchronous checkpointing maintains durability without blocking processing\\n- B+ tree structures optimize both sequential and random access patterns\\n\\n**Performance Advantage**: Event data processing operates on memory-resident data with minimal serialization overhead.\\n\\n### Asynchronous Persistence for Event Durability\\n\\nThe checkpoint manager ensures event durability without blocking event processing.\\n\\n#### Background Checkpoint Process\\n\\n- **Collection Phase**: Identify modified pages during low-activity periods\\n- **Write Phase**: Persist changes to storage without blocking ongoing operations\\n- **Coordination**: Manage recovery markers for failure scenarios\\n\\n**Key Advantage**: Event processing continues at memory speeds while persistence happens in background threads.\\n\\n---\\n\\n## B+ Tree Organization for Event Data\\n\\nEvent-Optimized Data Structures\\n\\nApache Ignite organizes event data through specialized B+ tree variations optimized for time-series and event-driven access patterns:\\n\\n**Event Processing Optimizations**:\\n\\n- Time-based ordering for streaming access patterns\\n- Range scan optimization for time window queries\\n- Cache-friendly layout for sequential event processing\\n- Multi-version support for consistent read operations\\n\\n### MVCC Integration for Event Consistency\\n\\nEvent processing maintains consistency through multi-version concurrency control:\\n\\n**Event Processing Benefits**:\\n\\n- **Consistent Analytics**: Read events at specific points in time without blocking new events\\n- **High-Frequency Writes**: Events process concurrently with analytical queries\\n- **Recovery Guarantees**: Event ordering maintained across failures\\n\\n---\\n\\n## Performance Characteristics at Event Scale\\n\\n### Memory-First Performance Profile\\n\\n**Event Processing Characteristics**:\\n\\n- **Write Operations**: Events commit to memory efficiently\\n- **Read Operations**: Event queries complete quickly from memory\\n- **Range Scans**: Time-window analytics benefit from memory-resident data\\n- **Concurrent Processing**: Memory-first design supports mixed read/write loads\\n\\n**Scaling Characteristics**:\\n\\n- **Linear Memory Scaling**: Performance grows with available memory\\n- **CPU Utilization**: Event processing can saturate multiple cores\\n- **Network Optimization**: Collocated processing eliminates network bottlenecks\\n\\n### Real-World Event Processing Examples\\n\\n**Real-World Performance Impact:**\\n\\n**Financial Trading Platforms**: High-frequency trades process at memory speeds instead of waiting for disk writes. Portfolio updates, risk calculations, and compliance checks happen concurrently without I/O bottlenecks.\\n\\n**IoT Event Processing**: Sensor data ingestion scales to device-native rates without sampling or queuing delays. Anomaly detection runs on live data streams rather than batch-processed snapshots.\\n\\n**Gaming Backends**: Player actions process immediately while leaderboards, achievements, and session state update concurrently. No delays between action and world state changes.\\n\\n---\\n\\n## Foundation for High-Velocity Applications\\n\\nMemory-first architecture creates the performance foundation that makes high-velocity event processing practical:\\n\\n**Eliminates Traditional Bottlenecks**:\\n\\n- Disk I/O wait times removed from event processing path\\n- Garbage collection interference eliminated through off-heap design\\n- Network serialization overhead reduced through efficient memory management\\n\\n**Enables New Application Patterns**:\\n\\n- Real-time analytics on live transactional event streams\\n- Sub-millisecond response capabilities for high-frequency processing\\n- IoT processing at sensor data rates without data sampling\\n\\n**Maintains Enterprise Requirements**:\\n\\n- ACID transaction guarantees for critical events\\n- Durability through asynchronous checkpointing\\n- Recovery capabilities for event stream continuity\\n\\nThe memory-first foundation transforms what\'s possible for high-velocity applications. Instead of architecting around disk I/O constraints, you can design for the performance characteristics your business requirements actually need.\\n\\n---\\n\\n_Next: Part 3 explores how flexible schema management lets systems evolve without downtime or complex coordination, and why these capabilities are essential for high-velocity applications that cannot afford processing interruptions._"},{"id":"/2025/11/25/ignite3-architecture-p1","metadata":{"permalink":"/blog/2025/11/25/ignite3-architecture-p1","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-11-25-ignite3-architecture-p1.md","source":"@site/blog/2025-11-25-ignite3-architecture-p1.md","title":"When Multi-System Complexity Compounds at Scale","description":"Your high-velocity application began with smart architectural choices: PostgreSQL for reliable transactions, Redis for fast cache access, and custom processing for domain-specific logic. These decisions powered early success and growth.","date":"2025-11-26T00:00:00.000Z","tags":[{"inline":true,"label":"architecture","permalink":"/blog/tags/architecture"},{"inline":true,"label":"technical","permalink":"/blog/tags/technical"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"ignite3","permalink":"/blog/tags/ignite-3"}],"readingTime":7.45,"hasTruncateMarker":true,"authors":[{"name":"Michael Aglietti","title":"Apache Ignite Contributor and DevRel","url":"https://github.com/maglietti","imageURL":"https://github.com/maglietti.png","key":"maglietti","page":null}],"frontMatter":{"title":"When Multi-System Complexity Compounds at Scale","authors":["maglietti"],"date":"2025-11-26T00:00:00.000Z","tags":["architecture","technical","ignite","ignite3"]},"unlisted":false,"prevItem":{"title":"Memory-First Architecture: The Foundation for High-Velocity Event Processing","permalink":"/blog/2025/12/02/ignite3-architecture-p2"},"nextItem":{"title":"Schema Design for Distributed Systems: Why Data Placement Matters","permalink":"/blog/2025/11/18/schema-design-for-distributed-systems-ai3"}},"content":"Your high-velocity application began with smart architectural choices: PostgreSQL for reliable transactions, Redis for fast cache access, and custom processing for domain-specific logic. These decisions powered early success and growth.\\n\\n\x3c!-- truncate --\x3e\\n\\nBut success changes the game. Your system now handles thousands of events per second, and customers expect microsecond-level response times. The same architectural choices that enabled growth now create performance bottlenecks that compound with every additional event.\\n\\n**At high event volumes, data movement between systems becomes the primary performance constraint.**\\n\\n_Part 1 of 8 in the Apache Ignite 3 Architecture Series_\\n\\n---\\n\\n## The Scale Reality for High-Velocity Applications\\n\\nAs event volume grows, architectural compromises that once seemed reasonable at lower scale become critical bottlenecks. Consider a financial trading platform, gaming backend, or IoT processor handling tens of thousands of operations per second.\\n\\n### Event Processing Under Pressure\\n\\n**High-frequency event characteristics**\\n\\n- Events arrive faster than traditional batch processing can handle  \\n- Each event requires immediate consistency checks against live data  \\n- Results must update multiple downstream systems simultaneously  \\n- Network delays compound into user-visible lag  \\n- **Traffic spikes create systemic pressure** \u2014 traditional stacks drop connections or crash when overwhelmed  \\n\\n**The compounding effect**\\n\\n- At 100 events per second, network latency of 2ms adds minimal overhead. \\n- At 10,000 events per second, that same 2ms latency creates a 20-second processing backlog within system boundaries. \\n- During traffic spikes (50,000+ events/second), traditional systems collapse entirely, dropping connections and losing data when they\'re needed most. \\n\\nThe math scales against you.\\n\\n---\\n\\n### When Smart Choices Become Scaling Limits\\n\\n**Initial Architecture, works great at lower scale:**\\n\\n```mermaid\\nflowchart TB\\n    subgraph \\"Event Processing\\"\\n        Events[High-Volume Events<br/>10,000/sec]\\n    end\\n    \\n    subgraph \\"Multi-System Architecture\\"\\n        Redis[(Cache<br/>Session Data<br/>2ms latency)]\\n        PostgreSQL[(Relational DB<br/>Transaction Data<br/>5ms latency)]\\n        Processing[Custom Processing<br/>Business Logic<br/>3ms latency]\\n    end\\n    \\n    Events --\x3e Redis\\n    Events --\x3e PostgreSQL\\n    Events --\x3e Processing\\n    \\n    Redis <--\x3e|Sync Overhead| PostgreSQL\\n    PostgreSQL <--\x3e|Data Movement| Processing\\n    Processing <--\x3e|Cache Updates| Redis\\n```\\n\\n**What happens at scale**\\n\\n- **Network Latency Tax**: Every system hop adds milliseconds that compound\\n- **Synchronization Delays**: Keeping systems consistent creates processing queues\\n- **Memory Overhead**: Each system caches the same data in different formats\\n- **Consistency Windows**: Brief periods where systems show different data states \\n\\n---\\n\\n### The Hidden Cost of Multi-System Success\\n\\n**Data Movement Overhead:**\\n\\nYour events don\'t just need processing, they need processing that maintains consistency across all systems. \\n\\nEach event triggers:\\n\\n1. **Cache lookup** (cache): \u2248 0.5 ms network + processing\\n2. **Transaction validation** (relational db): \u2248 2 ms network + disk I/O  \\n3. **Business-logic execution** (custom logic): \u2248 1ms processing + data marshalling \\n4. **Result synchronization** (across systems): \u2248 3 ms coordination overhead\\n\\n**Minimum per-event cost \u2248 7 ms before business logic.** \\n\\nAt 10,000 events/s, you\u2019d need 70 seconds of processing capacity just *for data movement* per real-time second!\\n\\n---\\n\\n## The Performance Gap That Grows With Success\\n\\n### Why Traditional Options Fail\\n\\n**Option 1: Scale Out Each System**\\n\\n- **Strategy**: Add cache clusters, database replicas, processing nodes\\n- **Result**: More systems to coordinate, exponentially more complexity\\n- **Reality**: Network overhead grows faster than processing capacity\\n\\n**Option 2: Custom Optimization**  \\n\\n- **Strategy**: Build application-layer caching, custom consistency protocols\\n- **Result**: Engineering team maintains complex, system-specific optimizations\\n- **Reality**: Solutions don\'t generalize; each optimization creates technical debt\\n\\n**Option 3: Accept Performance Compromises**\\n\\n- **Strategy**: Use async processing, eventual consistency,  and accept delayed insights\\n- **Result**: Business requirements compromised to fit architectural limitations\\n- **Reality**: Competitive disadvantage as customer expectations grow\\n\\n---\\n\\n### The Critical Performance Gap\\n\\n| Component | Optimized for | Typical Latency |\\n|------------|---------------|----------------|\\n| Database | ACID transactions | Milliseconds |\\n| Cache | Access speed | Microseconds |\\n| Compute | Throughput | Minutes \u2013 hours |\\n\\nApplications needing *microsecond insights* on *millisecond transactions* have no good options at scale in traditional architectures.\\n\\nDuring traffic spikes, traditional architectures either drop connections (data loss) or degrade performance (missed SLAs). High-velocity applications need intelligent flow control that guarantees stability under pressure while preserving data integrity.\\n\\n---\\n\\n## Event Processing at Scale\\n\\n**Here\'s what traditional multi-system event processing costs:**\\n\\n```java\\n// Traditional multi-system event processing\\nlong startTime = System.nanoTime();\\n\\n// 1. Cache lookup for session data\\nString sessionData = redisClient.get(\\"session:\\" + eventId);  // ~500\u03bcs network\\nif (sessionData == null) {\\n    sessionData = postgresDB.query(\\"SELECT * FROM sessions WHERE id = ?\\", eventId);  // ~2ms fallback\\n    redisClient.setex(\\"session:\\" + eventId, 300, sessionData);  // ~300\u03bcs cache update\\n}\\n\\n// 2. Transaction processing\\npostgresDB.executeTransaction(tx -> {  // ~2-5ms transaction\\n    tx.execute(\\"INSERT INTO events VALUES (?, ?, ?)\\", eventId, userId, eventData);\\n    tx.execute(\\"UPDATE user_stats SET event_count = event_count + 1 WHERE user_id = ?\\", userId);\\n});\\n\\n// 3. Custom processing with consistency coordination\\nProcessingResult result = customProcessor.process(eventData, sessionData);  // ~1ms processing\\nredisClient.setex(\\"result:\\" + eventId, 600, result);  // ~300\u03bcs result caching\\n\\n// 4. Synchronization across systems\\nensureConsistency(eventId, sessionData, result);  // ~2-3ms coordination\\n\\nlong totalTime = System.nanoTime() - startTime;\\n// Total: 6-12ms per event (not including queuing delays)\\n```\\n\\n**Compound Effect at Scale:**\\n\\n| Rate            | Required processing time/s |\\n| --------------- | -------------------------- |\\n| 1,000 events/s  | 6\u201312 seconds               |\\n| 5,000 events/s  | 30\u201360 seconds              |\\n| 10,000 events/s | 60\u2013120 seconds             |\\n\\n**The math doesn\u2019t work:** parallelism helps, but coordination overhead grows exponentially with system count.\\n\\n---\\n\\n### Real-World Breaking Points\\n\\n- **Financial Services**: Trading platforms hitting 10,000+ trades/second discover that compliance reporting delays impact trading decisions.\\n\\n- **Gaming Platforms**: Multiplayer backends processing user actions find that leaderboard updates lag behind gameplay events.\\n\\n- **IoT Analytics**: Manufacturing systems processing sensor data realize that anomaly detection arrives too late for preventive action.\\n\\n---\\n\\n## The Apache Ignite Alternative\\n\\n### Eliminating Multi-System Overhead\\n\\n```mermaid\\nflowchart TB\\n    subgraph \\"Event Processing\\"\\n        Events[High-Volume Events<br/>10,000/sec]\\n    end\\n    \\n    subgraph \\"Apache Ignite Platform\\"\\n        subgraph \\"Collocated Processing\\"\\n            Memory[Memory-First Storage<br/>Optimized Access Times]\\n            Transactions[MVCC Transactions<br/>ACID Guarantees]\\n            Compute[Event Processing<br/>Where Data Lives]\\n        end\\n    end\\n    \\n    Events --\x3e Memory\\n    Memory --\x3e Transactions\\n    Transactions --\x3e Compute\\n    \\n    Memory <--\x3e|Minimal Copying| Transactions\\n    Transactions <--\x3e|Collocated| Compute\\n    Compute <--\x3e|Direct Access| Memory\\n```\\n\\n**Key difference:** events process *where the data lives*, eliminating inter-system network latency.\\n\\n---\\n\\n### Apache Ignite 3 Performance Reality Check\\n\\n**Here\'s the same event processing with integrated architecture:**\\n\\n```java\\n// Apache Ignite 3 integrated event processing\\ntry (IgniteClient client = IgniteClient.builder().addresses(\\"cluster:10800\\").build()) {\\n    // Single integrated transaction spanning cache, database, and compute\\n    client.transactions().runInTransaction(tx -> {\\n        // 1. Access session data (in memory, no network overhead)\\n        Session session = client.tables().table(\\"sessions\\")\\n            .keyValueView().get(tx, Tuple.create().set(\\"id\\", eventId));\\n        \\n        // 2. Process event with ACID guarantees (same memory space)\\n        client.sql().execute(tx, \\"INSERT INTO events VALUES (?, ?, ?)\\", \\n                           eventId, userId, eventData);\\n        \\n        // 3. Execute processing collocated with data\\n        ProcessingResult result = client.compute().execute(\\n            JobTarget.colocated(\\"events\\", Tuple.create().set(\\"id\\", eventId)), \\n            EventProcessor.class, eventData);\\n        \\n        // 4. Update derived data (same transaction, guaranteed consistency)\\n        client.sql().execute(tx, \\"UPDATE user_stats SET event_count = event_count + 1 WHERE user_id = ?\\", userId);\\n        \\n        return result;\\n    });\\n}\\n// Result: microsecond-range event processing through integrated architecture\\n```\\n\\n**Result**: Processing 10,000 events/s is achievable with integrated architecture eliminating network overhead.\\n\\n---\\n\\n### The Unified Data-Access Advantage\\n\\n**Here\'s what eliminates the need for separate systems:**\\n\\n```java\\n// The SAME data, THREE access paradigms, ONE system\\nTable customerTable = client.tables().table(\\"customers\\");\\n\\n// 1. Key-value access for cache-like performance\\nCustomer customer = customerTable.keyValueView()\\n    .get(tx, Tuple.create().set(\\"customer_id\\", customerId));\\n\\n// 2. SQL access for complex analytics\\nResultSet<SqlRow> analytics = client.sql().execute(tx, \\n    \\"SELECT segment, AVG(order_value) FROM customers WHERE region = ?\\", region);\\n\\n// 3. Record access for type-safe operations\\nCustomerRecord record = customerTable.recordView()\\n    .get(tx, new CustomerRecord(customerId));\\n\\n// All three: same schema, same data, same transaction model\\n```\\n\\n**Eliminates:**\\n\\n- **Cache API** for cache operations\\n- Data movement during **distributed joins** for analytical queries  \\n- **Custom mapping logic** for type-safe access\\n- **Data synchronization** between cache and database\\n- **Schema drift risks** across different systems \\n\\n**Unified advantage:** one schema, one transaction model, multiple access paths.\\n\\n---\\n\\n## Apache Ignite Architecture Preview\\n\\nThe ability to handle high-velocity events without multi-system overhead requires specific technical innovations:\\n\\n- **Memory-First Storage**: Event data lives in memory with optimized access times typically under 10 microseconds for cache-resident data\\n- **Collocated Compute**: Processing happens where data already exists, eliminating movement\\n- **Integrated Transactions**: ACID guarantees span cache, database, and compute operations  \\n- **Minimal Data Copying**: Events process against live data through collocated processing and direct memory access\\n\\nThese innovations address the compound effects that make multi-system architectures unsuitable for high-velocity applications.\\n\\n---\\n\\n## Business Impact of Architectural Evolution\\n\\n### Cost Efficiency\\n\\n- **Reduced infrastructure:** one platform instead of several  \\n- **Lower network costs:** eliminate inter-system bandwidth overhead  \\n- **Simplified operations:** fewer platforms to monitor, backup, and scale  \\n\\n### Performance Gains\\n\\n- **Millisecond latency:** eliminates network overhead  \\n- **Higher throughput:** more events on existing hardware  \\n- **Predictable scaling:** consistent performance under load  \\n\\n### Developer Experience\\n\\n- **Single API:** one model for all data operations  \\n- **Consistent behavior:** no synchronization anomalies  \\n- **Faster delivery:** one integrated system to test and debug  \\n\\n---\\n\\n## The Architectural Evolution Decision\\n\\nEvery successful application reaches this point: the architecture that once fueled growth now constrains it.  \\n\\n**The question isn\'t whether you\'ll hit multi-system scaling limits. It\'s how you\'ll evolve past them.**\\n\\n**Apache Ignite** consolidates transactions, caching, and compute into a single, memory-first platform designed for high-velocity workloads. Instead of managing the compound complexity of coordinating multiple systems at scale, you consolidate core operations into a platform designed for high-velocity applications.\\n\\nYour winning architecture doesn\'t have to become your scaling limit. It can evolve into the foundation for your next phase of growth.\\n\\n---\\n\\n_Next: Part 2 explores how Apache Ignite\u2019s memory-first architecture enables optimized event processing without compromising durability. This foundation makes true high-velocity performance possible._"},{"id":"/2025/11/18/schema-design-for-distributed-systems-ai3","metadata":{"permalink":"/blog/2025/11/18/schema-design-for-distributed-systems-ai3","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-11-18-schema-design-for-distributed-systems-ai3.md","source":"@site/blog/2025-11-18-schema-design-for-distributed-systems-ai3.md","title":"Schema Design for Distributed Systems: Why Data Placement Matters","description":"You can scale out your database, add more nodes, and tune every index, but if your data isn\u2019t in the right place, performance still hits a wall. Every distributed system eventually runs into this: joins that cross the network, caches that can\u2019t keep up, and queries that feel slower the larger your cluster gets.","date":"2025-11-19T00:00:00.000Z","tags":[{"inline":true,"label":"technical","permalink":"/blog/tags/technical"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"ignite3","permalink":"/blog/tags/ignite-3"}],"readingTime":7.94,"hasTruncateMarker":true,"authors":[{"name":"Michael Aglietti","title":"Apache Ignite Contributor and DevRel","url":"https://github.com/maglietti","imageURL":"https://github.com/maglietti.png","key":"maglietti","page":null}],"frontMatter":{"title":"Schema Design for Distributed Systems: Why Data Placement Matters","authors":["maglietti"],"date":"2025-11-19T00:00:00.000Z","tags":["technical","ignite","ignite3"]},"unlisted":false,"prevItem":{"title":"When Multi-System Complexity Compounds at Scale","permalink":"/blog/2025/11/25/ignite3-architecture-p1"},"nextItem":{"title":"Getting to Know Apache Ignite 3","permalink":"/blog/2025/11/11/getting-to-know-ignite3"}},"content":"You can scale out your database, add more nodes, and tune every index, but if your data isn\u2019t in the right place, performance still hits a wall. Every distributed system eventually runs into this: joins that cross the network, caches that can\u2019t keep up, and queries that feel slower the larger your cluster gets.\\n\\n\x3c!-- truncate --\x3e\\n\\nMost distributed SQL databases claim to solve scalability. They partition data evenly, replicate it across nodes, and promise linear performance. But *how* data is distributed and *which* records end up together matters more than most people realize. If related data lands on different nodes, every query has to travel the network to fetch it, and each millisecond adds up.\\n\\nThat\u2019s where **data placement** becomes the real scaling strategy.  \\n\\nApache Ignite 3 takes a different path with **schema-driven colocation** \u2014 a way to keep related data physically together. Instead of spreading rows randomly across nodes, Ignite uses your schema relationships to decide where data lives. The result: a 200 ms cross-node query becomes a 5 ms local read.\\n\\n---\\n\\n## How Ignite 3 Differs from Other Distributed Databases\\n\\n**Traditional Distributed SQL Databases:**\\n\\n- Hash-based partitioning ignores data relationships  \\n- Related data scattered across nodes by default  \\n- Cross-node joins create network bottlenecks  \\n- Millisecond latencies due to disk-first architecture  \\n\\n**Ignite 3 Schema-Driven Approach:**\\n\\n- Colocation configuration in schema definitions  \\n- Related data automatically placed together  \\n- Local queries eliminate network overhead  \\n- Microsecond latencies through memory-first storage  \\n\\n---\\n\\n## The Distributed Data Placement Problem\\n\\nYou\u2019ve tuned indexes, optimized queries, and scaled your cluster\u2014but latency still creeps in.  \\nThe problem isn\u2019t your SQL -- it\u2019s where your data lives.  \\n\\nTraditional hash-based partitioning distributes records randomly across nodes based on primary key values.  \\nWhile this ensures even data distribution, it scatters related records that applications frequently access together.  \\nIt\u2019s a clever approach\u2014until you need to join data that doesn\u2019t share the same key.  \\nThen every query turns into a distributed operation, and your network becomes the bottleneck.\\n\\nIgnite 3 provides automatic colocation based on schema relationships.  \\nYou define relationships directly in your schema, and Ignite automatically places related data on the same nodes using the specified colocation keys.\\n\\nUsing a [music catalog example](https://github.com/lerocha/chinook-database/tree/master),  \\nwe\u2019ll demonstrate how schema-driven data placement reduces query latency from 200 ms to 5 ms.\\n\\n> This post assumes you have a basic understanding of how to get an Ignite 3 cluster running and have worked with the Ignite 3 Java API.  \\n> If you\'re new to Ignite 3, start with the [Java API quick start guide](/docs/ignite3/3.1.0/getting-started/key-value-api) to set up your development environment.\\n\\n---\\n\\n## How Ignite 3 Places Data Differently\\n\\nTables are distributed across multiple nodes using consistent hashing, but with a key difference:  \\nyour schema definitions control data placement.  \\nInstead of accepting random distribution of related records, you declare relationships in your schema and let Ignite handle placement automatically.\\n\\n**Partitioning Fundamentals:**\\n\\n- Each table is divided into partitions (typically 64\u20131024 per table)  \\n- Primary key hash determines which partition data goes into  \\n- Partitions are distributed evenly across available nodes  \\n- Each partition has configurable replicas for fault tolerance  \\n\\n**Data Placement Concepts:**\\n\\n- **Affinity** \u2013 the algorithm that determines which nodes store which partitions  \\n- **Colocation** \u2013 ensuring related data from different tables gets placed on the same nodes  \\n\\nThe diagram below shows how colocation works in practice.  \\nArtist and Album tables use different primary keys, but colocation strategy ensures albums are partitioned by `ArtistId` rather than `AlbumId`:\\n\\n```mermaid\\ngraph TB\\n    subgraph \\"3-Node Cluster\\"\\n        N1[\\"Node 1 Partitions: 0,3,6,9\\"]\\n        N2[\\"Node 2 Partitions: 1,4,7,10\\"] \\n        N3[\\"Node 3 Partitions: 2,5,8,11\\"]\\n    end\\n    \\n    subgraph \\"Album Table - colocateBy ArtistId\\"\\n        B1[\\"AlbumId=101, ArtistId=1 hash(1)\u2192P1 Node 2\\"]\\n        B2[\\"AlbumId=102, ArtistId=1 hash(1)\u2192P1 Node 2\\"]\\n        B3[\\"AlbumId=201, ArtistId=22 hash(22)\u2192P11 Node 3\\"]\\n        B4[\\"AlbumId=301, ArtistId=42 hash(42)\u2192P6 Node 1\\"]\\n    end\\n    \\n    subgraph \\"Artist Table\\"\\n        A1[\\"ArtistId=1 hash\u2192P1 Node 2\\"]\\n        A2[\\"ArtistId=22 hash\u2192P11 Node 3\\"] \\n        A3[\\"ArtistId=42 hash\u2192P6 Node 1\\"]\\n    end\\n    \\n    A1 -.->|\\"Same partition\\"| B1 -.-> N2\\n    A1 -.->|\\"Same partition\\"| B2 -.-> N2 \\n    A2 -.->|\\"Same partition\\"| B3 -.-> N3\\n    A3 -.->|\\"Same partition\\"| B4 -.-> N1\\n```\\n\\nColocation configuration in your schema ensures that Album records use the `ArtistId` value (not `AlbumId`) for partition assignment.  \\nThis guarantees that Artist 1 and all albums with `ArtistId = 1` hash to the same partition and therefore live on the same nodes.\\n\\n---\\n\\n## Distribution Zones and Data Placement\\n\\nDistribution zones are cluster-level configurations that define how data is distributed and replicated.\\n\\n> **Zone Creation Options:** Ignite 3 supports multiple approaches:  \\n> 1. **SQL DDL** \u2013 `CREATE ZONE` statements  \\n> 2. **Java Builder API** \u2013 programmatic `ZoneDefinition.builder()`  \\n>  \\n> We use the Java Builder API here for consistency with our programmatic schema examples.\\n\\nA distribution zone specifies:\\n\\n- **Partition count** \u2013 how many partitions your data is divided into (typically 64\u20131024 per table)  \\n- **Replica count** \u2013 how many copies of each partition exist for fault tolerance  \\n- **Node filters** \u2013 which nodes can store data for this zone  \\n\\nFirst, create the distribution zones:\\n\\n```java\\n// Create the standard zone for frequently updated data\\nignite.catalog().create(ZoneDefinition.builder(\\"MusicStore\\")\\n    .replicas(2)\\n    .storageProfiles(\\"default\\")\\n    .build()).execute();\\n\\n// Create the replicated zone for reference data (replicas = cluster size)\\nignite.catalog().create(ZoneDefinition.builder(\\"MusicStoreReplicated\\")\\n    .replicas(clusterNodes().size()) \\n    .storageProfiles(\\"default\\")\\n    .build()).execute();\\n```\\n\\n---\\n\\n## Building Your Music Platform Schema\\n\\n> **Schema Creation:** Ignite 3 supports three approaches:  \\n> 1. **SQL DDL** \u2013 traditional `CREATE TABLE` statements  \\n> 2. **Java Annotations API** \u2013 POJO markup with `@Table`, `@Column`, etc.  \\n> 3. **Java Builder API** \u2013 programmatic `TableDefinition.builder()`  \\n>  \\n> We use the Annotations API here for its clarity and type safety.\\n\\nThe Artist table establishes the partitioning strategy that dependent tables will follow through colocation:\\n\\n```java\\n@Table(zone = @Zone(value = \\"MusicStore\\", storageProfiles = \\"default\\"))\\npublic class Artist {\\n    @Id\\n    @Column(value = \\"ArtistId\\", nullable = false)\\n    private Integer ArtistId;\\n    \\n    @Column(value = \\"Name\\", nullable = false, length = 120)\\n    private String Name;\\n    \\n    public Artist() {}\\n    \\n    public Artist(Integer artistId, String name) {\\n        this.ArtistId = artistId;\\n        this.Name = name;\\n    }\\n    \\n    public Integer getArtistId() { return ArtistId; }\\n    public void setArtistId(Integer artistId) { this.ArtistId = artistId; }\\n    public String getName() { return Name; }\\n    public void setName(String name) { this.Name = name; }\\n}\\n```\\n\\n---\\n\\n## Parent\u2013Child Colocation Implementation\\n\\nWhen users search for \\"The Beatles\\", they expect both artist details and album listings in the same query.  \\nWithout colocation, this requires cross-node joins that can take 40\u2013200 ms.\\n\\nWe solve this by setting `colocateBy` in the `@Table` annotation:\\n\\n```java\\n@Table(\\n    zone = @Zone(value = \\"MusicStore\\", storageProfiles = \\"default\\"),\\n    colocateBy = @ColumnRef(\\"ArtistId\\")\\n)\\npublic class Album {\\n    @Id\\n    @Column(value = \\"AlbumId\\", nullable = false)\\n    private Integer AlbumId;\\n    \\n    @Id\\n    @Column(value = \\"ArtistId\\", nullable = false)\\n    private Integer ArtistId;\\n    \\n    @Column(value = \\"Title\\", nullable = false, length = 160)\\n    private String Title;\\n    \\n    @Column(value = \\"ReleaseDate\\", nullable = true)\\n    private LocalDate ReleaseDate;\\n    \\n    // Constructors and getters/setters...\\n}\\n```\\n\\nThe colocation field (`ArtistId`) must be part of the composite primary key.  \\nIgnite uses the `ArtistId` value to ensure albums with the same artist live on the same nodes as their corresponding artist record.\\n\\n---\\n\\n## Performance Impact: Memory-First + Colocation\\n\\nLet\u2019s quantify the effect of combining memory-first storage with schema-driven colocation.\\n\\n**Without Colocation \u2013 Data Scattered:**\\n\\n```java\\nArtist artist = artistView.get(null, artistKey);              // Node 2\\nCollection<Album> albums = albumView.getAll(null, albumKeys); // Nodes 1,2,3\\n// Result: 3 network operations for related data\\n// Query time: 40\u2013200 ms (network latency \xd7 nodes involved)\\n```\\n\\n**With Memory-First + Colocation \u2013 Data Local:**\\n\\n```java\\nArtist artist = artistView.get(null, artistKey);              // Node 2\\nCollection<Album> albums = albumView.getAll(null, albumKeys); // Node 2\\n// Result: 1 node involved, local memory access\\n// Query time: 1\u20135 ms (memory access + no network hops)\\n```\\n\\nThe performance difference combines **memory-first storage** with **schema-driven colocation**:\\n\\n- **Query latency reduction:** 200 ms \u2192 5 ms (memory access + no network hops)  \\n- **Network traffic elimination:** related data queries become local operations  \\n- **Resource efficiency:** CPU focuses on serving requests instead of moving data  \\n\\n---\\n\\n## Colocation Enables Compute-to-Data Processing\\n\\nSchema-driven colocation doesn\u2019t just optimize queries\u2014it enables processing where data lives:\\n\\n```java\\n// Process all albums for an artist locally\\nComputeJob<RecommendationResult> job = ComputeJob.colocated(\\"Artist\\", artistId,\\n    AlbumRecommendationJob.class);\\n    \\n// Runs on the same node where artist and album data live\\nCompletableFuture<RecommendationResult> result = ignite.compute()\\n    .submitAsync(job, preferences);\\n```\\n\\nInstead of moving gigabytes of album data to a compute cluster, you move kilobytes of logic to where the data already resides.\\n\\n---\\n\\n## Implementation Guide\\n\\nDeploy tables in dependency order to avoid colocation reference errors:\\n\\n```java\\ntry (IgniteClient client = IgniteClient.builder()\\n        .addresses(\\"127.0.0.1:10800\\")\\n        .build()) {\\n    \\n    // 1. Reference tables with no dependencies\\n    client.catalog().createTable(Genre.class);\\n    \\n    // 2. Root entities\\n    client.catalog().createTable(Artist.class);\\n    \\n    // 3. Dependent entities in hierarchy order\\n    client.catalog().createTable(Album.class);      // References Artist\\n    client.catalog().createTable(Track.class);      // References Album\\n}\\n```\\n\\n---\\n\\n## Accessing Your Distributed Data\\n\\nIgnite 3 provides multiple views of the same colocated data:\\n\\n```java\\n// RecordView for entity operations\\nRecordView<Artist> artists = client.tables()\\n    .table(\\"Artist\\")\\n    .recordView(Artist.class);\\n\\n// Operations with partition keys route to single nodes\\nArtist beatles = new Artist(1, \\"The Beatles\\");\\nartists.upsert(null, beatles);\\n\\nAlbum abbeyRoad = new Album(1, 1, \\"Abbey Road\\", LocalDate.of(1969, 9, 26));\\nalbums.upsert(null, abbeyRoad);  // Automatically colocated with artist\\n```\\n\\n---\\n\\n## Summary\\n\\nData placement is where distributed performance is won or lost.  \\nWith **schema-driven colocation**, Apache Ignite 3 keeps related data together on the same nodes, so your queries stay local, fast, and predictable.\\n\\nInstead of tuning around network latency, you design for it once at the schema level.  \\nYour joins stay local, your compute jobs run where the data lives, and scaling stops being a tradeoff between performance and size.\\n\\n**Why it works:**  \\n- **Memory-first + colocation** \u2192 microsecond access to related data  \\n- **Schema-driven placement** \u2192 predictable performance at scale  \\n- **Compute-to-data** \u2192 logic runs with data, not across the network  \\n- **Unified platform** \u2192 transactions, analytics, and compute together  \\n\\nWhen data lives together, your system scales naturally \u2014 without complexity creeping in.\\n\\nExplore the [Ignite 3 documentation](/docs/) for detailed examples and API references."},{"id":"/2025/11/11/getting-to-know-ignite3","metadata":{"permalink":"/blog/2025/11/11/getting-to-know-ignite3","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-11-11-getting-to-know-ignite3.md","source":"@site/blog/2025-11-11-getting-to-know-ignite3.md","title":"Getting to Know Apache Ignite 3","description":"Apache Ignite 3 is a memory-first distributed SQL database platform that consolidates transactions, analytics, and compute workloads previously requiring separate systems. Built from the ground up over four years of development, it represents a complete departure from traditional caching solutions toward a unified distributed computing platform with microsecond latencies and collocated processing capabilities.","date":"2025-11-12T00:00:00.000Z","tags":[{"inline":true,"label":"technical","permalink":"/blog/tags/technical"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"ignite3","permalink":"/blog/tags/ignite-3"},{"inline":true,"label":"featured","permalink":"/blog/tags/featured"}],"readingTime":7.08,"hasTruncateMarker":true,"authors":[{"name":"Michael Aglietti","title":"Apache Ignite Contributor and DevRel","url":"https://github.com/maglietti","imageURL":"https://github.com/maglietti.png","key":"maglietti","page":null}],"frontMatter":{"title":"Getting to Know Apache Ignite 3","authors":["maglietti"],"date":"2025-11-12T00:00:00.000Z","tags":["technical","ignite","ignite3","featured"]},"unlisted":false,"prevItem":{"title":"Schema Design for Distributed Systems: Why Data Placement Matters","permalink":"/blog/2025/11/18/schema-design-for-distributed-systems-ai3"},"nextItem":{"title":"Apache Ignite 3.1: Performance, Multi-Language Client Support, and Production Hardening","permalink":"/blog/2025/11/03/apache-ignite-3-1"}},"content":"Apache Ignite 3 is a memory-first distributed SQL database platform that consolidates transactions, analytics, and compute workloads previously requiring separate systems. Built from the ground up over four years of development, it represents a complete departure from traditional caching solutions toward a unified distributed computing platform with microsecond latencies and collocated processing capabilities.\\n\\n\x3c!-- truncate --\x3e\\n\\n**Forget everything you knew about Apache Ignite.** Version 3.0 is a complete architectural rewrite that transforms Ignite from a caching platform into a memory-first distributed computing platform with microsecond latencies and collocated processing.\\n\\n## Architectural Foundation: Schema-Driven Design\\n\\nThe core architectural shift in Ignite 3 is that your schema becomes the foundation for data placement, query optimization, and compute job scheduling. Instead of managing separate systems with different data models, you define your schema once and it drives everything.\\n\\n```java\\n// Unified platform connection\\nIgniteClient ignite = IgniteClient.builder()\\n    .addresses(\\"node1:10800\\", \\"node2:10800\\", \\"node3:10800\\")\\n    .build();\\n```\\n\\nSchema definitions use Java annotations to specify colocation strategies, storage profiles, and indexing:\\n\\n> **Schema Creation**: Ignite 3 supports three approaches for schema creation:\\n> \\n> 1. **SQL DDL** - Traditional `CREATE TABLE` statements\\n> 2. **Java Annotations API** - POJO markup with `@Table`, `@Column`, etc.\\n> 3. **Java Builder API** - Programmatic `TableDefinition.builder()` approach\\n>\\n> We use the Java Annotations API in this blog for their compile-time type safety and clear colocation syntax.\\n\\n```java\\n@Table(zone = @Zone(value = \\"MusicStore\\", storageProfiles = \\"default\\"))\\npublic class Artist {\\n    @Id\\n    private Integer ArtistId;\\n\\n    @Column(value = \\"Name\\", length = 120, nullable = false)\\n    private String Name;\\n\\n    // Constructors, getters, setters...\\n}\\n\\n@Table(\\n    zone = @Zone(value = \\"MusicStore\\", storageProfiles = \\"default\\"),\\n    colocateBy = @ColumnRef(\\"ArtistId\\"),\\n    indexes = @Index(value = \\"IFK_AlbumArtistId\\", columns = { \\n        @ColumnRef(\\"ArtistId\\") })\\n)\\npublic class Album {\\n    @Id\\n    private Integer AlbumId;\\n\\n    @Id\\n    private Integer ArtistId;\\n\\n    @Column(value = \\"Title\\", length = 160, nullable = false)\\n    private String Title;\\n\\n    // Constructors, getters, setters...\\n}\\n```\\n\\nThe `colocateBy` annotation ensures that albums are stored on the same nodes as their corresponding artists, eliminating distributed join overhead and enabling local processing.\\n\\n## Multiple APIs, Single Schema\\n\\nIgnite 3 provides different API views into the same schema, eliminating impedance mismatch between operational and analytical workloads:\\n\\n```java\\n// RecordView for structured operations\\nRecordView<Artist> artists = ignite.tables()\\n    .table(\\"Artist\\")\\n    .recordView(Artist.class);\\n\\n// KeyValueView for high-performance access patterns\\nKeyValueView<Long, Album> albums = ignite.tables()\\n    .table(\\"Album\\")\\n    .keyValueView(Long.class, Album.class);\\n\\n// SQL for analytics using Apache Calcite engine\\nSqlStatement analytics = ignite.sql()\\n    .statementBuilder()\\n    .query(\\"SELECT a.Name, COUNT(al.AlbumId) as AlbumCount \\" +\\n            \\"FROM Artist a JOIN Album al ON a.ArtistId = al.ArtistId \\" +\\n            \\"GROUP BY a.Name\\");\\n\\n// Collocated compute jobs\\nComputeJob<String> job = ComputeJob.colocated(\\"Artist\\", 42,\\n    RecommendationJob.class);\\nJobExecution<String> recommendation = ignite.compute()\\n    .submit(ignite.clusterNodes(), job, \\"rock\\");\\n```\\n\\nThis approach eliminates the typical data serialization and movement overhead between different systems while maintaining type safety and schema evolution capabilities.\\n\\n> This represents a fundamental architectural shift from Ignite 2.x, which treated everything as key-value operations in a cache. Ignite 3 puts an evolvable schema first and uses memory-centric storage to deliver microsecond latencies for all operations, not just cache hits.\\n\\n## Memory-First Storage Architecture\\n\\nUnlike disk-first distributed databases, Ignite 3 uses a memory-first storage model with configurable persistence options:\\n\\n- **`aimem`**: Pure in-memory storage for maximum performance\\n- **`aipersist`**: Memory-first with persistence for durability\\n- **`RocksDB`**: Disk-based storage for write-heavy workloads\\n\\nThe memory-first approach delivers microsecond response times for hot data while providing flexible cost-performance trade-offs through configurable memory-to-disk ratios.\\n\\n### Storage Engine Characteristics\\n\\n|Engine|Primary Use Case|Latency Profile|Durability|\\n|---|---|---|---|\\n|aimem|Ultra-low latency|Microseconds|Volatile|\\n|aipersist|Balanced performance|Microseconds (memory)|Persistent|\\n|RocksDB|Write-heavy workloads|Variable|Persistent|\\n\\n## Consistency and Concurrency Model\\n\\nIgnite 3 implements Raft consensus for strong consistency and MVCC (Multi-Version Concurrency Control) for transaction isolation:\\n\\n- **Raft consensus**: Ensures data consistency across replicas without split-brain scenarios\\n- **MVCC transactions**: Provides snapshot isolation and deadlock-free concurrency\\n- **ACID compliance**: Full transactional guarantees across distributed operations\\n\\nThis consistency model applies uniformly across all APIs, whether you\'re using RecordView operations, SQL queries, or compute jobs.\\n\\n## Collocated Processing: Compute-to-Data Architecture\\n\\nOne of Ignite 3\'s key architectural advantages is collocated processing, which brings computation to where data is stored rather than moving data to compute resources:\\n\\n```java\\n// Traditional approach: data movement overhead\\n// 1. Query data from database\\n// 2. Move data to compute cluster  \\n// 3. Process data remotely\\n// 4. Return results\\n\\n// Ignite 3 approach: compute colocation\\nComputeJob<Result> job = ComputeJob.colocated(\\"Customer\\", customerId,\\n    RiskAnalysisJob.class);\\nCompletableFuture<Result> result = ignite.compute()\\n    .submitAsync(job, parameters);\\n```\\n\\nThis compute-to-data pattern eliminates network serialization overhead and enables processing of large datasets without data movement. Instead of moving terabytes of data to processing nodes, you move kilobytes of code to where the data lives.\\n\\n## System Consolidation Benefits\\n\\nTraditional distributed architectures typically require separate systems for different workloads:\\n\\n**Traditional Multi-System Architecture:**\\n\\n- Transactional database (PostgreSQL, MySQL) - millisecond latencies\\n- Analytics database (ClickHouse, Snowflake) - batch processing\\n- Caching layer (Redis, Hazelcast) - separate consistency model\\n- Compute cluster (Spark, Flink) - data movement overhead\\n- Message queue (Kafka, RabbitMQ) - separate operational model\\n- Stream processing (Kafka Streams, Pulsar) - additional complexity\\n\\n**Ignite 3 Unified Platform:**\\n\\n- Schema-driven storage with multiple storage engines - microsecond latencies\\n- SQL analytics through Apache Calcite - real-time processing\\n- Collocated compute processing - zero data movement\\n- Built-in streaming with flow control - integrated backpressure\\n- ACID transactions across all operations - single consistency model\\n- One operational model and consistency guarantee\\n\\n### Operational Advantages\\n\\n1. **Unified Schema Evolution**: Schema changes propagate automatically across all access patterns\\n2. **Single Consistency Model**: ACID guarantees across transactions, analytics, and compute\\n3. **Reduced Operational Complexity**: One system to monitor, tune, and scale\\n4. **Eliminated Data Movement**: Processing happens where data lives\\n5. **Cost-Elastic Scaling**: Adjust memory-to-disk ratios based on performance requirements\\n\\n## Streaming and Flow Control\\n\\nIgnite 3 includes built-in streaming capabilities with configurable backpressure mechanisms:\\n\\n```java\\n// Publisher with flow control configuration\\nStreamingOptions options = StreamingOptions.builder()\\n    .pageSize(1000)\\n    .autoFlushFrequency(Duration.ofMillis(100))\\n    .retryLimit(3)\\n    .build();\\n\\n// Handle millions of events with automatic backpressure\\nCompletableFuture<Void> streaming = ignite.sql()\\n    .streamAsync(\\"INSERT INTO events VALUES (?, ?, ?)\\", \\n                 eventStream, \\n                 options);\\n```\\n\\nThe streaming API provides automatic flow control through configurable page sizes, flush intervals, and retry policies, preventing system overload without data loss.\\n\\n## Performance Characteristics\\n\\nIgnite 3\'s memory-first architecture delivers significantly different performance characteristics compared to disk-based distributed databases:\\n\\n- **Latency**: Microsecond response times for memory-resident data vs. millisecond latencies for disk-based systems\\n- **Throughput**: Handles millions of operations per second per node\\n- **Scalability**: Linear scaling through data partitioning and colocation\\n- **Consistency**: ACID transactions with minimal overhead due to memory speeds\\n\\nThe 10-1000x performance improvement comes from eliminating disk I/O bottlenecks and data movement overhead through collocated processing.\\n\\n## Migration and Adoption Strategy\\n\\nFor technical teams considering Ignite 3:\\n\\n### Assessment Phase\\n\\n1. **Workload Analysis**: Identify performance-critical paths requiring microsecond latencies\\n2. **Data Model Mapping**: Design colocation strategies for your entities\\n3. **Integration Points**: Plan API migration from current multi-system architecture\\n4. **Performance Benchmarking**: Compare memory-first vs. disk-first performance for your workloads\\n\\n### Implementation Approach\\n\\n1. **Start with New Features**: Use Ignite 3 for new development requiring low latency\\n2. **Gradual Migration**: Move performance-critical workloads first\\n3. **Schema Design**: Leverage colocation for optimal data locality\\n4. **Operational Integration**: Integrate monitoring and deployment pipelines\\n\\n## Technical Considerations\\n\\n### Schema Design Best Practices\\n\\n- Use `colocateBy` annotations to ensure related data stays together\\n- Design partition keys to distribute load evenly across nodes\\n- Consider query patterns when defining indexes and colocation strategies\\n- Plan for schema evolution with backward-compatible changes\\n\\n### Performance Optimization\\n\\n- Size memory regions appropriately for your working set\\n- Use collocated compute jobs to minimize data movement\\n- Leverage appropriate storage engines for different workload patterns\\n- Monitor memory usage and adjust disk ratios as needed\\n\\n### Operational Requirements\\n\\n- Plan for Raft consensus network requirements (low-latency, reliable connectivity)\\n- Design backup and recovery procedures for persistent storage engines\\n- Implement monitoring for memory usage, query performance, and compute job execution\\n- Establish capacity planning procedures for memory-first architecture\\n\\n## Summary\\n\\nApache Ignite 3 represents a schema-driven distributed computing platform that consolidates transaction processing, analytics, and compute workloads into a single memory-first architecture. Key architectural elements include:\\n\\n- **Schema-driven design**: Single schema definition drives data placement, query optimization, and compute colocation\\n- **Memory-first storage**: Multiple storage engines with microsecond latency characteristics\\n- **Collocated processing**: Compute-to-data architecture that eliminates data movement overhead\\n- **Unified APIs**: Multiple access patterns (RecordView, KeyValueView, SQL, Compute) for the same schema\\n- **ACID consistency**: Raft consensus and MVCC transactions across all operations\\n- **Built-in streaming**: Flow control and backpressure mechanisms for high-velocity data ingestion\\n\\nThe platform addresses scenarios where traditional multi-system architectures create operational complexity and performance bottlenecks through data movement between separate databases, compute clusters, and analytics systems.\\n\\nExplore the [Ignite 3 documentation](/docs/) for detailed implementation guides and API references."},{"id":"/2025/11/03/apache-ignite-3-1","metadata":{"permalink":"/blog/2025/11/03/apache-ignite-3-1","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-11-03-apache-ignite-3-1.mdx","source":"@site/blog/2025-11-03-apache-ignite-3-1.mdx","title":"Apache Ignite 3.1: Performance, Multi-Language Client Support, and Production Hardening","description":"Apache Ignite 3.1 improves the three areas that matter most when running distributed systems: performance at scale, language flexibility, and operational visibility. The release also fixes hundreds of bugs related to data corruption, race conditions, and edge cases discovered since 3.0.","date":"2025-11-03T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"release","permalink":"/blog/tags/release"}],"readingTime":8.34,"hasTruncateMarker":true,"authors":[{"name":"Evgeniy Stanilovskiy","title":"Apache Ignite Committer","url":"https://github.com/zstan","imageURL":"https://github.com/zstan.png","key":"evgeniy","page":null}],"frontMatter":{"title":"Apache Ignite 3.1: Performance, Multi-Language Client Support, and Production Hardening","authors":["evgeniy"],"date":"2025-11-03T00:00:00.000Z","tags":["apache","ignite","release"]},"unlisted":false,"prevItem":{"title":"Getting to Know Apache Ignite 3","permalink":"/blog/2025/11/11/getting-to-know-ignite3"},"nextItem":{"title":"What\'s New in Apache Ignite 3.0","permalink":"/blog/2025/02/24/whats-new-in-apache-ignite-3-0"}},"content":"Apache Ignite 3.1 improves the three areas that matter most when running distributed systems: performance at scale, language flexibility, and operational visibility. The release also fixes hundreds of bugs related to data corruption, race conditions, and edge cases discovered since 3.0.\\n\\n\x3c!--truncate--\x3e\\n\\n**Before you upgrade**: This release introduces zone-based replication, which changes how RAFT groups are allocated. Persistent storage in upgraded 3.0 clusters will continue to use table-based replication. Read the [Zone-Based Replication Migration](#zone-based-replication-migration) section to understand your options.\\n\\n### What This Release Delivers\\n\\n- **Improved replication performance and reliability**: Zone-based replication improves data colocation, reduces required thread count and memory overhead while naturally improving SQL performance.\\n- **Extended clients support**: Python DB API driver, .NET distributed computing with ADO.NET integration, and enhanced C++ client support expand your options for working with data.\\n- **Better cluster observability**: 50+ new metrics covering checkpoints, SQL, transactions, and storage. New system views for cluster introspection.\\n- **Improved APIs**: Multiple schema support, improved query planning controls, and streamlined Java APIs.\\n\\n### Performance: Built for Scale\\n\\n#### Zone-Based Replication Reduces Overhead\\n\\nApache Ignite 3.1 replaces the table-based replication model from 3.0 with zone-based replication.\\n\\n**Updated defaults**: Zone-based replication is enabled by default for new 3.1 clusters.\\n\\n**Existing clusters**: Clusters with persistent storage upgraded from 3.0 will continue to use table-based replication. To adopt zone-based replication and gain the performance benefits, you must migrate to a new 3.1 cluster. Table-based replication support will be discontinued in Ignite 3.2 release.\\n\\n#### DDL Operations Now Batch Automatically\\n\\nCreating multiple tables no longer requires multiple round-trips. DDL operations batch automatically when possible, reducing setup time during schema initialization and testing.\\n\\n#### Partition Pruning and Partition Awareness\\n\\nApache Ignite 3.1 introduces two other major SQL optimizations that dramatically improve query performance:\\n\\n**Partition Pruning**: The query optimizer automatically eliminates unnecessary partition scans based on predicates. Queries with key-based filters only scan relevant partitions instead of the entire dataset.\\n\\n**Partition Awareness**: Client queries route directly to nodes owning the data, eliminating coordinator hops. The client determines the exact target node for single-partition queries.\\n\\nUse the new `EXPLAIN MAPPING` statement to verify query routing:\\n\\n```sql\\nEXPLAIN MAPPING FOR SELECT * FROM orders WHERE order_id = 12345;\\n```\\n\\nCombined impact: Queries with partition key predicates can see 10x+ performance improvements.\\n\\n### Multi-Language Support\\n\\n#### Python: PEP 249-Compliant Database Driver\\n\\nConnect to Apache Ignite from Python with a standard DB API 2.0 compliant driver. SSL support and macOS compatibility are built in.\\n\\nYou can install the driver from pip:\\n\\n```shell\\npip install pyignite-dbapi\\n```\\n\\nThen, you can import it into your application and initialize the connection:\\n\\n```python\\n# Import and use the driver\\nimport pyignite_dbapi\\n\\nconn = pyignite_dbapi.connect(address=\'localhost:10800\', use_ssl=True)\\ncursor = conn.cursor()\\ncursor.execute(\'SELECT * FROM orders WHERE customer_id = ?\', (customer_id,))\\n```\\n\\n#### .NET: Distributed Computing and ADO.NET\\n\\nWrite compute jobs in C#, F#, or any .NET language and distribute them across your cluster:\\n\\n```csharp\\npublic class HelloJob : IComputeJob<string, string>\\n{\\n    public ValueTask<string> ExecuteAsync(IJobExecutionContext context, string arg, CancellationToken cancellationToken) =>\\n        ValueTask.FromResult(\\"Hello \\" + arg);\\n}\\n\\nvar jobDesc = new JobDescriptor<string, string>(\\n    JobClassName: typeof(HelloJob).AssemblyQualifiedName!,\\n    DeploymentUnits: [new DeploymentUnit(\\"unit1\\")]);\\nvar jobTarget = JobTarget.AnyNode(await client.GetClusterNodesAsync());\\nvar jobExec = await client.Compute.SubmitAsync(jobTarget, jobDesc, \\"world\\");\\n```\\n\\nADO.NET integration brings familiar patterns to .NET developers:\\n\\n```csharp\\nvar connStr = \\"Endpoints=localhost:10800\\";\\nawait using var conn = new IgniteDbConnection(connStr);\\nawait conn.OpenAsync();\\nDbCommand cmd = conn.CreateCommand();\\ncmd.CommandText = \\"DROP TABLE IF EXISTS Person\\";\\nawait cmd.ExecuteNonQueryAsync();\\n```\\n\\nAdditional .NET features in 3.1:\\n\\n- **Platform Streamer Receiver**: Custom data processing during streaming operations\\n- **Batch SQL Execution**: `ISql.ExecuteBatchAsync` for efficient multi-statement execution\\n- **CancellationToken Support**: Integrated cancellation for SQL and Compute APIs\\n\\nSee the [extended blog post about .NET compute in Ignite 3.1](https://ptupitsyn.github.io/NET-Compute-In-Apache-Ignite-3-1/) for a more in-depth explanation.\\n\\n#### C++ Client\\n\\nUse the improved C++ client to improve you application with several new production-ready features:\\n\\n- **Heartbeat Support**: Connection health monitoring prevents timeout disconnects\\n- **Transaction Timeouts**: Configurable timeout settings for transaction operations\\n- **Query Cancellation**: An option to cancel long-running queries\\n\\n#### ODBC Driver SSL Support\\n\\nUse the newly added support for **SSL/TLS** to enable secure connections to the cluster from your ODBC applications.\\n\\n### SQL Capabilities\\n\\n#### Multiple Schemas\\n\\nOrganize tables across multiple schemas instead of using only PUBLIC:\\n\\n```sql\\nCREATE SCHEMA analytics;\\nCREATE TABLE analytics.events (id int primary key, timestamp timestamp, data varchar);\\n```\\n\\n#### Query Plan Recalculation\\n\\nConfigure when query plans are recalculated based on data changes:\\n\\n```sql\\nCREATE TABLE Person (\\n  id INT PRIMARY KEY,\\n  name VARCHAR,\\n  age INT\\n) WITH (MIN STALE ROWS 1000, STALE ROWS FRACTION 0.15);\\n```\\n\\nIgnite will recalculate plans automatically when the application exceeds the thresholds.\\n\\nAlternatively, manually invalidate plans to ensure they reflect current data:\\n\\n```shell\\nsql planner invalidate-cache --tables=PUBLIC.Person\\n```\\n\\n#### EXPLAIN Output Improvements\\n\\nUse the improved EXPLAIN command to track which nodes execute queries and what data they access, making query execution plans clearer. The command now also supports the `EXPLAIN MAPPING FOR` option for tracking data distribution.\\n\\n#### New Functions\\n\\n- `GROUPING`: Aggregate function for advanced grouping operations\\n- `CURRENT_USER`: Access current user for auditing and access control\\n\\n### Code Deployment\\n\\nAccess deployment unit information directly from your compute jobs to better diagnose issues and validate your code:\\n\\n```java\\npublic class DiagnosticJob implements ComputeJob<Void, String> {\\n    @Override\\n    public CompletableFuture<String> executeAsync(JobExecutionContext context, Void input) {\\n        String deploymentInfo = context.deploymentUnits().stream()\\n            .map(unit -> String.format(\\"%s:%s at %s\\", unit.name(), unit.version(), unit.path()))\\n            .collect(Collectors.joining(\\", \\"));\\n        return CompletableFuture.completedFuture(deploymentInfo);\\n    }\\n}\\n```\\n\\nDeployment improvements in 3.1:\\n\\n- ZIP archive support preserves folder structure for complex applications\\n- Files over 10 MB now supported\\n- Automatic unit loading at node startup\\n\\n### Production Operations\\n\\n#### Metrics and Observability\\n\\nApache Ignite 3.1 adds comprehensive metrics across all major subsystems:\\n\\n- **Storage Metrics**: Checkpoint operations, data regions, and storage I/O for aipersist storage engine\\n- **Table Metrics**: Per-table operation statistics including read/write throughput\\n- **Rebalance Metrics**: Track rebalancing progress and performance\\n- **SQL Query Metrics**: Execution time, row counts, and query cache hit rates\\n- **Transaction Metrics**: Transaction lifecycle and duration tracking\\n- **Topology Metrics**: Node join/leave events and cluster state changes\\n- **Throttling Metrics**: Backpressure and flow control statistics\\n- **Clock Drift Metrics**: Monitor time synchronization across cluster nodes\\n\\n**Metric Log Exporter**: Exports metrics to files. The exporter is used by default for all new clusters, providing guaranteed access to basic cluster metrics.\\n\\n#### System Views for Cluster Introspection\\n\\nNew views expose internal cluster state:\\n\\n- `SYSTEM.SQL_CACHED_QUERY_PLANS`: View cached query plans\\n- `SYSTEM.INDEX_COLUMNS`: Access index column information\\n- `SYSTEM.SCHEMAS`: List all schemas in the cluster\\n\\nAll system views now use standardized column naming. Old column naming is still supported for compatibility purposes.\\n\\n#### Compute Job Lifecycle Events\\n\\nNew lifecycle events help you track compute jobs through submission, execution, completion, and failure. MapReduce task events provide visibility into distributed computations.\\n\\n### Cluster Management\\n\\n#### Automatic Metastorage Node Selection\\n\\nIgnite now automatically selects metastorage and cluster management group nodes based on cluster size on cluster initialization:\\n\\n- \u22643 nodes: all nodes participate\\n- 4 nodes: 3 nodes (maintains odd number for consensus)\\n- \u22655 nodes: 5 nodes (balances fault tolerance with overhead)\\n\\n#### Multicast Discovery for Dynamic Environments\\n\\nNodes discover each other automatically using multicast, removing the need for static node lists in containerized deployments:\\n\\n```shell\\nnode config update ignite.network.nodeFinder.multicast.group=239.5.0.0\\nnode config update ignite.network.nodeFinder.type=MULTICAST\\n```\\n\\n#### Docker Enhancements\\n\\nThe default docker environment comes with multiple improvements:\\n\\n- `BOOTSTRAP_NODE_CONFIG` environment variable for configuration management\\n- ARM64 images for ARM-based systems\\n- Non-root default user improves security\\n- Java 17 and 21 images available\\n\\n#### Distribution Zone Quorum Control\\n\\nYou can explicitly set quorum requirements in distribution zones:\\n\\n```sql\\nCREATE ZONE exampleZone (REPLICAS 3, QUORUM SIZE 3) STORAGE PROFILES[\'default\'];\\n```\\n\\n### Transaction Improvements\\n\\nNew transaction timeout options can set different timeouts for read-only and read-write transactions:\\n\\n- `readOnlyTimeoutMillis`: Shorter timeout for read-only transactions\\n- `readWriteTimeoutMillis`: Longer timeout for complex write operations\\n\\nThis prevents read-only queries from timing out unnecessarily while protecting against long-running writes.\\n\\n### Java API Updates\\n\\nMultiple new Java methods simplify the work with your cluster and provide more direct access to data:\\n\\n- `deleteAll()`: Bulk delete operations\\n- `ignite.cluster().nodes()`: Returns nodes in logical topology\\n- `ignite.cluster().localNode()`: Quick access to local node in embedded mode\\n- `CancelHandle` API: Stop queries, transactions, and compute jobs\\n- Batched execution cancellation support\\n\\n### Disaster Recovery and Operational Tools\\n\\nNew CLI and REST APIs enable partition-level data cleanup and restart, letting you recover from corrupted partitions without restarting the whole cluster. The system properly destroys tables during node recovery and cleans abandoned transaction write intents during index builds.\\n\\n### Migration from Apache Ignite 2\\n\\nApache Ignite 3.1 includes a complete migration toolkit with DDL generator for automatic schema conversion, persistent data migration with progress tracking, and automatic type conversion for legacy Java time APIs. The toolkit supports authenticated operations and complex field mappings for key and value replication.\\n\\n### Breaking Changes and Deprecations\\n\\nAll breaking changes include backward compatibility support. Recreate your cluster, update your code and configuration before 3.2, when deprecated approaches will be removed.\\n\\n#### Zone-Based Replication Migration {#zone-based-replication-migration}\\n\\nZone-based replication changes how RAFT groups are allocated across tables. Clusters upgraded from 3.0 continue using table-based replication to preserve stability. To adopt zone-based replication and gain the performance benefits, create a new 3.1 cluster and migrate data using SQL `COPY INTO`/`COPY FROM` commands. See the [3.0 to 3.1 Migration Guide](https://ignite.apache.org/docs/ignite3/latest/installation/migration-from-ai3-1) for detailed workflow.\\n\\n#### Configuration and API Changes\\n\\n**Configuration**: Property names now include units (i.e. `timeoutMillis` instead of `timeout`). System properties were consolidated under `ignite.system`. Old formats work temporarily.\\n\\n**SQL Syntax**: `CREATE ZONE` syntax modernized to align with SQL standards. Old `WITH` clause syntax is deprecated but functional.\\n\\n**Java API**: `ignite.clusterNodes()` deprecated in favor of `ignite.cluster().nodes()`. System view columns standardized with old names temporarily available.\\n\\n**Data Types**: `BINARY` and `CHAR` removed. Use `VARBINARY` and `VARCHAR` instead. Maximum precision for `VARCHAR`/`VARBINARY` increased to 2GB.\\n\\n### Get Started\\n\\n**Download**: [Apache Ignite 3.1](/download)\\n\\n**Migration Guide**: [Upgrading from 3.0](https://ignite.apache.org/docs/ignite3/latest/installation/migration-from-ai3-1)\\n\\n**Community**: Join the [Apache Ignite mailing list](https://ignite.apache.org/community/resources.html) or [Slack channel](https://ignite.apache.org/community/resources.html)\\n\\nQuestions about upgrading? Ask on the [dev list](mailto:dev@ignite.apache.org) or [user list](mailto:user@ignite.apache.org)."},{"id":"/2025/02/24/whats-new-in-apache-ignite-3-0","metadata":{"permalink":"/blog/2025/02/24/whats-new-in-apache-ignite-3-0","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-02-24-whats-new-in-apache-ignite-3-0.mdx","source":"@site/blog/2025-02-24-whats-new-in-apache-ignite-3-0.mdx","title":"What\'s New in Apache Ignite 3.0","description":"Apache Ignite 3.0 is the latest milestone in Apache Ignite evolution that enhances developer experience, platform resilience, and efficiency. In this article, we\'ll explore the key new features and improvements in Apache Ignite 3.0.","date":"2025-02-24T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"ignite3","permalink":"/blog/tags/ignite-3"}],"readingTime":3.85,"hasTruncateMarker":true,"authors":[{"name":"Stanislav Lukyanov","title":"Apache Ignite Committer","url":"https://github.com/slukyanov","imageURL":"https://github.com/slukyanov.png","key":"stanislav","page":null}],"frontMatter":{"title":"What\'s New in Apache Ignite 3.0","authors":["stanislav"],"date":"2025-02-24T00:00:00.000Z","tags":["apache","ignite","release","ignite3"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 3.1: Performance, Multi-Language Client Support, and Production Hardening","permalink":"/blog/2025/11/03/apache-ignite-3-1"},"nextItem":{"title":"Apache Ignite 2.17 Release: What\'s New","permalink":"/blog/2025/02/13/apache-ignite-2-17-0"}},"content":"Apache Ignite 3.0 is the latest milestone in Apache Ignite evolution that enhances developer experience, platform resilience, and efficiency. In this article, we\'ll explore the key new features and improvements in Apache Ignite 3.0.\\n\\n\x3c!--truncate--\x3e\\n\\n## Installation and Management of Ignite 3\\n\\nApache Ignite 3.0 simplifies the installation and management process, making it more accessible for developers and administrators.\\n\\n### New Ignite 3 Installation Packages\\n\\nApache Ignite 3.0 introduces modern Linux installation options:\\n\\n- **Native Linux Packages**: Ignite now offers native RPM and DEB installation packages for Linux distributions, making it easier to install, upgrade, and manage through standard package managers.\\n\\n### Interactive Unified Ignite CLI\\n\\nThe new Ignite 3.0 Command Line Interface (CLI) provides a streamlined experience for managing and interacting with the cluster.\\n\\n- **Single CLI Tool**: The new CLI unifies cluster configuration, management, and SQL access in one tool, reducing complexity.\\n- **Scripting and Interactive Mode**: Users can execute scripts for automation or use an interactive shell (REPL) for direct interaction with the cluster.\\n- **Syntax Highlighting and Autocomplete**: The interactive mode includes enhanced usability features such as syntax highlighting and command autocompletion, making cluster management and troubleshooting easier.\\n\\n### Dynamic Configuration Framework\\n\\nApache Ignite 3.0 replaces the legacy Spring XML-based configuration with a modern dynamic configuration system:\\n\\n- **HOCON-based Configuration**: Human-Optimized Config Object Notation (HOCON) is now the standard configuration language, offering a more readable and flexible alternative to XML.\\n- **Dynamic Changes**: Configuration parameters can now be modified dynamically via the CLI or REST API without requiring a node restart, improving operational flexibility.\\n\\n## Clients and APIs for Ignite 3\\n\\nApache Ignite 3.0 streamlines application development by unifying access across different clients and data models while ensuring flexibility and improving developer experience.\\n\\n### Unified Ignite Clients\\n\\nPreviously, Ignite had a distinction between thin and thick clients, requiring developers to choose between lightweight connections or full-featured clients. In Ignite 3.0:\\n\\n- **Lightweight Yet Fully Featured Ignite Clients**: New clients now support the full range of API features without the need to choose between thin or thick clients.\\n- **Consistent Experience Across Languages**: The new client model ensures consistency in API behavior across different programming languages, reducing learning curves and integration complexities.\\n\\n### Table API and Unified Schema for Ignite 3\\n\\nIgnite 3.0 enhances the way the data schema is managed and accessed across SQL and NoSQL interfaces.\\n\\n- **Consistent Data Schema**: All data representations\u2014SQL schema, key-value data types, and internal data storage\u2014are now unified, eliminating the need for error-prone mappings between different models.\\n- **Table Views**: Table Views is a new API that allows applications to independently define how they access the database tables, increasing flexibility in choosing the client-side data model.\\n- **Record API**: Record API is a new alternative to Key-Value API that allows you to use a single data object without separating it into keys and values, which further increases flexibility of development.\\n\\n### Asynchronous and Reactive Programming for Ignite 3\\n\\nIgnite 3.0 enhances support for concurrent programming paradigms:\\n\\n- **Language Features Support**: Client APIs support asynchronous and reactive programming with standard language constructs such as CompletableFuture and Flow API in Java or Task and IAsyncEnumerable in .NET.\\n\\n### SQL Transactions in Ignite 3\\n\\nIgnite 3.0 includes full transaction support in SQL:\\n\\n- **Transactional SQL Support**: Full support for transactions allows you to bring more SQL applications to Ignite without compromising on consistency.\\n- **Combining SQL and NoSQL**: Both SQL and NoSQL-style APIs can be used together in a single transaction, enabling developers to choose the API they want to use at any given time.\\n\\n## Architecture and Performance in Ignite 3\\n\\nApache Ignite 3.0 includes major architectural upgrades to improve cluster reliability and efficiency.\\n\\n### Raft-based Consensus\\n\\nApache Ignite 3.0 now utilizes a Raft-based consensus mechanism for enhanced resiliency:\\n\\n- **Improved Fault Tolerance**: Distributed consensus ensures stronger cluster stability and prevents split-brain scenarios.\\n- **Simplified Cluster Changes**: The new protocol reduces impact of node restarts and topology changes on the overall cluster, minimizing downtime and simplifying maintenance.\\n\\n## Apache Ignite 3.0\\n\\nApache Ignite 3.0 is a major step forward, simplifying installation, improving configuration management, enhancing API usability, and significantly boosting performance.\\n\\n- **For New Ignite Users**: Apache Ignite 3.0 provides an easier learning curve, streamlining first-time installation and configuration.\\n- **For Experienced Ignite Users**: Enhanced developer experience simplifies continuous improvement and maintenance.\\n\\nTo learn more:\\n\\n- Register for and attend [Ignite Summit 2025](https://events.ringcentral.com/events/ignite-summit-2025) on Feb 25 online!\\n- Don\'t miss the session, \\"[What\'s New and Cool in Ignite 3](https://ignite-summit.org/2025/sessions/844189)\\" by Pavel Tupitsyn, a core Ignite committer.\\n\\nTo try the new Apache Ignite 3.0 capabilities yourself:\\n\\n- [Download Apache Ignite 3.0](https://ignite.apache.org/download) from the official website."},{"id":"/2025/02/13/apache-ignite-2-17-0","metadata":{"permalink":"/blog/2025/02/13/apache-ignite-2-17-0","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2025-02-13-apache-ignite-2-17-0.mdx","source":"@site/blog/2025-02-13-apache-ignite-2-17-0.mdx","title":"Apache Ignite 2.17 Release: What\'s New","description":"We are happy to announce the release of Apache Ignite 2.17.0! In this latest version, the Ignite community has introduced a range of new features and improvements to deliver a more efficient, flexible, and future-proof platform. Below, we\'ll cover the key highlights that you can look forward to when upgrading to the new release.","date":"2025-02-13T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":4.05,"hasTruncateMarker":true,"authors":[{"name":"Nikita Amelchev","title":"Apache Ignite Committer","url":"https://github.com/NSAmelchev","imageURL":"https://github.com/NSAmelchev.png","key":"nikita","page":null}],"frontMatter":{"title":"Apache Ignite 2.17 Release: What\'s New","authors":["nikita"],"date":"2025-02-13T00:00:00.000Z","tags":["database","ignite","release","archived"]},"unlisted":false,"prevItem":{"title":"What\'s New in Apache Ignite 3.0","permalink":"/blog/2025/02/24/whats-new-in-apache-ignite-3-0"},"nextItem":{"title":"Ignite on .NET 9 and Intel CET","permalink":"/blog/2024/11/22/apache-ignite-net-intel-cet-fix"}},"content":"We are happy to announce the release of [Apache Ignite](https://ignite.apache.org/) 2.17.0! In this latest version, the Ignite community has introduced a range of new features and improvements to deliver a more efficient, flexible, and future-proof platform. Below, we\'ll cover the key highlights that you can look forward to when upgrading to the new release.\\n\\n\x3c!--truncate--\x3e\\n\\n### Migrating to Java 11 {#migrate-to-java-11}\\n\\nIgnite 2.17 has officially moved its codebase to Java 11. With Java 8 approaching end-of-life (for public updates) and many organizations already moving to newer Java versions, this change enables Ignite to take advantage of modern language features, improved performance, and security enhancements. By upgrading Ignite to this latest release, you can ensure your cluster runs on a more up-to-date and secure Java environment.\\n\\n### Transaction-Aware SQL and Scan Queries {#transaction-aware-sql}\\n\\nApache Ignite provides multiple interfaces to query data, including:\\n\\n- Key-Value API.\\n- SQL.\\n- Scan query.\\n- Index scan query.\\n\\nWhile Ignite has long supported ACID transactions for the Key-Value API, there has been a known limitation when it comes to data queries: changes made within an ongoing transaction were not visible to SQL or Scan queries. This could lead to inconsistencies when querying data inside a transaction.\\n\\nWith the release of Apache Ignite 2.17, we are excited to introduce transaction-aware SQL and Scan queries, a significant enhancement that improves consistency and isolation when querying data within transactions.\\n\\n**NOTE**: This feature is currently supported only for the Calcite SQL engine and at the `READ_COMMITTED` isolation level.\\n\\nTo enable this feature, set the `txAwareQueriesEnabled` property in the `TransactionConfiguration`. Once enabled, your SQL and Scan queries will reflect transaction-related changes in real-time.\\n\\nHere\'s an example of how it works:\\n\\n```java\\ntry (Transaction tx = srv.transactions().txStart(PESSIMISTIC, READ_COMMITTED)) {\\n    cache.put(1, 2);\\n\\n    List<List<?>> sqlData = executeSql(srv, \\"SELECT COUNT(*) FROM TBL.TBL\\");\\n    List<Entry<Integer, Integer>> scanData = cache.query(new ScanQuery<Integer, Integer>()).getAll();\\n\\n    assertEquals(\\"Must see transaction related data\\", 1L, sqlData.get(0).get(0));\\n    assertEquals(\\"Must see transaction related data\\", 1, scanData.size());\\n\\n    tx.commit();\\n}\\n```\\n\\n### Control Utility Switches to Thin Client Protocol {#control-utility-migrates-to-thin-client}\\n\\nStarting from Apache Ignite version 2.17, the utility by default uses a connection through the thin client protocol (configured on a node via `ClientConnectorConfiguration`).\\n\\nWith the default configuration of Ignite, no migration actions will be required. Additional configuration of the connector is no longer necessary.\\n\\nIn some cases, a few actions may be required to migrate user scripts using the utility. See more in [documentation](https://ignite.apache.org/docs/latest/tools/control-script#migration-to-the-thin-client-protocol). It\'s important to note that connection via Binary-REST protocol (configured via `ConnectorConfiguration`) has been deprecated and is planned to be removed in future releases.\\n\\n### Custom User-Defined Metrics {#custom-user-defined-metrics}\\n\\nYou can now create custom user-defined metrics in Ignite 2.17. This feature allows you to gather and expose metric data specific to the needs of your application. You can perform in-depth monitoring and troubleshooting by tracking those metrics that matter most to you. Here is example of usage:\\n\\n```java\\nIgnite ignite = Ignition.ignite();\\n\\nignite.metrics()\\n    .getOrCreate(\\"app-metric-registry\\")\\n    .register(\\"Status\\", () -> appStatus.get(), \\"Application status.\\");\\n```\\n\\n### Calcite SQL Engine {#calcite-sql-engine}\\n\\nThe Apache Ignite community continues to enhance the SQL experience, and the latest updates to the [Calcite SQL engine](https://ignite.apache.org/docs/latest/SQL/sql-calcite) bring several powerful features and improvements!\\n\\nUpdates include support for bitwise operations and aggregates (e.g., `BIT_AND`, `BIT_OR`, `BIT_XOR`), arithmetic overflow handling, date formatting/parsing with custom formats, and join type hints for better query optimization. Additionally, the Calcite engine now supports grouping by aliases and ordinal values, providing more flexibility in query design.\\n\\nLooking ahead, the Ignite community has big plans for Calcite. The goal is to make Calcite the default SQL engine in future releases, deprecating the legacy H2-based engine.\\n\\n### Java Thin Client Enhancements: `invoke()` and `invokeAll()` {#java-thin-client-enhancements}\\n\\nIn this release, the Java thin client adds entry processor methods that will simplify how you interact with Ignite clusters: `invoke()` and `invokeAll()`.\\n\\nAn entry processor is used to process cache entries on the nodes where they are stored. An entry processor does not require the entry to be transferred to the client in order to perform an operation on it. The operation is performed remotely, and only the results are transmitted to the client.\\n\\nHere is example of an operation:\\n\\n```java\\nClientCache<Integer, Integer> cache = client.getOrCreateCache(\\"myCache\\");\\n\\ncache.invoke(0, new IncrementProcessor());\\n```\\n\\n**NOTE**: The classes of the entry processors must be available on the server nodes of the cluster.\\n\\n### Anything else? {#anything-else}\\n\\nSee the [release notes](https://ignite.apache.org/releases/ignite2/2.17.0/release_notes.html) to learn about all of the new features and improvements.\\n\\nReach out to us on the community user list for more questions, details, and feedback.\\n\\nSincerely yours, Ignite contributors and committers"},{"id":"/2024/11/22/apache-ignite-net-intel-cet-fix","metadata":{"permalink":"/blog/2024/11/22/apache-ignite-net-intel-cet-fix","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2024-11-22-apache-ignite-net-intel-cet-fix.mdx","source":"@site/blog/2024-11-22-apache-ignite-net-intel-cet-fix.mdx","title":"Ignite on .NET 9 and Intel CET","description":"Old JDK code meets new Intel security feature, JVM + CLR in one process, and a mysterious crash.","date":"2024-11-22T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":".NET","permalink":"/blog/tags/net"},{"inline":true,"label":"security","permalink":"/blog/tags/security"},{"inline":true,"label":"Intel","permalink":"/blog/tags/intel"},{"inline":true,"label":"CET","permalink":"/blog/tags/cet"}],"readingTime":0.13,"hasTruncateMarker":true,"authors":[{"name":"Pavel Tupitsyn","title":"Apache Ignite Committer","url":"https://github.com/ptupitsyn","imageURL":"https://github.com/ptupitsyn.png","key":"pavel","page":null}],"frontMatter":{"title":"Ignite on .NET 9 and Intel CET","authors":["pavel"],"date":"2024-11-22T00:00:00.000Z","tags":["database","ignite",".NET","security","Intel","CET"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.17 Release: What\'s New","permalink":"/blog/2025/02/13/apache-ignite-2-17-0"},"nextItem":{"title":"Apache Ignite 2.16.0: Cache dumps, Calcite engine stabilization, JDK 14+ bug fixes","permalink":"/blog/2023/12/25/apache-ignite-2-16-0"}},"content":"Old JDK code meets new Intel security feature, JVM + CLR in one process, and a mysterious crash.\\n\\n\x3c!--truncate--\x3e\\n\\n[Read More...](https://ptupitsyn.github.io/Ignite-on-NET-9/)"},{"id":"/2023/12/25/apache-ignite-2-16-0","metadata":{"permalink":"/blog/2023/12/25/apache-ignite-2-16-0","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2023-12-25-apache-ignite-2-16-0.mdx","source":"@site/blog/2023-12-25-apache-ignite-2-16-0.mdx","title":"Apache Ignite 2.16.0: Cache dumps, Calcite engine stabilization, JDK 14+ bug fixes","description":"As of December 25, 2023, Apache Ignite 2.16 has been released. You can directly check the full list of resolved Important JIRA tasks but let\'s briefly overview some valuable improvements.","date":"2023-12-25T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"in","permalink":"/blog/tags/in"},{"inline":true,"label":"memory","permalink":"/blog/tags/memory"},{"inline":true,"label":"open","permalink":"/blog/tags/open"},{"inline":true,"label":"source","permalink":"/blog/tags/source"},{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":4.01,"hasTruncateMarker":true,"authors":[{"name":"Nikita Amelchev","title":"Apache Ignite Committer","url":"https://github.com/NSAmelchev","imageURL":"https://github.com/NSAmelchev.png","key":"nikita","page":null}],"frontMatter":{"title":"Apache Ignite 2.16.0: Cache dumps, Calcite engine stabilization, JDK 14+ bug fixes","authors":["nikita"],"date":"2023-12-25T00:00:00.000Z","tags":["database","ignite","in","memory","open","source","release","archived"]},"unlisted":false,"prevItem":{"title":"Ignite on .NET 9 and Intel CET","permalink":"/blog/2024/11/22/apache-ignite-net-intel-cet-fix"},"nextItem":{"title":"Dynamic LINQ performance and usability with Ignite.NET and System.Linq.Dynamic","permalink":"/blog/2023/05/22/apache-ignite-net-dynamic-linq"}},"content":"As of December 25, 2023, [Apache Ignite](https://ignite.apache.org/) 2.16 has been released. You can directly check the full list of resolved [Important JIRA tasks](https://s.apache.org/j3brc) but let\'s briefly overview some valuable improvements.\\n\\n### Cache dumps\\n\\nIgnite has persistent cache [snapshots](https://ignite.apache.org/docs/latest/snapshots/snapshots) and this feature is highly appreciated by Ignite users. This release introduces another way to make a copy of user data - a cache dump.\\n\\nThe cache dump is essentially a file that contains all entries of a cache group at the time of dump creation. Dump is consistent like a snapshot, which means all entries that existed in the cluster at the moment of dump creation will be included in the dump file. Meta information of dumped caches and binary meta are also included in the dump.\\n\\nMain differences from cache snapshots:\\n\\n- Supports in-memory caches that a snapshot feature does not support.\\n- Takes up less disk space. The dump contains only the cache entries as-is.\\n- Can be used for offline data processing.\\n\\n\x3c!--truncate--\x3e\\n\\nThe [IgniteSnapshot](https://github.com/apache/ignite/blob/ignite-2.16/modules/core/src/main/java/org/apache/ignite/IgniteSnapshot.java#L75) interface provides a method to create a dump:\\n\\n```java\\nignite.snapshot().createDump(\\"dump-name\\", Arrays.asList(\\"cacheGrp1\\", \\"cacheGrp2\\")).get();\\n```\\n\\nYou can read a dump using the [Dump Reader](https://github.com/apache/ignite/blob/ignite-2.16/modules/core/src/main/java/org/apache/ignite/dump/DumpReader.java) application:\\n\\n```java\\n// Consumer should be implemented to receive all data stored in cache dump.\\nDumpConsumer cnsmr = new DumpConsumerImpl(..);\\n\\nDumpReaderConfiguration cfg = new DumpReaderConfiguration(new File(\\"path-to-dump\\"), cnsmr);\\n\\nnew DumpReader(cfg, log).run();\\n```\\n\\n### Calcite engine: added hints and diagnostic tools, became more stable\\n\\nThe [Calcite engine](https://ignite.apache.org/docs/2.16.0/SQL/sql-calcite) is now fully equipped with metrics, events and the performance statistics tool. Moreover, query plans and other useful properties have been added to the [performance statistics report](https://ignite.apache.org/docs/2.16.0/extensions-and-integrations/performance-statistics).\\n\\nThe following hints have been introduced to help the optimizer make optimizations more rational or build an execution plan faster:\\n\\n- [FORCE_INDEX / NO_INDEX](https://ignite.apache.org/docs/2.16.0/SQL/sql-calcite#force_index-no_index) - Forces or disables index scan.\\n- [ENFORCE_JOIN_ORDER](https://ignite.apache.org/docs/2.16.0/SQL/sql-calcite#enforce_join_order) - Forces join order as appears in a query. Fastens building of joins plan.\\n\\nThere are 10+ bugs and performance fixes in the release.\\n\\n### Java thin client: Service Awareness feature\\n\\nIn previous versions of Ignite, the thin client invoked the service grid on a random server node. A service may not be deployed on each node. If a node misses the invoked service, the invocation request is redirected to a proper node. This additional network hop adds overhead and can now be avoided.\\n\\nWith Service Awareness, the thin client knows where service instances are deployed and sends the request to the correct node.\\n\\nNote that the service topology is updated asynchronously starting with the first service invocation. Thus, some invocation redirects are still possible.\\n\\nThe feature is activated if:\\n\\n- The [Partition Awareness](https://github.com/apache/ignite/blob/ignite-2.16/modules/core/src/main/java/org/apache/ignite/configuration/ClientConfiguration.java#L577) property is enabled in a client configuration (it is enabled by default).\\n- Cluster and thin client versions are 2.16.0 and higher.\\n\\n### CDC: Realtime mode\\n\\nSince version 2.12 Ignite supports the [CDC functionality](https://ignite.apache.org/docs/2.16.0/persistence/change-data-capture). It\'s implemented with a background process that processes archived WAL segments. The delay between the creation of an event and it\'s processing by this process contains the time WAL segments were archived. Some users are intolerant of this lag. For such users, Ignite now provides functionality that makes it possible to process events almost instantly after they are created. Please refer to the [CdcManager](https://github.com/apache/ignite/blob/ignite-2.16/modules/core/src/main/java/org/apache/ignite/internal/cdc/CdcManager.java) interface javadocs for more details.\\n\\n### Other improvements and changes\\n\\n- Fixed JDK 14-21 support issues.\\n- [Cluster Management API](https://cwiki.apache.org/confluence/display/IGNITE/IEP-81+Cluster+Management+API) has been implemented to unify management command invokers via various protocols - CLI, JMX, REST. The Ignite now provides JMX command invoker.\\n- Operations on atomic caches within transactions are finally forbidden. The system property `IGNITE_ALLOW_ATOMIC_OPS_IN_TX` has been removed.\\n- The community agreed to remove MVCC. The `CacheAtomicityMode#TRANSACTIONAL_SNAPSHOT` cache mode has been removed.\\n- Mixed mode cache groups are now forbidden, but `IGNITE_ALLOW_MIXED_CACHE_GROUPS` system option may temporarily allow them.\\n- The ignite-ml and cassandra modules have been migrated to the [Ignite extensions](https://github.com/apache/ignite-extensions).\\n- 100+ small improvements and bug fixes.\\n\\n### Anything else?\\n\\nSee the [release notes](https://ignite.apache.org/releases/ignite2/2.16.0/release_notes.html) to learn about all of the new features and improvements.\\n\\nReach out to us on the community user list for more questions, details, and feedback.\\n\\nSincerely yours, Ignite contributors and committers"},{"id":"/2023/05/22/apache-ignite-net-dynamic-linq","metadata":{"permalink":"/blog/2023/05/22/apache-ignite-net-dynamic-linq","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2023-05-22-apache-ignite-net-dynamic-linq.mdx","source":"@site/blog/2023-05-22-apache-ignite-net-dynamic-linq.mdx","title":"Dynamic LINQ performance and usability with Ignite.NET and System.Linq.Dynamic","description":"Dynamically building database queries can be necessary for some use cases, such as UI-defined filtering. This can get challenging with LINQ frameworks like EF Core and Ignite.NET.","date":"2023-05-22T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"linq","permalink":"/blog/tags/linq"},{"inline":true,"label":".NET","permalink":"/blog/tags/net"},{"inline":true,"label":"SQL","permalink":"/blog/tags/sql"},{"inline":true,"label":"performance","permalink":"/blog/tags/performance"},{"inline":true,"label":"csharp","permalink":"/blog/tags/csharp"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":0.19,"hasTruncateMarker":true,"authors":[{"name":"Pavel Tupitsyn","title":"Apache Ignite Committer","url":"https://github.com/ptupitsyn","imageURL":"https://github.com/ptupitsyn.png","key":"pavel","page":null}],"frontMatter":{"title":"Dynamic LINQ performance and usability with Ignite.NET and System.Linq.Dynamic","authors":["pavel"],"date":"2023-05-22T00:00:00.000Z","tags":["database","ignite","linq",".NET","SQL","performance","csharp","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.16.0: Cache dumps, Calcite engine stabilization, JDK 14+ bug fixes","permalink":"/blog/2023/12/25/apache-ignite-2-16-0"},"nextItem":{"title":"Apache Ignite 2.13.0: new Apache Calcite-based SQL engine","permalink":"/blog/2022/04/28/apache-ignite-2-13-0"}},"content":"Dynamically building database queries can be necessary for some use cases, such as UI-defined filtering. This can get challenging with LINQ frameworks like EF Core and Ignite.NET.\\n\\n\x3c!--truncate--\x3e\\n\\n[Read More...](https://ptupitsyn.github.io/Dynamic-LINQ-With-Ignite/)"},{"id":"/2022/04/28/apache-ignite-2-13-0","metadata":{"permalink":"/blog/2022/04/28/apache-ignite-2-13-0","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2022-04-28-apache-ignite-2-13-0.mdx","source":"@site/blog/2022-04-28-apache-ignite-2-13-0.mdx","title":"Apache Ignite 2.13.0: new Apache Calcite-based SQL engine","description":"As of April 26, 2022, Apache Ignite 2.13 has been released. You can directly check the full list of resolved Important JIRA tasks but here let\'s briefly overview some valuable improvements.","date":"2022-04-28T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"in","permalink":"/blog/tags/in"},{"inline":true,"label":"memory","permalink":"/blog/tags/memory"},{"inline":true,"label":"open","permalink":"/blog/tags/open"},{"inline":true,"label":"source","permalink":"/blog/tags/source"},{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":3.02,"hasTruncateMarker":true,"authors":[{"name":"Nikita Amelchev","title":"Apache Ignite Committer","url":"https://github.com/NSAmelchev","imageURL":"https://github.com/NSAmelchev.png","key":"nikita","page":null}],"frontMatter":{"title":"Apache Ignite 2.13.0: new Apache Calcite-based SQL engine","authors":["nikita"],"date":"2022-04-28T00:00:00.000Z","tags":["database","ignite","in","memory","open","source","release","archived"]},"unlisted":false,"prevItem":{"title":"Dynamic LINQ performance and usability with Ignite.NET and System.Linq.Dynamic","permalink":"/blog/2023/05/22/apache-ignite-net-dynamic-linq"},"nextItem":{"title":"Apache Ignite 2.12.0: CDC, Index Query API, Vulnerabilities Fixes","permalink":"/blog/2022/01/14/apache-ignite-2-12-0"}},"content":"As of April 26, 2022, [Apache Ignite](https://ignite.apache.org/) 2.13 has been released. You can directly check the full list of resolved [Important JIRA tasks](https://s.apache.org/x8u49) but here let\'s briefly overview some valuable improvements.\\n\\n#### This is a breaking change release: The legacy service grid implementation was removed.\\n\\n### New Apache Calcite-based SQL engine\\n\\nWe\'ve implemented a new experimental SQL engine based on Apache Calcite. Now it\'s possible to:\\n\\n- Get rid of some [H2 limitations](https://cwiki.apache.org/confluence/display/IGNITE/IEP-37%3A+New+query+execution+engine#IEP37:Newqueryexecutionengine-Motivation);\\n- [Optimize](https://cwiki.apache.org/confluence/display/IGNITE/IEP-37%3A+New+query+execution+engine#IEP37:Newqueryexecutionengine-Implementationdetails) some query execution.\\n\\nThe current H2-based engine has fundamental limitations. For example:\\n\\n- some queries should be splitted into 2 phases (map subquery and reduce subquery), but some of them cannot be effectively executed in 2 phases.\\n- H2 is a third-party database product with not-ASF license.\\n- The optimizer and other internal things are not supposed to work in a distributed environment.\\n- It\'s hard to make Ignite-specific changes to the H2 code, patches are often declined.\\n\\n\x3c!--truncate--\x3e\\n\\nThe Apache Calcite is a SQL engine with customizable modules. Requests can be splitted into more than 2 phases.\\n\\nA query engine can be set before query execution. Here is an example for SQL:\\n\\n```java\\nSELECT /*+ QUERY_ENGINE(\'h2\') */ fld FROM table;\\n```\\n\\nor\\n\\n```java\\nSELECT /*+ QUERY_ENGINE(\'calcite\') */ fld FROM table;\\n```\\n\\nSee JDBC and ODBC examples [here](https://github.com/apache/ignite/blob/master/modules/calcite/README.txt).\\n\\nThe new engine requires the ignite-indexing module (which depends on H2) to be included to the classpath to support queries infrastructure.\\n\\nSee more technical details about the new engine in the [IEP-37](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=130028084).\\n\\n### Read Repair strategies\\n\\n[\\"Read Repair\\"](https://ignite.apache.org/docs/latest/read-repair) refers to a technique of repairing inconsistencies between primary and backup copies of data during normal read operations. When a specific key (or keys) is read by a user operation, Ignite checks the values for the given key in all backup copies.\\n\\nWe\'ve implemented the new Read Repair strategies as follows:\\n\\n- LWW (Last Write Wins) - Last write (the newest entry) wins.\\n- PRIMARY - Value from the primary node wins.\\n- RELATIVE_MAJORITY - The relative majority: a value found more often than any other wins.\\n- REMOVE - Inconsistent entries will be removed.\\n- CHECK_ONLY - Only check will be performed.\\n\\n### Array type in Binary Object\\n\\nIn previous versions Ignite did not save information about array type. Now it can be stored in a binary object:\\n\\n```\\ncache.put(1, new Person[] {new Person(1), new Person(2)});\\n\\nPerson[] obj = cache.get(1);\\n\\nassertEquals(Person[].class, obj.getClass());\\n```\\n\\nThe feature is disabled by default due to compatibility issues. Set the IGNITE_USE_BINARY_ARRAYS system property to true to enable it.\\n\\n### CDC for in-memory caches\\n\\nThe [Change Data Capture](https://ignite.apache.org/docs/latest/persistence/change-data-capture) now can be configured for in-memory caches. From now on, only CDC needed records for such caches will be logged to WAL.\\n\\n### Other improvements and changes\\n\\n- The C++ thin client implemented continuous queries and asynchronous network events handling. See the updated thin clients features list [here](https://cwiki.apache.org/confluence/display/IGNITE/Thin+clients+features);\\n- Implemented NUMA-aware [allocator](https://github.com/apache/ignite/tree/master/modules/numa-allocator) for data regions;\\n- Ignite maven BOM;\\n- Removed the legacy service grid implementation;\\n- 100+ small improvements and bug fixes.\\n\\n### Anything else?\\n\\nSee the [release notes](https://ignite.apache.org/releases/ignite2/2.13.0/release_notes.html) to learn about all of the new features and improvements.\\n\\nReach out to us on the community user list for more questions, details, and feedback.\\n\\nSincerely yours,\\nIgnite contributors and committers"},{"id":"/2022/01/14/apache-ignite-2-12-0","metadata":{"permalink":"/blog/2022/01/14/apache-ignite-2-12-0","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2022-01-14-apache-ignite-2-12-0.mdx","source":"@site/blog/2022-01-14-apache-ignite-2-12-0.mdx","title":"Apache Ignite 2.12.0: CDC, Index Query API, Vulnerabilities Fixes","description":"As of January 14, 2022, Apache Ignite 2.12 has been released. You can directly check the full list of resolved Important JIRA tasks but here let\'s briefly overview some valuable improvements.","date":"2022-01-14T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"in-memory","permalink":"/blog/tags/in-memory"},{"inline":true,"label":"open-source","permalink":"/blog/tags/open-source"},{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":3.86,"hasTruncateMarker":true,"authors":[{"name":"Nikita Amelchev","title":"Apache Ignite Committer","url":"https://github.com/NSAmelchev","imageURL":"https://github.com/NSAmelchev.png","key":"nikita","page":null}],"frontMatter":{"title":"Apache Ignite 2.12.0: CDC, Index Query API, Vulnerabilities Fixes","authors":["nikita"],"date":"2022-01-14T00:00:00.000Z","tags":["database","ignite","in-memory","open-source","release","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.13.0: new Apache Calcite-based SQL engine","permalink":"/blog/2022/04/28/apache-ignite-2-13-0"},"nextItem":{"title":"Apache Ignite 2.11.1: Emergency Log4j2 Update","permalink":"/blog/2021/12/21/apache-ignite-2-11-1"}},"content":"As of January 14, 2022, [Apache Ignite](https://ignite.apache.org/) 2.12 has been released. You can directly check the full list of resolved [Important JIRA tasks](https://s.apache.org/0zyi2) but here let\'s briefly overview some valuable improvements.\\n\\n### Vulnerability Updates\\n\\nThe Apache Ignite versions lower than 2.11.1 are vulnerable to [CVE-2021-44832](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44832) which is related to the `ignite-log4j2` module usage.\\n\\nThe release also fixes 10+ CVE\'s of various modules. See [release notes](https://ignite.apache.org/releases/ignite2/2.12.0/release_notes.html) for more details.\\n\\n### Change Data Capture\\n\\nChange Data Capture ([CDC](https://en.wikipedia.org/wiki/Change_data_capture)) is a data processing pattern used to asynchronously receive entries that have been changed on the local node so that action can be taken using the changed entry.\\n\\n\x3c!--truncate--\x3e\\n\\nBelow are some of the CDC use cases:\\n\\n- Streaming changes in Warehouse;\\n- Updating search index;\\n- Calculating statistics (streaming queries);\\n- Auditing logs;\\n- Async interaction with external systems: Moderation, business process invocation, etc.\\n\\nIgnite implements CDC with the `ignite-cdc.sh` application and [Java API](https://github.com/apache/ignite/blob/master/modules/core/src/main/java/org/apache/ignite/cdc/CdcConsumer.java#L56).\\n\\nBelow are the CDC application and the Ignite node integrated via [WAL archive segments](https://ignite.apache.org/docs/2.12.0/persistence/native-persistence#write-ahead-log):\\n\\n![Apache Ignite CDC design](/img/blog/c5574c7d-2a24-4def-b1c4-b2343ed98397.svg)\\n\\nWhen CDC is enabled, the Ignite server node creates a hard link to each WAL archive segment in the special `db/cdc/{consistency_id}` directory. The `ignite-cdc.sh` application can be runruns on a different JVM and processes newly archived WAL segments. When the segment is fully processed by `ignite-cdc.sh`, it is removed. The actual disk space is free when both links (archive and CDC) are removed.\\n\\nState of consumption is a pointer to the last processed event. A consumer can tell `ignite-cdc.sh` to save the consumption state. On startup event processing will be continued from the last saved state.\\n\\nSee implementation details [here](https://ignite.apache.org/docs/2.12.0/persistence/change-data-capture).\\n\\n### Index Query API\\n\\nThe Apache Ignite now provides Index Query API for existing indexes. Index queries work over distributed indexes and retrieve cache entries that match the specified query.\\n\\nIt will help in some cases, where:\\n\\n- SQL is not applicable by the design of user application;\\n- `IndexScan` is preferable to `ScanQuery` for performance reasons.\\n\\nExample of query:\\n\\n```java\\n// Find the persons who work in Organization 1 and have salary more than 1,000.\\nQueryCursor<Cache.Entry<Integer, Person>> cursor = cache.query(\\n  new IndexQuery<Integer, Person>(Person.class, \\"ORG_SALARY_IDX\\")\\n  .setCriteria(eq(\\"orgId\\", 1), gt(\\"salary\\", 1000))\\n);\\n```\\n\\nSee more details [here](https://ignite.apache.org/docs/latest/key-value-api/using-cache-queries#executing-index-queries).\\n\\n### Snapshots\\n\\nPrevious versions can perform snapshot restore in the same cluster topology only. The new version provides the ability to restore snapshots on different cluster topologies. Moreover, added support of encrypted caches.\\n\\n### Distributed Environment Tests\\n\\nThe [new testing framework](https://cwiki.apache.org/confluence/display/IGNITE/IEP-56%3A+Distributed+environment+tests) was implemented. The main goal is to have a large enough set of integration tests that cover most of the typical cluster usage scenarios.\\n\\nFeatures:\\n\\n- Ignite nodes can be started/stopped on a Docker or a real cluster with any custom configuration;\\n- Any Apache Ignite version is supported (released or compiled from sources);\\n- Apache Ignite forks are also supported out of the box;\\n- Any other application execution is also possible, e.g. we implemented starters for Spark and Zookeeper;\\n- The cluster can be managed using the `control.sh`, we made this a part of the test API;\\n- Custom Java applications can be executed remotely with/without a built-in Ignite node or a Thin client;\\n- Any ssh command can be executed remotely, and the result will be available locally (at the python test);\\n- A network can be broken by editing `iptables` to check communication issues;\\n- Tests can be executed in parallel when the cluster size is bigger than tests requirements.\\n\\nFramework based on [Ducktape](https://ducktape-docs.readthedocs.io/en/latest/index.html) library from Kafka team, that\'s why we called it Ducktests.\\n\\n### Migration modules to the Apache Ignite Extensions\\n\\nThere is activity on the migration of frameworks to extensions:\\n\\n- GCE, AWS, Azure modules were migrated to `gce`, `aws`, `azure` extensions.\\n- CacheSpringStoreSessionListener was migrated to the `spring-tx` extension.\\n- TcpDiscoveryZookeeperIpFinder was migrated to the `zookeeper-ip-finder` extension.\\n\\nThe binaries archive now weighs 10 percent less.\\n\\n### Anything else?\\n\\nSee the [release notes](https://ignite.apache.org/releases/ignite2/2.12.0/release_notes.html) to learn about all of the new features and bug fixes.\\n\\nReach out to us on the community user list for more questions, details, and feedback.\\n\\nSincerely yours,\\n\\nIgnite contributors and committers"},{"id":"/2021/12/21/apache-ignite-2-11-1","metadata":{"permalink":"/blog/2021/12/21/apache-ignite-2-11-1","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2021-12-21-apache-ignite-2-11-1.mdx","source":"@site/blog/2021-12-21-apache-ignite-2-11-1.mdx","title":"Apache Ignite 2.11.1: Emergency Log4j2 Update","description":"The new Apache Ignite 2.11.1 is an emergency release that fixes CVE-2021-44228, CVE-2021-45046, CVE-2021-45105 related to the ignite-log4j2 module usage.","date":"2021-12-21T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"in-memory","permalink":"/blog/tags/in-memory"},{"inline":true,"label":"log4j2","permalink":"/blog/tags/log-4-j-2"},{"inline":true,"label":"open-source","permalink":"/blog/tags/open-source"},{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":2.14,"hasTruncateMarker":true,"authors":[{"name":"Maxim Muzafarov","title":"Apache Ignite Committer","url":"https://github.com/mmuzaf","imageURL":"https://github.com/mmuzaf.png","key":"maxim","page":null}],"frontMatter":{"title":"Apache Ignite 2.11.1: Emergency Log4j2 Update","authors":["maxim"],"date":"2021-12-21T00:00:00.000Z","tags":["database","ignite","in-memory","log4j2","open-source","release","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.12.0: CDC, Index Query API, Vulnerabilities Fixes","permalink":"/blog/2022/01/14/apache-ignite-2-12-0"},"nextItem":{"title":"Apache Ignite 2.11: Stabilization First","permalink":"/blog/2021/09/20/apache-ignite-2-11-stabilization"}},"content":"The new [Apache Ignite](https://ignite.apache.org/) 2.11.1 is an emergency release that fixes [CVE-2021-44228](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-44228), [CVE-2021-45046](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-45046), [CVE-2021-45105](https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-45105) related to the ignite-log4j2 module usage.\\n\\n### Apache Ignite with Log4j Vulnerability\\n\\nAll the following conditions must be met:\\n\\n- The Apache Ignite version lower than 2.11.0 is used (since these vulnerabilities are already fixed in 2.11.1, 2.12, and upper versions);\\n- The `ignite-logj42` is used by Apache Ignite and located in the `libs` directory (by default it is located in the `libs/optional` directory, so these deployments are not affected);\\n- The Java version in use is older than the following versions: `8u191`, `11.0.1`. This is due to the fact that later versions set the JVM property `com.sun.jndi.ldap.object.trustURLCodebase` to `false` by default, which disables JNDI loading of classes from arbitrary URL code bases.\\n\\nNOTE: Relying only on the Java version as a protection against these vulnerabilities is very risky and has not been tested.\\n\\n\x3c!--truncate--\x3e\\n\\n### Risk Mitigation Without Upgrading\\n\\nPlease note that all of these cases require a cluster downtime, but we still recommend to upgrade the Apache Ignite.\\n\\n#### Method 1: Removing the Vulnerable Classes\\n\\nWhen using an older Apache Ignite version, it is possible to remove the JndiLookup class from any Java application by executing this command:\\n\\n```\\nfind $IGNITE_HOME/ -type f -name \\"*log4j-core-*.jar\\" -exec zip -q -d \\"{}\\" org/apache/logging/log4j/core/lookup/JndiLookup.class \\\\;\\n```\\n\\nThis will recursively find all log4j-core JAR files, starting from the `IGNITE_HOME` directory, and remove the vulnerable JndiLookup class from them.\\n\\n#### Method 2: Disabling Message Lookups\\n\\nThis method can be used as an additional protection layer in case you suspect not all log4j dependencies have been properly updated. If you are using the Apache Ignite of an older version, we recommend to disable message lookups globally by setting the environment variable `LOG4J_FORMAT_MSG_NO_LOOKUPS` to `true` or, alternatively, run the Apache Ignite with the `-Dlog4j2.formatMsgNoLookups=true` command-line option.\\n\\n#### Method 3: Replace log4j2 Dependency Manually\\n\\nIt is still possible to manually replace the Log4j of 2.x version in the Apache Ignite binary distribution to the 2.17.0 Log4j version if your log configuration does not imply to use the RoutingAppender. In case the RoutingAppender is used it may produce some error messages in a log file at the startup or empty lines during the execution, which are considered as a minor flow, however, we do not recommend this mitigation method in this case."},{"id":"/2021/09/20/apache-ignite-2-11-stabilization","metadata":{"permalink":"/blog/2021/09/20/apache-ignite-2-11-stabilization","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2021-09-20-apache-ignite-2-11-stabilization.mdx","source":"@site/blog/2021-09-20-apache-ignite-2-11-stabilization.mdx","title":"Apache Ignite 2.11: Stabilization First","description":"The new Apache Ignite 2.11 was released on September 17, 2021. It can be considered to be a greater extent as a stabilization release that closed a number of technical debts of the internal architecture and bugs. Out of more than 200 completed tasks, 120 are bug fixes. However, some valuable improvements still exist, so let\'s take a quick look at them together.","date":"2021-09-20T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"in-memory","permalink":"/blog/tags/in-memory"},{"inline":true,"label":"open-source","permalink":"/blog/tags/open-source"},{"inline":true,"label":"release","permalink":"/blog/tags/release"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":4.22,"hasTruncateMarker":true,"authors":[{"name":"Maxim Muzafarov","title":"Apache Ignite Committer","url":"https://github.com/mmuzaf","imageURL":"https://github.com/mmuzaf.png","key":"maxim","page":null}],"frontMatter":{"title":"Apache Ignite 2.11: Stabilization First","authors":["maxim"],"date":"2021-09-20T00:00:00.000Z","tags":["database","ignite","in-memory","open-source","release","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.11.1: Emergency Log4j2 Update","permalink":"/blog/2021/12/21/apache-ignite-2-11-1"},"nextItem":{"title":"Apache Ignite Momentum: Highlights from 2020-2021","permalink":"/blog/2021/09/14/apache-ignite-momentum-highlights-from"}},"content":"The new [Apache Ignite](https://ignite.apache.org/) 2.11 was released on September 17, 2021. It can be considered to be a greater extent as a stabilization release that closed a number of technical debts of the internal architecture and bugs. Out of more than 200 completed tasks, 120 are bug fixes. However, some valuable improvements still exist, so let\'s take a quick look at them together.\\n\\n### Thin Clients\\n\\nPartition awareness is enabled by default in the 2.11 release and allows thin clients to send query requests directly to the node that owns the queried data. Without partition awareness, an application executes all queries and operations via a single server node that acts as a proxy for the incoming requests.\\n\\nThe support of [Continuous Queries](https://ignite.apache.org/docs/latest/thin-clients/java-thin-client#cache-entry-listening) added to the java thin client. For the other supported features, you can check the [List of Thin Client Features](https://cwiki.apache.org/confluence/display/IGNITE/Thin+clients+features).\\n\\n\x3c!--truncate--\x3e\\n\\n### Cellular-clusters Deployment\\n\\nThe Apache Ignite internals has the so-called *switch* (a part of Partition Map Exchange) process that is used to perform atomic execution of cluster-wide operations and move a cluster from one consistent state to another, for example, a cache creation/destroy, a node JOIN/LEFT/FAIL operations, snapshot creation, etc. During the switching process, all user transactions are parked for a small period of time which in turn increases the average latency and decreases throughput of the overall cluster.\\n\\nSplitting the cluster into virtual cells containing 4-8 nodes may increase the total cluster performance and minimize the influence of one cell on another in case of node fail events. Such a technique also significantly increases the recovery speed of transactions on cells not affected by failing nodes. The time when transactions are parked also decreases on non-affected cells which in turn decreases the worst latency for the cluster operations overall.\\n\\nFrom now on, you can use the *RendezvousAffinityFunction* affinity function with *ClusterNodeAttributeColocatedBackupFilter* to group nodes into virtual cells. Since the node baseline attributes are used as cell markers the corresponding [BASELINE_NODE_ATTRIBUTES](https://ignite.apache.org/docs/latest/monitoring-metrics/system-views#baseline_node_attributes) system view was added.\\n\\nSee benchmarks below that represent the worst (max) latency, which happens in case of node left/failure/timeout events on broken and alive cells.\\n\\n[![Cellular clusters latency comparison](/img/blog/ec8a7800-01e9-4910-aaa9-0e27ea2d4303.png)](/img/blog/ec8a7800-01e9-4910-aaa9-0e27ea2d4303.png)\\n\\n### New Page Replacement Policies\\n\\nWhen Native Persistence is on and the amount of data, which Ignite stores on the disk, is bigger than the off-heap memory amount allocated for the data region, another page should be evicted from the off-heap to the disk to preload a page from the disk to the completely full off-heap memory. This process is called page replacement. Previously, Apache Ignite used the Random-LRU page replacement algorithm which has a low maintenance cost, but it has many disadvantages and greatly affects the performance when the page replacement is started. On some deployments, administrators even force a cluster restart periodically to avoid page replacement. There are a few new algorithms available from now on:\\n\\n- Segmented-LRU Algorithm\\n- CLOCK Algorithm\\n\\nPage replacement algorithm can be configured by the *PageReplacementMode* property of *DataRegionConfiguration*. By default, the CLOCK algorithm is now used. You can check the [Replacement Policies](https://ignite.apache.org/docs/latest/memory-configuration/replacement-policies) in the documentation for more details.\\n\\n### Snapshot Restore And Check Commands\\n\\n#### Check\\n\\nAll snapshots are fully consistent in terms of concurrent cluster-wide operations as well as ongoing changes with Ignite. However, in some cases and for your own peace of mind, it may be necessary to check the snapshot for completeness and for data consistency. The Apache Ignite is now delivered with a built-in snapshot consistency check commands that enable you to verify internal data consistency, calculate data partitions hashes and pages checksums, and print out the result if a problem is found. The check command also compares hashes calculated by containing keys of primary partitions with corresponding backup partitions and reports any differences.\\n\\n```\\n# This procedure does not require the cluster to be in the idle state.\\ncontrol.(sh|bat) --snapshot check snapshot_name\\n```\\n\\n#### Restore\\n\\nPreviously, only the manual snapshot restore procedure was available by fully copying persistence data files from the snapshot directory to the Apache Ignite *work* directory. The automatic restore procedure allows you to restore cache groups from a snapshot on an active cluster by using the Java API or command line script (using CLI is recommended). Currently, the restore procedure has several limitations, so please check the documentation pages for details.\\n\\n```\\nStart restoring all user-created cache groups from the snapshot \\"snapshot_09062021\\".\\ncontrol.(sh|bat) --snapshot restore snapshot_09062021 --start\\n\\n# Start restoring only \\"cache-group1\\" and \\"cache-group2\\" from the snapshot \\"snapshot_09062021\\".\\ncontrol.(sh|bat) --snapshot restore snapshot_09062021 --start cache-group1,cache-group2\\n\\n# Get the status of the restore operation for \\"snapshot_09062021\\".\\ncontrol.(sh|bat) --snapshot restore snapshot_09062021 --status\\n\\n# Cancel the restore operation for \\"snapshot_09062021\\".\\ncontrol.(sh|bat) --snapshot restore snapshot_09062021 --cancel\\n```"},{"id":"/2021/09/14/apache-ignite-momentum-highlights-from","metadata":{"permalink":"/blog/2021/09/14/apache-ignite-momentum-highlights-from","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2021-09-14-apache-ignite-momentum-highlights-from.mdx","source":"@site/blog/2021-09-14-apache-ignite-momentum-highlights-from.mdx","title":"Apache Ignite Momentum: Highlights from 2020-2021","description":"When Apache Ignite entered the Apache Software Foundation (ASF) Incubator in 2014, it took less than a year for the project and its community to graduate from the Incubator and become a top-level project for the ASF. Since then, Ignite has experienced a significant and steady growth in popularity, and it has been used by thousands of application developers and architects to create high-performance and scalable applications used by millions of people daily. In this article, we\'ll recap the achievements of Ignite in 2020-2021.","date":"2021-09-14T00:00:00.000Z","tags":[{"inline":true,"label":"bigdata","permalink":"/blog/tags/bigdata"},{"inline":true,"label":"computing","permalink":"/blog/tags/computing"},{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"in-memory","permalink":"/blog/tags/in-memory"},{"inline":true,"label":"open","permalink":"/blog/tags/open"},{"inline":true,"label":"source","permalink":"/blog/tags/source"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":3.92,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite Momentum: Highlights from 2020-2021","authors":["denis"],"date":"2021-09-14T00:00:00.000Z","tags":["bigdata","computing","database","ignite","in-memory","open","source","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.11: Stabilization First","permalink":"/blog/2021/09/20/apache-ignite-2-11-stabilization"},"nextItem":{"title":"Apache Ignite 2.10: Thin Client Expansion","permalink":"/blog/2021/03/18/apache-ignite-2-10-thin"}},"content":"When Apache Ignite entered the Apache Software Foundation (ASF) Incubator in 2014, it took less than a year for the project and its community to graduate from the Incubator and become a top-level project for the ASF. Since then, Ignite has experienced a significant and steady growth in popularity, and it has been used by thousands of application developers and architects to create high-performance and scalable applications used by millions of people daily. In this article, we\'ll recap the achievements of Ignite in 2020-2021.\\n\\n### Ignite is Ranked as a Top 5 Project\\n\\nThe ASF has ranked Apache ignite as a Top 5 project in various categories since 2017. [That year](https://blogs.apache.org/foundation/entry/apache-in-2017-by-the), Ignite was in the Top 5 of Apache Project Repositories by Commits and most active Apache mailing lists. [Today](https://www.apache.org/foundation/docs/FY2021AnnualReport.pdf), the momentum continues, and Ignite continues to be ranked as a Top 5 project in multiple categories: second on the Top 5 big data user lists, third on the Top 5 big data dev lists, second on the Top 5 of all user lists, third on the Top 5 repos by size.\\n\\n[![Apache Ignite Rankings](/img/blog/463ae37d-866d-4c15-8ebf-6b88499daa81.jpeg)](/img/blog/463ae37d-866d-4c15-8ebf-6b88499daa81.jpeg)\\n\\n\x3c!--truncate--\x3e\\n\\nOf greatest significance, the continued Top 5 ranking on the \\"dev list\\" reflects an active community of contributors who are committed to keeping the code base growing, while the Top 5 ranking on the \\"user list\\" means that more and more Ignite application developers come to the community to ask questions, indicating continued growth in adoption.\\n\\n### The Worldwide Ignite community is Engaged\\n\\nThis broad and growing interest in Apache Ignite has continued over the last year and a half. However, faced with the pandemic and shelter-in-place orders around the world, the community sought ways to stay in touch and continue sharing experiences. The community naturally turned to a virtual format and established two new successful programs.\\n\\nThe first was a series of [Ignite Virtual Meetups](https://www.meetup.com/Apache-Ignite-Virtual-Meetup/events/past/), where Apache Ignite users, developers, committers, contributors and architects worldwide could share experiences on a wide range of topics, ask questions, and help drive the project forward. Since these virtual meetups began, the community has already held 17 events, which were attended by hundreds of community members and developers.\\n\\nThe second new program was launched this May with the virtual [Ignite Summit](https://ignite-summit.org/2021/), the first global conference designed for the entire Ignite community. [Twenty-five speakers from industry-leading companies](https://www.youtube.com/playlist?list=PLMc7NR20hA-KF8c_hVICKpzKnWkjzfC2V) including finance, biotech, health & fitness, construction and cloud computing led 15 hours of discussion about how Apache Ignite delivers the performance and scale required to address the world\'s most challenging computational and hybrid transactional/analytical processing requirements. The Summit had attendees from North America, Latin America, EMEA and APAC. Remarkably, attendees spent an average of nearly 5 hours at the event!\\n\\n### Innovation Continues at a Rapid Pace\\n\\nOver the last year and a half, the community has released [five new versions of Ignite 2.x](https://ignite.apache.org/download). The releases introduce numerous improvements and optimizations, including major features, such as new monitoring and profiling frameworks, cluster snapshots, encoding keys rotation for transparent data encryption, and more.\\n\\nThe community also put significant effort into contributing and releasing [new documentation](https://ignite.apache.org/docs/), which is now hosted on the Ignite website. Since the new documentation was posted, it has become the most visited resource on the website, a clear indication that it is helping Ignite developers make faster, easier progress on their Ignite development and optimization tasks.\\n\\nFurther, Igniters have begun working on the next major release, Ignite 3.0, which introduces significant usability improvements, a new SQL engine based on Apache Calcite, a Raft-based consistency protocol, and many other improvements. Users can already try the first two Alpha versions:\\n\\n- [Alpha 1 Overview](https://www.gridgain.com/resources/blog/ignite-3-alpha-sneak-peek-future-apache-ignite)\\n- [Alpha 2 Overview](https://www.gridgain.com/resources/blog/just-released-apache-ignite-3-alpha-2)\\n\\n### The payoff: Ignite Downloads Continue to Soar\\n\\nThe inherent benefits of Apache Ignite, combined with all the effort of a dedicated community, has resulted in a popular project that continues to see increasing adoption. Ignite Maven monthly downloads are skyrocketing, and we have seen a 65% year-over-year growth in downloads so far in 2021, resulting in hundreds of thousands of downloads each month.\\n\\nWe eagerly look forward to the full release of Apache ignite 3.0 and fully expect downloads, adoption and community enthusiasm to continue to soar. Good luck to the Ignite community!"},{"id":"/2021/03/18/apache-ignite-2-10-thin","metadata":{"permalink":"/blog/2021/03/18/apache-ignite-2-10-thin","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2021-03-18-apache-ignite-2-10-thin.mdx","source":"@site/blog/2021-03-18-apache-ignite-2-10-thin.mdx","title":"Apache Ignite 2.10: Thin Client Expansion","description":"As of March 15, 2021, Apache Ignite 2.10 has been released. You can directly check the full list of resolved Important JIRA\'s but here let\'s briefly overview some valuable improvements.","date":"2021-03-18T00:00:00.000Z","tags":[{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":3.11,"hasTruncateMarker":true,"authors":[{"name":"Maxim Muzafarov","title":"Apache Ignite Committer","url":"https://github.com/mmuzaf","imageURL":"https://github.com/mmuzaf.png","key":"maxim","page":null}],"frontMatter":{"title":"Apache Ignite 2.10: Thin Client Expansion","authors":["maxim"],"date":"2021-03-18T00:00:00.000Z","tags":["ignite","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite Momentum: Highlights from 2020-2021","permalink":"/blog/2021/09/14/apache-ignite-momentum-highlights-from"},"nextItem":{"title":"Apache Ignite 2.9 Released: Cluster snapshots and tracing","permalink":"/blog/2020/11/05/apache-ignite-2-9-released"}},"content":"As of March 15, 2021, [Apache Ignite](https://ignite.apache.org/) 2.10 has been released. You can directly check the full list of resolved [Important JIRA\'s](https://s.apache.org/i3ny6) but here let\'s briefly overview some valuable improvements.\\n\\n### Thin Clients\\n\\nThin clients now support several important features which, previously were available only on the thick clients. Thin clients are always backward and forward compatible with the server nodes of the cluster, so the cluster upgrade process will be more convenient if the lack of these features prevented you from doing that.\\n\\nSee the list of what is changed for thin clients below:\\n\\n- Transactions\\n- Service invocations\\n- Continuous Queries\\n- SQL API\\n- Cluster API\\n- Cache Async API\\n- Kubernetes Discovery (*ThinClientKubernetesAddressFinder*)\\n\\nYou may check the [List of Thin Client Features](https://cwiki.apache.org/confluence/display/IGNITE/Thin+clients+features) that supported by platforms you are interested in or see the [What\'s new in Apache Ignite.NET 2.10](https://ptupitsyn.github.io/Whats-New-In-Ignite-Net-2.10/).\\n\\n\x3c!--truncate--\x3e\\n\\n### Cluster Monitoring\\n\\nApache Ignite self-monitoring and cluster health check subsystems are also extended by additional SQL-views and command line scripts.\\n\\n#### New *control-script* Commands\\n\\nQuery any of the available system views.\\n\\n```\\ncontrol.sh --system-view views\\nCommand [SYSTEM-VIEW] started\\n--------------------------------------------------------------------------------\\nname                           schema    description\\nSQL_QUERIES_HISTORY            SYS       SQL queries history.\\nINDEXES                        SYS       SQL indexes\\nBASELINE_NODES                 SYS       Baseline topology nodes\\nSTRIPED_THREADPOOL_QUEUE       SYS       Striped thread pool task queue\\nSCAN_QUERIES                   SYS       Scan queries\\nPARTITION_STATES               SYS       Distribution of cache group partitions across cluster nodes\\n\\nCommand [SYSTEM-VIEW] finished with code: 0\\n--------------------------------------------------------------------------------\\n```\\n\\nQuery any of the available system metrics.\\n\\n```\\ncontrol.sh --metric sysCurrentThreadCpuTime\\nCommand [METRIC] started\\n--------------------------------------------------------------------------------\\nmetric                          value\\nsys.CurrentThreadCpuTime        17270000\\nCommand [METRIC] finished with code: 0\\n--------------------------------------------------------------------------------\\n```\\n\\n[Read More](https://ignite.apache.org/docs/latest/tools/control-script)\\n\\n#### Managing Ignite System Properties\\n\\nIn addition to basic cluster configuration settings, you can perform some low-level cluster configuration and tuning via Ignite system properties. Run the command below to see the list of all available system properties for configuration:\\n\\n```\\n$./ ignite.sh -systemProps\\n\\n--------------------------------------------------------------------------------\\nIGNITE_AFFINITY_HISTORY_SIZE           - [Integer] Maximum size for affinity assignment history. Default is 25.\\nIGNITE_ALLOW_ATOMIC_OPS_IN_TX          - [Boolean] Allows atomic operations inside transactions. Default is true.\\nIGNITE_ALLOW_START_CACHES_IN_PARALLEL  - [Boolean] Allows to start multiple caches in parallel. Default is true.\\n```\\n\\n[Read more](https://ignite.apache.org/docs/latest/setup#setting-ignite-system-properties)\\n\\n### Cluster Profiling\\n\\nFrom now on, Apache Ignite is delivered with the cluster profiling tool. This tool collects and processes all cluster internal information about Queries, Compute Tasks, Cache operations, Checkpoint and WAL statistics, and so on for problem detection and cluster self-tuning purposes. Each cluster node collects performance statistics into a special binary file that is placed under the `[IGINTE_WORK_DIR]/perf_stat/` directory with the template filename as `node-[nodeId]-[index].prf`. All these files are consumed by offline-tool that builds the report in a human-readable format.\\n\\n[Read More](https://ignite.apache.org/docs/latest/monitoring-metrics/performance-statistics)\\n\\n![transactions statistics](/img/blog/d445a88f-98d1-4a6e-b4d8-037e819ca91f.png)\\n\\n### Transparent Data Encryption - Cache Key Rotation\\n\\nPayment card industry data security standard (PCI DSS) requires that key-management procedures include a predefined crypto period for each key in use and define a process for key changes at the end of the defined crypto period. An expired key should not be used to encrypt new data, but it can be used for archived data, such keys should be strongly protected (section 3.5 - 3.6 of PCI DSS Requirements and Security Assessment Procedures).\\n\\nApache Ignite now supports full PCI DSS requirements:\\n\\n- *Transparent Data Encryption* available since the 2.7 release.\\n- *Master Key Rotation* procedure available since the 2.9 release.\\n- *Cache Key Rotation* procedure available since the 2.10 release.\\n\\nYou may use the CLI tools that provide the ability to change the re-encryption rate as well as suspend and resume background re-encryption at runtime.\\n\\n[Read More](https://ignite.apache.org/docs/latest/security/cache-encryption-key-rotation)"},{"id":"/2020/11/05/apache-ignite-2-9-released","metadata":{"permalink":"/blog/2020/11/05/apache-ignite-2-9-released","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2020-11-05-apache-ignite-2-9-released.mdx","source":"@site/blog/2020-11-05-apache-ignite-2-9-released.mdx","title":"Apache Ignite 2.9 Released: Cluster snapshots and tracing","description":"As of October 23, 2020, Apache Ignite 2.9 is available. Like every other Ignite release, release 2.9 includes many changes. Let\'s take a look at the major features of release 2.9.","date":"2020-11-05T00:00:00.000Z","tags":[{"inline":true,"label":"two","permalink":"/blog/tags/two"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":1.54,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 2.9 Released: Cluster snapshots and tracing","authors":["denis"],"date":"2020-11-05T00:00:00.000Z","tags":["two","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.10: Thin Client Expansion","permalink":"/blog/2021/03/18/apache-ignite-2-10-thin"},"nextItem":{"title":"Ignite 2.8 Released: Less Stress in Production and Advances in Machine Learning","permalink":"/blog/2020/03/11/ignite-2-8-released-less"}},"content":"As of October 23, 2020, Apache Ignite 2.9 is available. Like every other Ignite release, release 2.9 includes many changes. Let\'s take a look at the major features of release 2.9.\\n\\n### Cluster Snapshots\\n\\nIgnite 2.9 provides the ability to create full cluster snapshots for deployments that use Ignite Persistence. Snapshots can be taken online, when the cluster is active and accessible to users. An Ignite snapshot includes a cluster-wide copy of all data records that exist at the moment the snapshot is started. All snapshots are consistent, in terms of concurrent, cluster-wide operations as well as in terms of ongoing changes in Ignite Persistence data, index, schema, binary metadata, marshaller, and other files on nodes. See [Ignite documentation](https://ignite.apache.org/docs/latest/persistence/snapshots) to learn about this feature.\\n\\n\x3c!--truncate--\x3e\\n\\n### Tracing\\n\\nThe Ignite monitoring system continues to improve. In Ignite 2.9, a new tracing subsystem became available. Tracing provides information that is useful for debugging, that helps with both regular, daily, basic system monitoring and with incident analysis. You can collect distributed traces of tasks that are executed in your cluster and use this information to diagnose latency problems. In the 2.9 release, the following Ignite components are instrumented for tracing:\\n\\n- Discovery\\n- Communication\\n- Exchange\\n- Transactions\\n\\nSee [the documentation](https://ignite.apache.org/docs/latest/monitoring-metrics/tracing) for more information.\\n\\n### Other Changes\\n\\nIn addition to snapshots and tracing, Ignite 2.9 provides the following new features:\\n\\n- Cluster discovery, cluster API, compute API, and service invocation support for thin clients (Java and .Net)\\n- Cluster-wide, read-only mode\\n- Ability to run user-defined code inside the Ignite sandbox\\n- Transparent data encryption: master key rotation\\n- Management tools to cancel user tasks and queries\\n- Platform cache (.Net)\\n\\nSee the [release notes](https://ignite.apache.org/releases/ignite2/2.9.0/release_notes.html) to learn about all of the new features.\\n\\nSincerely yours,\\nIgnite contributors and committers"},{"id":"/2020/03/11/ignite-2-8-released-less","metadata":{"permalink":"/blog/2020/03/11/ignite-2-8-released-less","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2020-03-11-ignite-2-8-released-less.mdx","source":"@site/blog/2020-03-11-ignite-2-8-released-less.mdx","title":"Ignite 2.8 Released: Less Stress in Production and Advances in Machine Learning","description":"With thousands of changes contributed to Apache Ignite 2.8 that enhanced almost all the components of the platform, it\'s possible to overlook some of the improvements that can convince you to upgrade to this version sooner than later. While a quick check of the release notes will help to discover anticipated bug fixes, this article aims to guide through enhancements every Ignite developer should be aware of.","date":"2020-03-11T00:00:00.000Z","tags":[{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"in-memory","permalink":"/blog/tags/in-memory"},{"inline":true,"label":"learning","permalink":"/blog/tags/learning"},{"inline":true,"label":"machine","permalink":"/blog/tags/machine"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":5.04,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Ignite 2.8 Released: Less Stress in Production and Advances in Machine Learning","authors":["denis"],"date":"2020-03-11T00:00:00.000Z","tags":["database","ignite","in-memory","learning","machine","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.9 Released: Cluster snapshots and tracing","permalink":"/blog/2020/11/05/apache-ignite-2-9-released"},"nextItem":{"title":"Apache Ignite 2.7: Deep Learning and Extended Languages Support","permalink":"/blog/2018/12/13/apache-ignite-2-7-deep"}},"content":"With thousands of changes contributed to Apache Ignite 2.8 that enhanced almost all the components of the platform, it\'s possible to overlook some of the improvements that can convince you to upgrade to this version sooner than later. While a quick check of the [release notes](https://ignite.apache.org/releases/ignite2/2.8.0/release_notes.html) will help to discover anticipated bug fixes, this article aims to guide through enhancements every Ignite developer should be aware of.\\n\\n### New Subsystem for Production Monitoring and Tracing\\n\\nSeveral months of constant work on [IEP-35: Monitoring & Profiling](https://cwiki.apache.org/confluence/pages/viewpage.action?pageId=112820392) has resulted in the creation of a robust and elastic subsystem for production monitoring and diagnostic (aka. profiling). This was influenced by the needs of many developers who deployed Ignite in critical environments and were asking for a foundation that can be integrated with many external monitoring tools and be expanded easily.\\n\\nThe [new subsystem](https://apacheignite.readme.io/docs/new-metrics#section-exporters) consists of several registries that group individual metrics related to a specific Ignite component. For instance, you will find registries for cache, compute, or service grid APIs. Since the registries are designed to be generic, specific exporters can observe the state of Ignite via a myriad of tools supporting various protocols. By default, Ignite 2.8 introduces exporters for monitoring interfaces such as log files, JMX and SQL views, and contemporary ones such as OpenCensus.\\n\\n\x3c!--truncate--\x3e\\n\\nPresently, this new subsystem is released in an experimental mode only to give Ignite users some time to check the new API and suggest any improvements. Since the developer community is already impatient to remove the experimental flag, don\'t delay!\\n\\n### Advances in Ignite Machine Learning\\n\\nMachine Learning (ML) capabilities of Ignite 2.8 are so drastically different from previous versions that if you\'ve been waiting for the best moment to use the API, then the time has come. Let\'s scratch the surface here and learn more details from the updated documentation pages.\\n\\nA model training is usually a multi-step process that goes with preprocessing, training, and evaluation/valuation phases. A new [pipelining API](https://apacheignite.readme.io/docs/evaluation) puts things in order by combining all the phases in a single workflow.\\n\\nIn addition to the pipelining APIs, Ignite 2.8 introduced [ensemble methods](https://apacheignite.readme.io/docs/ensemble-methods), which allow combining several machine learning techniques into one predictive model to decrease variance (bagging) and bias (boosting), or improve predictions (stacking).\\n\\nFurthermore, now you can import [Apache Spark or XGBoost models](https://apacheignite.readme.io/docs/model-importing) to Ignite for further inference, pipelining other tasks. Feel free to keep training a model with your favorite framework and convert it to Ignite representation once the model needs to be deployed in production and executed at scale.\\n\\n### Beyond Java: Partition-Awareness and Other Changes\\n\\nEven though Ignite is a Java middleware, it functions as a cross-platform database and compute platform that is used for applications developed in C#, C++, Python, and other programming languages.\\n\\nThin client protocol is a real enabler for other programming languages support, and with Ignite 2.8, it got a significant performance optimization by supporting [partition-awareness](https://apacheignite-net.readme.io/docs/thin-client#section-partition-awareness). The latter allows thin clients to send query requests directly to nodes that own the queried data. Without partition awareness, an application that is connected to the cluster via a thin client executes all queries and operations via a single server node that acts as a proxy for the incoming requests.\\n\\nCheck the [detailed blog](https://ptupitsyn.github.io/Whats-New-In-Ignite-Net-2.8/) post by Pavel Tupitsyn, Ignite committer and PMC, who elaborates on the partition-awareness feature and introduces other .NET-specific enhancements.\\n\\n### Less Stress in Production\\n\\nThis section lists top improvements that might not have striking or catchy names but can bring relief by automating and optimizing things, and by avoiding data inconsistencies when you are already in production.\\n\\nThe stop-the-world pauses triggered by Java garbage collectors impact performance, responsiveness, and throughput of our Java applications. Apache Ignite has a partition-map-exchange (PME) process that, as Java garbage collectors, has some phases that put on hold all running operations for the sake of cluster-wide consistency. For most of the Ignite usage scenarios, these phases complete promptly and are unnoticed. However, some low-latency or high-throughput use cases can detect a decline that might impact some business operations for a moment in time. [This wiki page](https://cwiki.apache.org/confluence/display/IGNITE/%28Partition+Map%29+Exchange+-+under+the+hood) lists all the conditions that can trigger a distributed PME, and with Ignite 2.8, some of them were taken off the list -- the blocking PME no longer happens if a node belonging to the current baseline topology leaves the cluster or a thick client connects to it.\\n\\nNext, we all know that things break, and what really matters is how a system handles failures. With Ignite 2.8, we revisited the way the cluster handles crash recoveries on restarts while replaying write-ahead-logs (check [IGNITE-7196](https://issues.apache.org/jira/browse/IGNITE-7196) and [IGNITE-9420](https://issues.apache.org/jira/browse/IGNITE-9420)). Also, the [read-repair feature](https://apacheignite.readme.io/docs/read-repair) was added to manage data inconsistencies between primary and backups copies of the cluster on-the-fly.\\n\\nFurthermore, it\'s worth mentioning that Ignite 2.8 became more prudent about disk space consumption by supporting the compaction of data files and write-ahead-logs of the native persistence. By sacrificing a bit more CPU cycles for the needs of [compaction algorithms](https://ignite.apache.org/releases/ignite2/2.8.0/javadoc/org/apache/ignite/configuration/DiskPageCompression.html), you can save a lot on the storage end.\\n\\nLast but not least, is an [auto-baseline](https://apacheignite.readme.io/docs/baseline-topology#section-baseline-topology-autoadjustment) feature that changes a cluster topology for deployments with Ignite native persistence without the need for your intervention in many scenarios. Check this documentation page for more details.\\n\\nReach out to us on the community user list for more questions, details, and feedback.\\n\\nSincerely yours,\\nIgnite contributors and committers"},{"id":"/2018/12/13/apache-ignite-2-7-deep","metadata":{"permalink":"/blog/2018/12/13/apache-ignite-2-7-deep","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2018-12-13-apache-ignite-2-7-deep.mdx","source":"@site/blog/2018-12-13-apache-ignite-2-7-deep.mdx","title":"Apache Ignite 2.7: Deep Learning and Extended Languages Support","description":"Deep Learning With TensorFlow","date":"2018-12-13T00:00:00.000Z","tags":[{"inline":true,"label":"two","permalink":"/blog/tags/two"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":2.12,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 2.7: Deep Learning and Extended Languages Support","authors":["denis"],"date":"2018-12-13T00:00:00.000Z","tags":["two","archived"]},"unlisted":false,"prevItem":{"title":"Ignite 2.8 Released: Less Stress in Production and Advances in Machine Learning","permalink":"/blog/2020/03/11/ignite-2-8-released-less"},"nextItem":{"title":"Apache Ignite 2.5: Scaling to 1000s Nodes Clusters","permalink":"/blog/2018/05/31/apache-ignite-2-5-scaling"}},"content":"### Deep Learning With TensorFlow\\n\\nEven though it was natural to provide machine learning algorithms in Ignite out of the box, another direction was taken for deep learning capabilities. Primarily because machine learning approaches have already been adopted in businesses from big to small, while deep learning is still being used for narrow and specific use cases.\\n\\nThus, Ignite 2.7 can boast about an [official integration](https://ignite.apache.org/features/tensorflow.html) with TensorFlow deep learning framework that gives a way to use Ignite as a distributed storage for TensorFlow calculations. With Ignite, data scientists can store unlimited data sets across a cluster, gain performance improvements and rely on fault-tolerance of both products if an algorithm fails in the middle of an execution.\\n\\n\x3c!--truncate--\x3e\\n\\n### Extended Languages Support - Node.JS, Python, PHP\\n\\nJava, .NET and C++ have been extensively supported by Ignite for a while now. But until now, when it came to other languages, developers had to fall back to REST, JDBC/ODBC calls. To address the limitation of missing native APIs for programming languages different from the three above, the community released a low-level binary protocol used to build thin clients. A thin client is a lightweight Ignite client that connects to the cluster via a standard socket connection.\\n\\nBased on this protocol, Ignite 2.7 adds support for [Node.JS, Python and PHP](https://apacheignite.readme.io/docs/thin-clients). As for Java, .NET and C++, you can leverage from thin clients, as well, if the regular clients are not suitable for some reason.\\n\\n### Transparent Data Encryption\\n\\nFor those of you who are using Ignite persistence in production, this functionality brings peace of mind. Whether you store any sensitive information or an entire data set has to be encrypted due to regulations, this feature is what you need. Check [this page](https://apacheignite.readme.io/docs/transparent-data-encryption) for more details.\\n\\n### Transactional SQL Beta\\n\\nLast, but probably the most anticipated addition to Ignite, is fully transactional SQL. You\'re no longer limited to key-value APIs if an application needs to run ACID-compliant distributed transactions. Prefer SQL? Use SQL! Yes, it\'s still in beta and might not yet be the best fit for mission-critical deployments, but definitely try it in your development cycles and share your feedback. It took us several years to reach this milestone and before GA release comes out, we want to hear what you think.\\n\\nFinally, I have no more paper left to cover other optimizations and improvements. So, go ahead and check out our [release notes](https://ignite.apache.org/releases/ignite2/2.7.0/release_notes.html)."},{"id":"/2018/05/31/apache-ignite-2-5-scaling","metadata":{"permalink":"/blog/2018/05/31/apache-ignite-2-5-scaling","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2018-05-31-apache-ignite-2-5-scaling.mdx","source":"@site/blog/2018-05-31-apache-ignite-2-5-scaling.mdx","title":"Apache Ignite 2.5: Scaling to 1000s Nodes Clusters","description":"Apache Ignite was always appreciated by its users for two primary things it delivers - scalability and performance. Throughout the lifetime many distributed systems tend to do performance optimizations from a release to release while making scalability related improvements just a couple of times. It\'s not because the scalability is of no interest. Usually, scalability requirements are set and solved once by a distributed system and don\'t require significant additional interventions by engineers.","date":"2018-05-31T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"spark","permalink":"/blog/tags/spark"},{"inline":true,"label":"sql","permalink":"/blog/tags/sql"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":5.29,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 2.5: Scaling to 1000s Nodes Clusters","authors":["denis"],"date":"2018-05-31T00:00:00.000Z","tags":["apache","database","ignite","spark","sql","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.7: Deep Learning and Extended Languages Support","permalink":"/blog/2018/12/13/apache-ignite-2-7-deep"},"nextItem":{"title":"Apache Ignite 2.4 Brings Advanced Machine Learning and Spark DataFrames Capabilities","permalink":"/blog/2018/03/15/apache-ignite-2-4-brings"}},"content":"Apache Ignite was always appreciated by its users for two primary things it delivers - scalability and performance. Throughout the lifetime many distributed systems tend to do performance optimizations from a release to release while making scalability related improvements just a couple of times. It\'s not because the scalability is of no interest. Usually, scalability requirements are set and solved once by a distributed system and don\'t require significant additional interventions by engineers.\\n\\nHowever, Apache Ignite grew to the point when the community decided to revisit its discovery subsystem that influences how well and far Ignite scales out. The goal was pretty clear - Ignite has to scale to 1000s of nodes as good as it scales to 100s now.\\n\\nIt took many months to get the task implemented. So, please join me in welcoming Apache Ignite 2.5 that now can be scaled easily to 1000s of nodes and goes with other exciting capabilities. Let\'s check out the most prominent ones.\\n\\n\x3c!--truncate--\x3e\\n\\n### Massive Scalability\\n\\nThere are two components of Ignite that were modified in Ignite 2.5 to improve its scalability capabilities. The first one is related to 1000s nodes clusters while the other is related to the way we train machine learning (ML) models in Ignite. Let\'s start with the first.\\n\\n#### Marrying Apache Ignite and ZooKeeper\\n\\nRight, that 1000s nodes scalability goal was solved with the help of Apache ZooKeeper. Why did we turn to it?\\n\\nApache Ignite default TCP/IP Discovery organizes cluster nodes into a ring-topology form that has its advantages and disadvantages. For instance, on topologies with hundreds of cluster nodes, it can take many seconds why a system message traverse through all the nodes. As a result, necessary processing of events such as joining of new nodes or detecting of failed ones can take a while affecting overall cluster responsiveness and performance. That is a big deal if you\'d like to run 1000s nodes clusters.\\n\\nThe new ZooKeeper Discovery uses ZooKeeper as a single point of synchronization where Ignite nodes are exchanging discovery events through it. It solved the issue with long-to-be-processed discovery messages and, as a result, allowed Ignite scaling to large cluster topologies.\\n\\n[![ZooKeeper Discovery](/img/blog/4b80632d-232d-4e4f-bd5e-9d91f0bc550f.png)](https://apacheignite.readme.io/docs/zookeeper-discovery)\\n\\nAs a rule of thumb, keep using default [TCP/IP Discovery](https://apacheignite.readme.io/docs/tcpip-discovery) if it\'s unlikely that your Ignite cluster scales beyond 300s nodes and switch to [ZooKeeper Discovery](https://apacheignite.readme.io/docs/zookeeper-discovery) if that\'s the case.\\n\\n#### Machine Learning: Partition-Based Datasets\\n\\nThat\'s the second prominent feature of Ignite 2.5 that improves the way of how far you can scale your Ignite clusters to train ML models over terabytes or petabytes of data. The [partition-based datasets](https://apacheignite.readme.io/docs/ml-partition-based-dataset) moved us closer to the implementation of Zero-ETL concept which implies that Ignite can be used as a single storage where ML models and algorithms are being improved iteratively and online without ETLing data back and forth between Ignite and another storage.\\n\\nRead more about the datasets from [this](https://apacheignite.readme.io/docs/ml-partition-based-dataset) documentation page.\\n\\n### Genetic Algorithms\\n\\nIgnite\'s ML component is ramping up and in the version 2.5 it accepted a contribution of genetic algorithms (GAs) which help to solve optimization problems by simulating the process of biological evolution. GAs are excellent for searching through large and complex data sets for an optimal solution. Real world applications of GAs include automotive design, computer gaming, robotics, investments, traffic/shipment routing and more.\\n\\nRefer to excessive articles of my community-mates Turik Campbell and Akmal B. Chaudhri which cover main benefits of GAs:\\n\\n- [Travel Like MacGyver: Solve Knapsack Problem with GA Grid](https://www.linkedin.com/pulse/travel-like-macgyver-solve-knapsack-problem-ga-grid-turik-campbell/)\\n- [Genetic Algorithms with Apache Ignite](https://www.gridgain.com/resources/blog/genetic-algorithms-apacher-ignitetm)\\n\\n### Continuous Self-Healing and Consistency Checks\\n\\nIt\'s a known fact that many companies and businesses trusted Ignite its mission-critical deployments and solutions. As a result, sometimes Ignite doesn\'t even have a right to \\"misfire\\" and should be able to handle critical or unpredictable situations automatically or provide facilities to do deal with them manually.\\n\\nWith Ignite 2.5, we\'ve kicked off the realization of continuous self-healing concept that implies that no matter what happens with Ignite in production it should be able to tolerate unexpected failures and stay up and running. The following was done in 2.5:\\n\\n- [Critical Failures Handling](https://apacheignite.readme.io/docs/critical-failures-handling)\\n- [Long running transactions monitoring and termination](https://apacheignite.readme.io/docs/transactions#section-long-running-transactions-termination)\\n- [Data Consistency Check Facilities](https://apacheignite.readme.io/docs/consistency-check-facilities)\\n\\n### SQL: Security and Fast Data Loading\\n\\nThe community stays strong and determined in its goal of making Ignite SQL engine undistinguishable from SQL engines of famous and mature SQL database. What\'s the purpose? We want to make it easy for you to migrate from a relational database to Ignite, so that you can reuse all your skills gained before. Overall, this is what our SQL engine got in 2.5:\\n\\n- Fast data loading with [COPY](https://apacheignite-sql.readme.io/docs/copy) command and [streaming mode](https://apacheignite-sql.readme.io/docs/jdbc-driver#section-streaming) using SQL APIs.\\n- [Long running transactions monitoring and termination](https://apacheignite.readme.io/docs/transactions#section-long-running-transactions-termination)\\n- Secured Ignite cluster. Use [CREATE USER, DROP USER and ALTER USER](https://apacheignite-sql.readme.io/docs/ddl) commands to manage who is allowed to connect to your clusters.\\n\\n### In-place Execution of Spark DataFrame Queries\\n\\nApache Spark users can applaud because the [following ticket](https://issues.apache.org/jira/browse/IGNITE-7077) got merged in 2.5. In short, it means that from now on Ignite will be able to execute as many DataFrames SQL queries as it can in-place on Ignite servers side avoiding data movement from Ignite to Spark. The performance of your DataFrames queries should boost significantly. Enjoy!\\n\\n### DEB and RPM packages\\n\\nLast but not least, if you\'re a Linux user, now you can install the latest Ignite versions directly from DEB and RPM repositories. Refer to [how-to](https://apacheignite.readme.io/docs/getting-started#section-rpm-deb-packages-installation) and share your feedback with us.\\n\\nFinally, I have no more paper left to cover other optimizations and improvements. So, go ahead and check out our [release notes](https://ignite.apache.org/releases/ignite2/2.5.0/release_notes.html)."},{"id":"/2018/03/15/apache-ignite-2-4-brings","metadata":{"permalink":"/blog/2018/03/15/apache-ignite-2-4-brings","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2018-03-15-apache-ignite-2-4-brings.mdx","source":"@site/blog/2018-03-15-apache-ignite-2-4-brings.mdx","title":"Apache Ignite 2.4 Brings Advanced Machine Learning and Spark DataFrames Capabilities","description":"Usually, Ignite community rolls out a new version once in 3 months, but we had to make an exception for Apache Ignite 2.4 that consumed five months in total. We could easily blame Thanksgiving, Christmas and New Year holidays for the delay and would be forgiven, but, in fact, we were forging the release you can\'t simply pass by.","date":"2018-03-15T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"bigdata","permalink":"/blog/tags/bigdata"},{"inline":true,"label":"data","permalink":"/blog/tags/data"},{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"fast","permalink":"/blog/tags/fast"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"learning","permalink":"/blog/tags/learning"},{"inline":true,"label":"machine","permalink":"/blog/tags/machine"},{"inline":true,"label":"nodal","permalink":"/blog/tags/nodal"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":3.09,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 2.4 Brings Advanced Machine Learning and Spark DataFrames Capabilities","authors":["denis"],"date":"2018-03-15T00:00:00.000Z","tags":["apache","bigdata","data","database","fast","ignite","learning","machine","nodal","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.5: Scaling to 1000s Nodes Clusters","permalink":"/blog/2018/05/31/apache-ignite-2-5-scaling"},"nextItem":{"title":"Meltdown and Spectre patches show negligible impact to Apache Ignite performance","permalink":"/blog/2018/01/30/meltdown-and-spectre-patches-show"}},"content":"Usually, Ignite community rolls out a new version once in 3 months, but we had to make an exception for Apache Ignite 2.4 that consumed five months in total. We could easily blame Thanksgiving, Christmas and New Year holidays for the delay and would be forgiven, but, in fact, we were forging the release you can\'t simply pass by.\\n\\nLet\'s dive in and search for a big fish.\\n\\n### Machine Learning General Availability\\n\\nEight months ago, at the time of Apache Ignite 2.0, we put out the first APIs that formed the foundation of the Ignite\'s machine learning component of today. Since that time, Ignite machine learning experts and enthusiasts have been moving the library to the general availability condition meticulously. And Ignite 2.4 became a milestone that let us consider the [ML Grid](https://apacheignite.readme.io/docs/machine-learning) to be production ready.\\n\\n\x3c!--truncate--\x3e\\n\\nThe component gained a variety of algorithms that can solve a myriad of regression and classification tasks, gave an ability to train models avoiding ETL from Ignite to other systems, paved a way to [deep learning](https://apacheignite.readme.io/docs/multilayer-perceptron) usage scenarios. All that now empowers Ignite users with the tools for dealing with fraud detection, predictive analytics, and for building recommendation systems...if you want. Note, ETL is optional, and the whole memory-centric cluster is at your service!\\n\\nMoreover, Machine Learning Grid welcomed a [software donation](http://incubator.apache.org/ip-clearance/ga-grid-ignite.html) by NetMillennium, Inc. in the form of genetic algorithms that solve optimization problems by simulating the process of biological evolution. The algorithms haven\'t got to Ignite 2.4 and waiting for their time for a release in the master branch. Once you get them, you can apply the biological evolution simulation for real-world applications including automotive design, computer gaming, robotics, investments, traffic/shipment routing and more.\\n\\n### Spark DataFrames\\n\\nIt\'s not a joke or misprint. Spark users, the DataFrames are now officially supported for you! Many of you have been anticipating them for years and, thanks to Nikolay Izhikov, who was \\"promoted\\" to an Ignite committer for the contribution, now you can leverage from them.\\n\\nNo need to be wordy here. Just go ahead and start with [DataFrames in Ignite](https://apacheignite-fs.readme.io/docs/ignite-data-frame).\\n\\n### Expanding Ignite ecosystem\\n\\nIt was unfair that only Java, C#, and C++ developers could utilize the breadth and depth of Ignite APIs in their applications. Ignite 2.4 solved the injustice with its new [low-level binary client protocol](https://apacheignite.readme.io/v2.4/docs/binary-client-protocol). The protocol communicates with an existing Ignite cluster without starting a full-fledged Ignite node. An application can connect to the cluster through a raw TCP socket from any programming language you like.\\n\\nThe beauty of the protocol is that you can develop a so-called Ignite thin client that is a lightweight client connected to the cluster and interacts with it using key-value, SQL, and other APIs. [.NET thin client](https://apacheignite-net.readme.io/docs/thin-client) is already at your service and Node.JS, Python, PHP, Java thin clients are in a forge and being developed for the next releases.\\n\\n### RPM repository and much more\\n\\nSo, now Apache Ignite can also be installed from the [official RPM repository](https://www.apache.org/dist/ignite/rpm). Debian users, the packages for your operating systems to be assembled [soon](https://cwiki.apache.org/confluence/display/IGNITE/IEP-11%3A+Introduce+Apache+Ignite+delivery+in+RPM+and+DEB+packages).\\n\\nOverall, if to list all the features and benefits Ignite 2.4 brings, only 2 people will read the article till the end - me and my dear mom :) Thus, I\'ll let you discover the rest from the [release notes](https://ignite.apache.org/releases/ignite2/2.4.0/release_notes.html)."},{"id":"/2018/01/30/meltdown-and-spectre-patches-show","metadata":{"permalink":"/blog/2018/01/30/meltdown-and-spectre-patches-show","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2018-01-30-meltdown-and-spectre-patches-show.mdx","source":"@site/blog/2018-01-30-meltdown-and-spectre-patches-show.mdx","title":"Meltdown and Spectre patches show negligible impact to Apache Ignite performance","description":"As promised in my initial blog post on this matter, Apache Ignite community applied security patches against the notorious Meltdown Spectre vulnerabilities and completed performance testing of general operations and workloads that are typical for Ignite deployments.","date":"2018-01-30T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"meltdown","permalink":"/blog/tags/meltdown"},{"inline":true,"label":"performance","permalink":"/blog/tags/performance"},{"inline":true,"label":"security","permalink":"/blog/tags/security"},{"inline":true,"label":"spectre","permalink":"/blog/tags/spectre"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":1.69,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Meltdown and Spectre patches show negligible impact to Apache Ignite performance","authors":["denis"],"date":"2018-01-30T00:00:00.000Z","tags":["apache","ignite","meltdown","performance","security","spectre","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.4 Brings Advanced Machine Learning and Spark DataFrames Capabilities","permalink":"/blog/2018/03/15/apache-ignite-2-4-brings"},"nextItem":{"title":"Protecting Apache Ignite from \'Meltdown\' and \'Spectre\' vulnerabilities","permalink":"/blog/2018/01/08/protecting-apache-ignite-from-meltdown"}},"content":"As promised in my [initial blog post](https://blogs.apache.org/ignite/entry/protecting-apache-ignite-from-meltdown) on this matter, Apache Ignite community applied security patches against the notorious Meltdown Spectre vulnerabilities and completed performance testing of general operations and workloads that are typical for Ignite deployments.\\n\\nThe security patches were applied only for [CVE-2017-5754](https://nvd.nist.gov/vuln/detail/CVE-2017-5754) (Meltdown) and [CVE-2017-5753](https://nvd.nist.gov/vuln/detail/CVE-2017-5753) (Spectre Variant 1) vulnerabilities. The patches for [CVE-2017-5715](https://nvd.nist.gov/vuln/detail/CVE-2017-5715) (Spectre Variant 2) for the hardware the community used for testing are not stable yet an can [cause system reboot issues or another unpredictable behavior](https://newsroom.intel.com/news/root-cause-of-reboot-issue-identified-updated-guidance-for-customers-and-partners/).\\n\\nThe applied patches have shown that the performance implications are negligible - the performance drop is just in the 0 - 7% range as the figure shows:\\n\\n\x3c!--truncate--\x3e\\n\\n![Spectre and Meltdown Benchmarks](https://www.gridgain.com/sites/default/files/inline-images/meltdown-benchmarks.png)\\n\\nThus, Apache Ignite community highly recommends its customers and partners to consider security patches for CVE-2017-5754 (Meltdown) and CVE-2017-5753 (Spectre Variant 1) in their deployment environments and contact us on the user list if you run into a larger performance drop in your use case.\\n\\nAt the same time, we\'re keeping an eye on Intel announcements and will validate the performance implications of Spectre Variant 2 once a solution is released by the hardware vendor.\\n\\nJust for your reference, the benchmarks were executed in the following environment and configuration.\\n\\n### Benchmarking Environment\\n\\nCluster Configuration:\\n\\n- 4 servers and 8 client nodes\\n- Apache Ignite version: 2.4.0\\n\\nHardware:\\n\\n- Huawei RH2288 V3, CPU - 2x Xeon E5-2609 v4, 1.7GHz, RAM - 96Gb, SSD - 3x800Gb RAID0 2.4Tb, Network - 10Gb/s\\n- DEll R610, CPU - 2x Xeon X5570, RAM - 96Gb, SSD - 512Gb, HDD - 2048GB, Network - 10Gb/s\\n\\nOperating System:\\n\\n- OS CentOS Linux release 7.4.1708 (Core)\\n- Kernel - Linux 3.10.0-693.11.6.el7.x86_64 #1 SMP Thu Jan 4 01:06:37 UTC 2018 x86_64"},{"id":"/2018/01/08/protecting-apache-ignite-from-meltdown","metadata":{"permalink":"/blog/2018/01/08/protecting-apache-ignite-from-meltdown","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2018-01-08-protecting-apache-ignite-from-meltdown.mdx","source":"@site/blog/2018-01-08-protecting-apache-ignite-from-meltdown.mdx","title":"Protecting Apache Ignite from \'Meltdown\' and \'Spectre\' vulnerabilities","description":"The world was rocked after the recent disclosure of the Meltdown and Spectre vulnerabilities that literally affect almost all software ever developed. Both issues are related to the way all modern CPUs are designed and this is why they have opened unprecedented security breaches, making the software, including Apache Ignite, vulnerable to hacker attacks.","date":"2018-01-08T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"meltdown","permalink":"/blog/tags/meltdown"},{"inline":true,"label":"security","permalink":"/blog/tags/security"},{"inline":true,"label":"spectre","permalink":"/blog/tags/spectre"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":2.58,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Protecting Apache Ignite from \'Meltdown\' and \'Spectre\' vulnerabilities","authors":["denis"],"date":"2018-01-08T00:00:00.000Z","tags":["apache","ignite","meltdown","security","spectre","archived"]},"unlisted":false,"prevItem":{"title":"Meltdown and Spectre patches show negligible impact to Apache Ignite performance","permalink":"/blog/2018/01/30/meltdown-and-spectre-patches-show"},"nextItem":{"title":"Apache Ignite Essentials: 2-part Webinar Series for Architects and Java Developers","permalink":"/blog/2017/11/17/apache-ignite-essentials-series-for"}},"content":"The world was rocked after the recent disclosure of the [Meltdown and Spectre](https://www.vox.com/business-and-finance/2018/1/4/16850004/meltdown-spectre-intel-security-flaw-update) vulnerabilities that literally affect almost all software ever developed. Both issues are related to the way all modern CPUs are designed and this is why they have opened unprecedented security breaches, making the software, including Apache Ignite, vulnerable to hacker attacks.\\n\\nThe vulnerabilities are registered in the National Vulnerability Database under the following CVEs:\\n\\n- [CVE-2017-5753](https://nvd.nist.gov/vuln/detail/CVE-2017-5753) - Spectre variant 1\\n- [CVE-2017-5715](https://nvd.nist.gov/vuln/detail/CVE-2017-5715) - Spectre variant 2\\n- [CVE-2017-5754](https://nvd.nist.gov/vuln/detail/CVE-2017-5754) - Meltdown\\n\\n\x3c!--truncate--\x3e\\n\\n## How to protect Apache Ignite deployments?\\n\\nFirst, the vulnerabilities can be fixed only on the operating system (OS) or hardware levels. All OS and hardware vendors are working on and releasing patches to fill-in the security breaches. Depending on the type of your Apache Ignite deployment, make sure to do the following:\\n\\n- **On-premise deployments** - apply the patches prepared by your OS and hardware vendors. Consult with them to find out additional steps to act on. [This page](https://www.us-cert.gov/ncas/alerts/TA18-004A) is a good place to start with.\\n- **Cloud deployments** - major cloud providers such as Amazon and Microsoft are in a process of patching their cloud computing services. Consider a cloud provider\'s security announcements and recommendations or follow up with a representative for suggestions.\\n\\nSecond, an Apache Ignite cluster becomes vulnerable to the attacks only if someone gets unauthorized access to cluster machines (both on-premise or cloud deployments) and executes a malicious shell script or connects to the cluster directly and executes a Java, .NET or C++ computation there.\\n\\nDo the following to prevent this from happening:\\n\\n- Make sure the cluster machines are secured with a hard-to-guess or hard-to-calculate password.\\n- Consider using 3rd party security components provided by enterprise vendors (such as [this one](https://docs.gridgain.com/docs/security-and-audit)) to strengthen a security shield of your deployments.\\n\\nFinally, researchers who discovered Meltdown and Spectre have said that the first issue can be fixed with software patches while the second can be fully addressed only with hardware upgrades/replacement. Luckily, it\'s much more difficult for hackers to exploit Spectre. Thus, if the two recommendations given above are taken seriously, the chances that you will be impacted from Spectre are low.\\n\\n## What is the performance impact of security patches?\\n\\nMany security patches are rolled out with a precaution that some of the applications can see up to a 30% performance degradation. Apache Ignite community is planning to measure the impact of general usage scenarios and will follow up with the results in a consequent post.\\n\\nThis general performance testing might not cover your use case. Therefore, it\'s highly recommended that you assess and test a possible performance drop of your Apache Ignite deployments before applying the patches in production. If the drop is significant, then contact us on the [dev list](https://ignite.apache.org/community/resources.html#mail-lists)."},{"id":"/2017/11/17/apache-ignite-essentials-series-for","metadata":{"permalink":"/blog/2017/11/17/apache-ignite-essentials-series-for","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-11-17-apache-ignite-essentials-series-for.mdx","source":"@site/blog/2017-11-17-apache-ignite-essentials-series-for.mdx","title":"Apache Ignite Essentials: 2-part Webinar Series for Architects and Java Developers","description":"We finally made this happen! I\'m happy to invite all of the software architects and engineers out there to a series of webinars that will introduce you to the fundamental capabilities of in-memory computing platforms such as Apache Ignite.","date":"2017-11-17T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":0.88,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite Essentials: 2-part Webinar Series for Architects and Java Developers","authors":["denis"],"date":"2017-11-17T00:00:00.000Z","tags":["apache","ignite","archived"]},"unlisted":false,"prevItem":{"title":"Protecting Apache Ignite from \'Meltdown\' and \'Spectre\' vulnerabilities","permalink":"/blog/2018/01/08/protecting-apache-ignite-from-meltdown"},"nextItem":{"title":"Apache Ignite 2.3 - More SQL and Persistence Capabilities","permalink":"/blog/2017/11/01/apache-ignite-2-3-more"}},"content":"We finally made this happen! I\'m happy to invite all of the software architects and engineers out there to a series of webinars that will introduce you to the fundamental capabilities of in-memory computing platforms such as Apache Ignite.\\n\\nThere will also be a mix of theory and practice. A lot of code examples are waiting to be shown so that you can apply the theory in practice right away.\\n\\nThe series consists of two parts.\\n\\n### [Part 1: Tuesday, November 21, 2017, 11:00am PT / 2:00pm ET](https://ignite.apache.org/events.html#in-memory-computing-essentials-architects-and-developers-part-1)\\n\\nTo be covered:\\n\\n- Cluster configuration and deployment.\\n- Distributed database internals (partitioning, replication).\\n- Data processing with key-value APIs.\\n- Affinity Collocation.\\n- Data processing with SQL.\\n\\n\x3c!--truncate--\x3e\\n\\n### [Part 2: Wednesday, December 13, 2017, 11:00am PT / 2:00pm ET](https://ignite.apache.org/events.html#in-memory-computing-essentials-architects-and-developers-part-2)\\n\\nTo be covered:\\n\\n- Collocated processing.\\n- Collocated processing for distributed computations.\\n- Collocated processing for SQL (distributed joins and more).\\n- Machine Learning.\\n- Memory Architecture.\\n\\nBook your seat!"},{"id":"/2017/11/01/apache-ignite-2-3-more","metadata":{"permalink":"/blog/2017/11/01/apache-ignite-2-3-more","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-11-01-apache-ignite-2-3-more.mdx","source":"@site/blog/2017-11-01-apache-ignite-2-3-more.mdx","title":"Apache Ignite 2.3 - More SQL and Persistence Capabilities","description":"Putting aside the regular bug fixes and performance optimizations, the Apache Ignite 2.3 release brings new SQL capabilities and Ignite persistence improvements that are worth mentioning.","date":"2017-11-01T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"bigdata","permalink":"/blog/tags/bigdata"},{"inline":true,"label":"database","permalink":"/blog/tags/database"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"key-value","permalink":"/blog/tags/key-value"},{"inline":true,"label":"sql","permalink":"/blog/tags/sql"},{"inline":true,"label":"store","permalink":"/blog/tags/store"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":2.53,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 2.3 - More SQL and Persistence Capabilities","authors":["denis"],"date":"2017-11-01T00:00:00.000Z","tags":["apache","bigdata","database","ignite","key-value","sql","store","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite Essentials: 2-part Webinar Series for Architects and Java Developers","permalink":"/blog/2017/11/17/apache-ignite-essentials-series-for"},"nextItem":{"title":"Apache Ignite Community News (Issue 3)","permalink":"/blog/2017/09/15/apache-ignite-community-news-september"}},"content":"Putting aside the regular bug fixes and performance optimizations, the Apache Ignite 2.3 release brings new SQL capabilities and Ignite persistence improvements that are worth mentioning.\\n\\n### SQL\\n\\nLet\'s start with SQL first.\\n\\nApache Ignite users have consistently told us that despite all of Ignite\'s SQL capabilities, it\'s been at times challenging trying to figure out how to start using Ignite as an SQL database.\\n\\nThis was mostly caused by scattered documentation pages, lack of \\"getting started\\" guides and tutorials. We\'ve remedied this oversight! All related SQL knowledge has been curated in a [single documentation domain](https://apacheignite-sql.readme.io/docs).\\n\\n\x3c!--truncate--\x3e\\n\\nAre you curious about the SQL scope? Go to the new [SQL Reference Overview](https://apacheignite-sql.readme.io/docs/sql-reference-overview) section!\\n\\nCannot wait to learn how the Ignite SQL engine runs internally? We\'ve prepared an [Architectural Overview](https://apacheignite-sql.readme.io/docs/how-ignite-sql-works) section for you.\\n\\nSimply need to know how to connect to an Ignite cluster from an SQL tool? Here is a [tooling](https://apacheignite-sql.readme.io/docs/how-ignite-sql-works) section for you.\\n\\nLet\'s take a look at some specific SQL features released in Ignite 2.3.\\n\\nFirst, we\'re proud to deliver support of [ALTER TABLE](https://apacheignite-sql.readme.io/docs/alter-table) command. Presently, the command allows adding new columns to an SQL schema in runtime -- avoiding any cluster restarts. Once a new column is added, it can be turned into an index. Again, in runtime. No restarts!\\n\\nAnother significant addition seen in Ignite 2.3 is the integration with [SQLLine tool](https://apacheignite-sql.readme.io/docs/sqlline) that is bundled with every Apache Ignite release and can be used as a default command line tool for SQL based interactions.\\n\\nTo prove that it\'s fairly simple to work with Ignite as with an SQL database using the tool, we recorded a short screencast for you:\\n\\n[![SQLLine Demo](/img/blog/89364a0d-3c7e-427c-8237-868318dcd6f1.png)](https://youtu.be/FKS8A86h-VY)\\n\\n### Ignite Persistence\\n\\nIgnite native persistence keeps getting more attention and installs -- which is why the community released a feature requested by at least a dozen users. The feature allows enabling the persistence for specific data sets. Before Ignite version 2.3, the persistence could be enabled globally only.\\n\\nNow, it\'s up to you to decide which data to persist and which to store in RAM only. The persistence can be configured via [data regions](https://apacheignite.readme.io/docs/memory-configuration#section-data-regions) as shown below:\\n\\n[![Persistence Configuration](/img/blog/0c7ce964-1218-49eb-bc9b-54a4725cabed.png)](https://apacheignite.readme.io/docs/memory-configuration#section-data-regions)\\n\\nThis data region will consume up to 500 MB of RAM and will store a superset of data on disk ensuring that no data loss happens in case of a crash or even if there is no more space left in RAM.\\n\\n### Anything else?\\n\\nFlip through [our release notes](https://ignite.apache.org/releases/ignite2/2.3.0/release_notes.html) to see all the changes and improvements available in Apache Ignite 2.3 -- and, for sure, download and use this version in production.\\n\\nQuestions, comments? Let us know!"},{"id":"/2017/09/15/apache-ignite-community-news-september","metadata":{"permalink":"/blog/2017/09/15/apache-ignite-community-news-september","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-09-15-apache-ignite-community-news-september.mdx","source":"@site/blog/2017-09-15-apache-ignite-community-news-september.mdx","title":"Apache Ignite Community News (Issue 3)","description":"by Tom Diederich","date":"2017-09-15T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":3.81,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite Community News (Issue 3)","authors":["denis"],"date":"2017-09-15T00:00:00.000Z","tags":["apache","ignite","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.3 - More SQL and Persistence Capabilities","permalink":"/blog/2017/11/01/apache-ignite-2-3-more"},"nextItem":{"title":"Apache Ignite Community Update (August 2017 Issue)","permalink":"/blog/2017/08/30/apache-ignite-community-update-august"}},"content":"**by Tom Diederich**\\n\\nThis is our third community update. There\'s a lot going on, so let\'s get started.\\n\\nApache Ignite experts have already spoken at two meetups this month, both in Silicon Valley, but there are several more scheduled this month around the world.\\n\\nOn **Sept. 9** Apache Ignite PMC chair Denis Magda was the featured presenter at the **[Big Data and Cloud Meetup](https://www.meetup.com/datariders/events/242523245/)** in Santa Clara, Calif. His talk, titled \\"Apache Spark and Apache Ignite: Where Fast Data Meets the IoT,\\" was highly rated and we\'re planning a hands-on workshop with meetup organizers for November.\\n\\n\x3c!--truncate--\x3e\\n\\nOn **Sept. 13** Denis also spoke at the **[SF Big Analytics Meetup](https://www.meetup.com/SF-Big-Analytics/events/242368299/)** in Mountain View, Calif. Again, to a packed room. The topic of his talk was \\"Better Machine Learning with Apache Ignite.\\"\\n\\nBut Denis isn\'t having all the fun. Next Monday *(Sept. 18)*, technology evangelist Akmal Chaudhri will speak at the Camidge .NET User Group. The title of his talk: \\"**[Scale Out and Conquer: Apache Ignite for .NET Users](https://www.meetup.com/Camidge-NET-User-Group/events/238837204/)**.\\"\\n\\nWe\'re still looking for more meetups to speak at this month, so if you\'re an organizer or would like us to speak at one you\'re a member of, just let me know. In the meantime, here are the meetups planned for the remainder of September:\\n\\n- [Bay Area In-Memory Computing Meetup](https://www.meetup.com/preview/Bay-Area-In-Memory-Computing/events/242961495), Wednesday, Sept. 20 - Denis will present, \\"Apache Spark, Ignite and Flink: Where Fast Data Meets the IoT.\\"\\n- [Internet of Things (IoT) New York Meetup](https://www.meetup.com/preview/IoT-NY), Monday, Sept. 25 - Akmal will present, \\"Apache Spark and Apache Ignite: Where Fast Data Meets the IoT.\\"\\n- [NYC In-Memory Computing Meetup](https://www.meetup.com/preview/NYC-In-Memory-Computing-Meetup/events/243150945), Tuesday, Sept. 26 - Akmal will present, \\"Powering Up Banks and Financial Institutions with Distributed Systems.\\"\\n- [New York Kubernetes Meetup](https://www.meetup.com/preview/New-York-Kubernetes-Meetup/events/242597746), Wednesday, Sept. 27 - Akmal will provide a DevOps perspective on the orchestration of distributed databases and Apache Ignite.\\n\\nSee? I told you Denis wasn\'t having all the fun! Akmal is definitely on the road again.\\n\\n### Webinars\\n\\n- [Implementing In-Memory Computing for Financial Services Use Cases with Apache Ignite](http://bigcommunity.net/big-tv/) Sept 12 *(recording available)*\\n- [Better Machine Learning with Apache Ignite](https://www.gridgain.com/company/news/events/better-machine-learning-with-apacher-ignitetm), Wednesday, Sept. 27\\n\\n### Blog posts\\n\\nOn Sept. 5, Akmal published \\"[Using Java and .NET apps to connect to an Apache Ignite cluster](https://www.gridgain.com/resources/blog/using-java-and-net-apps-connect-apache-ignite-cluster), that details how to create an Apache Ignite cluster that can support the reading and writing of user-defined objects in a common storage format. This is particularly useful in situations where applications need to work with objects but these objects will be accessed by different programming languages and frameworks.\\n\\nOn Sept. 7, Dmitriy Setrakyan published \\"[Apache Ignite - In Memory Performance with Durability of Disk.](http://gridgain.blogspot.com/2017/09/apache-ignite-in-memory-performance.html)\\"\\n\\nNext up, on Sept. 12, was Akmal, who published \\"[Kubernetes and Apache Ignite Deployment on AWS](https://www.gridgain.com/resources/blog/kubernetes-and-apacher-ignitetm-deployment-aws).\\" That post walked through the steps required to get Kubernetes and Apache Ignite deployed on Amazon Web Services (AWS).\\n\\nAnd then on Sept. 13 Dmitriy published \\"[What is Apache Ignite](http://gridgain.blogspot.com/2017/09/what-is-apache-ignite.html).\\" I think the headline of that one is self-explanatory.\\n\\n### In the news\\n\\nNikita Ivanov is also an InfoWorld contributor. Read the first in his series on in-memory computing, \\"[Ensuring big data and fast data performance with in-memory computing](https://www.infoworld.com/article/3224449/big-data/ensuring-big-data-and-fast-data-performance-with-in-memory-computing.html#tk.rss_bigdata).\\"\\n\\n### Useful Resources\\n\\n- Stack Overflow. Stack Overflow is a question and answer site for professional and enthusiast programmers.\\n- Haaha. Haaha (also \\"Ha\\") (Russian: \u0425\u0430\u0431\u0440\u0430\u0445\u0430\u0431\u0440, \u0425\u0430\u0431\u0440) is a Russian collaborative blog with elements of social network about IT, Computer science and anything related to the Internet, owned by Thematic Media.\\n- [In-Memory Computing Planet](https://www.imcplanet.org/) (blogs and events) Add you blog feed!\\n- \\"Meetup in a Box.\\" If you would like to speak at a meetup, start or support a meetup, or have questions about meetups in general, let me know! I can help get you up and running with everything you\'ll need.\\n\\n*Please share any resources I\'ve excluded in the comments section and I\'ll include them in the next edition.*"},{"id":"/2017/08/30/apache-ignite-community-update-august","metadata":{"permalink":"/blog/2017/08/30/apache-ignite-community-update-august","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-08-30-apache-ignite-community-update-august.mdx","source":"@site/blog/2017-08-30-apache-ignite-community-update-august.mdx","title":"Apache Ignite Community Update (August 2017 Issue)","description":"by Tom Diederich","date":"2017-08-30T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"bigdata","permalink":"/blog/tags/bigdata"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"meetup","permalink":"/blog/tags/meetup"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":4.54,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite Community Update (August 2017 Issue)","authors":["denis"],"date":"2017-08-30T00:00:00.000Z","tags":["apache","bigdata","ignite","meetup","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite Community News (Issue 3)","permalink":"/blog/2017/09/15/apache-ignite-community-news-september"},"nextItem":{"title":"Apache Ignite 2.1 - A Leap from In-Memory to Memory-Centric Architecture","permalink":"/blog/2017/07/27/apache-ignite-2-1-a"}},"content":"***by Tom Diederich***\\n\\nIgniters, here are some community highlights from the last couple week. If I missed anything, please share it here. Meetups! Did you know that Apache Ignite experts are available to speak at your meetup? And we also have spots open for YOU to speak at the following meetups that some of us co-organize:\\n\\n- [Apache Ignite London](https://www.meetup.com/Apache-Ignite-London/)\\n- [Bay Area In-Memory Computing Meetup](https://www.meetup.com/Bay-Area-In-Memory-Computing/)\\n- [NYC In-Memory Computing Meetup](https://www.meetup.com/NYC-In-Memory-Computing-Meetup/)\\n- [Moscow Apache Ignite Meetup](https://www.meetup.com/Moscow-Apache-Ignite-Meetup/)\\n\\n\x3c!--truncate--\x3e\\n\\nMeanwhile, here\'s where to catch some great talks about Apache Ignite! We have 19 newly scheduled meetup talks on the books since the last update. All upcoming Ignite events can be found [here](https://ignite.apache.org/events.html). Let\'s take a closer look at some of them...\\n\\n### Scheduled speaking engagements\\n\\n**\\\\* Sept. 9: [Big Data and Cloud Meetup](https://www.meetup.com/datariders/events/242523245/) (Santa Clara, Calif.)**\\n\\nApache Ignite PMC chair Denis Magda will be speaking at the Big Data and Cloud Meetup September 9 from 10 a.m. to noon. His talk is titled: \\"Apache Spark and Apache Ignite: Where Fast Data Meets the IoT\\".\\n\\n**\\\\* Sept. 13: [SF Big Analytics Meetup](https://www.meetup.com/SF-Big-Analytics/events/242368299/)**\\n\\nDenis Magda will be the featured speaker at the SF Big Analytics Meetup on Sept. 13. Denis\' talk is titled: \\"Apache Ignite: the in-memory hammer in your data science toolkit.\\"\\n\\n**\\\\* Sept. 18: [Meetup: Camidge .NET User Group](https://www.meetup.com/Camidge-NET-User-Group/events/238837204/)**\\n\\nApache Ignite evangelist Akmal Chaudhri will speak at the Camidge .NET User Group Sept. 17. The title of his talk: \\"Scale Out and Conquer: Apache Ignite for .NET Users.\\"\\n\\n**\\\\* Sept. 21: Joint meetup! [Bay Area In-Memory Computing Meetup](https://www.meetup.com/Bay-Area-In-Memory-Computing/events/242961495/)** & [SF Spark and Friends](https://www.meetup.com/SF-Spark-and-Friends/)\\n\\n**\\\\* Sept. 27: [New York Kubernetes Meetup](https://www.meetup.com/New-York-Kubernetes-Meetup/events/242597746/)**\\n\\nApache Ignite evangelist Akmal Chaudhri will focus on a DevOps perspective on the orchestration of distributed databases such as Apache Ignite. Akmal will speak on node auto-discovery, automated horizontal scalability, availability, and utilization of RAM and disk with Apache Ignite.\\n\\n**\\\\* Oct. 4: Openstack & Ceph User Group Amsterdam**\\n\\nApache Ignite evangelist Akmal Chaudhri will show attendees how to build a Fast Data solution that will receive endless streams from the IoT side and will be capable of processing the streams in real-time using Apache Ignite\'s cluster resources.\\n\\n**\\\\* Oct. 13: [Big Data Week London 2017](http://london.bigdataweek.com/session/powering-banks-financial-institutions-distributed-systems/): A Festival of Data (conference)**\\n\\nAkmal Chaudhri will be speaking at the Big Data Week conference Oct. 13 in London. His talk, titled \\"Powering up banks and financial institutions with distributed systems,\\" will educate attendees about important Apache Ignite features for financial applications such as ACID compliance, SQL compatibility, persistence, replication, security, fault tolerance and more.\\n\\n**\\\\* Oct. 18: [Silicon Valley Java User Group](https://www.meetup.com/sv-jug/)**\\n\\nJoin Apache Ignite PMC Chair Denis Magda will introduce the many components of the open-source Apache Ignite. His talk, titled, \\"Catch an intro to Apache Ignite and skyrocket Java applications,\\" will teach attendees how to solve some of the most demanding scalability and performance challenges. He will also cover a few typical use cases and work through some code examples.\\n\\n**\\\\* Oct. 19: [Eurostaff Big Data London](https://www.meetup.com/Eurostaff-Big-Data/)**\\n\\nApache Ignite evangelist Akmal Chaudhri will show attendees how to build a Fast Data solution that will receive endless streams from the IoT side and will be capable of processing the streams in real-time using Apache Ignite\'s cluster resources.\\n\\n**\\\\* Oct. 24: [Spark Summit Europe 2017](https://spark-summit.org/eu-2017/events/how-to-share-state-across-multiple-apache-spark-jobs-using-apache-ignite/) (conference)**\\n\\nAkmal Chaudhri will be presenting at the Spark Summit Europe conference, Oct. 24-26 at the Convention Centre Dublin in Ireland. His session is titled: \\"How to Share State Across Multiple Spark Jobs using Apache Ignite.\\"\\n\\n**\\\\* Nov. 2: [Byte-Academy-FinTech-Python-Blockchain-Education](https://www.meetup.com/Byte-Academy-Finance-and-Technology-community/) Meetup (London)**\\n\\nIn his talk, titled, \\"Powering up banks and financial institutions with distributed systems,\\" Apache Ignite technical Akmal Chaudhri will explain important Apache Ignite features for financial applications such as ACID compliance, SQL compatibility, persistence, replication, security, fault tolerance and more. A customer case study will also be presented.\\n\\n### Blog posts\\n\\n- [Scale-up vs. scale-out architectures](https://www.gridgain.com/resources/blog/scale-vs-scale-out-architectures-conversation-fujitsus-dr-ferhat-hatay)\\n- [Cloud Wars: Apache Ignite - Getting started with AWS for Beginners](https://www.gridgain.com/resources/blog/cloud-wars-apacher-ignitetm-getting-started-aws-beginners-part-i) (Part I)\\n- [Apache Ignite Tip: Peer Class Loading Deployment Magic](https://www.gridgain.com/resources/blog/apacher-ignitetm-tip-peer-class-loading-deployment-magic)\\n- [The Future of In-Memory Computing](https://www.gridgain.com/resources/blog/future-in-memory-computing)\\n\\n### Webinars\\n\\n***Upcoming***\\n\\n- **Sept. 27**: [Better Machine Learning with Apache Ignite](https://www.gridgain.com/resources/webinars/better-machine-learning-apacher-ignitetm), with technical evangelist Akmal B. Chaudhri.\\n- **Oct. 4**: [Postgres with Apache Ignite: Faster Transactions and Analytics](https://www.gridgain.com/resources/webinars/postgres-apacher-ignitetm-faster-transactions-and-analytics), with GridGain senior solution architect Fotios Filacouris.\\n\\n**Past webinars (recordings available!)**\\n\\n[Deploy like a Boss: Using Kubernetes and Apache Ignite](https://www.gridgain.com/resources/webinars/deploy-boss-using-kubernetesr-and-apacher-ignitetm), with GridGain solution architect Dani Traphagen."},{"id":"/2017/07/27/apache-ignite-2-1-a","metadata":{"permalink":"/blog/2017/07/27/apache-ignite-2-1-a","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-07-27-apache-ignite-2-1-a.mdx","source":"@site/blog/2017-07-27-apache-ignite-2-1-a.mdx","title":"Apache Ignite 2.1 - A Leap from In-Memory to Memory-Centric Architecture","description":"The power and beauty of in-memory computing projects are that they truly do what they state -- deliver outstanding performance improvements by moving data closer to the CPU, using RAM as a storage and spreading the data sets out across a cluster of machines relying on horizontal scalability.","date":"2017-07-27T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"biodata","permalink":"/blog/tags/biodata"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"rdbms","permalink":"/blog/tags/rdbms"},{"inline":true,"label":"sql","permalink":"/blog/tags/sql"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":4.11,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 2.1 - A Leap from In-Memory to Memory-Centric Architecture","authors":["denis"],"date":"2017-07-27T00:00:00.000Z","tags":["apache","biodata","ignite","rdbms","sql","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite Community Update (August 2017 Issue)","permalink":"/blog/2017/08/30/apache-ignite-community-update-august"},"nextItem":{"title":"Apache Ignite 2.0: Redesigned Off-heap Memory, DDL and Machine Learning","permalink":"/blog/2017/05/05/apache-ignite-2-0-redesigned"}},"content":"The power and beauty of in-memory computing projects are that they truly do what they state -- deliver outstanding performance improvements by moving data closer to the CPU, using RAM as a storage and spreading the data sets out across a cluster of machines relying on horizontal scalability.\\n\\nHowever, there is an unspoken side of the story. No matter how fast a platform is, we do not want to lose the data and encounter cluster restarts or other outages. To guarantee this we need to somehow make data persistent on the disk.\\n\\nMost in-memory computing projects address the persistence dilemma by giving a way to sync data back to a relational database (RDBMS). That sounds reasonable and undoubtedly works pretty well in practice, but if we dig deeper, you\'ll likely encounter the following limitations:\\n\\n\x3c!--truncate--\x3e\\n\\n- **RDBMS is a bottleneck.** No matter how fast your in-memory technology project, you can accelerate read operations only because every write has to be persisted to the disk -- which is usually a single machine running an RDBMS instance.\\n\\n- **RDBMS is a single point of failure.** Your distributed in-memory cluster usually consists of dozens and even hundreds of nodes which means you can safely lose this node here or drop that node there without worrying about data consistency and availability. However, if the RDBMS used by the cluster fails, then what? The answer is obvious -- the cluster can no longer be utilized because the RAM and disk parts go out of sync.\\n\\n- **SQL over RAM only**. Apache Ignite provides SQL database capabilities, however, you can only leverage them if all of the data and indexes are located in RAM. If a single piece of data, represented by a disk copy located in the RDBMS, then an Ignite-only SQL query will return an incomplete result set.\\n\\n- **Required RAM warmup**. When your cluster goes down, you have to restart it and preload all of the data from the RDBMS to RAM. That\'s essential if you use SQL or similar advanced querying languages. This dramatically increases the overall time of the downtime and can cost a lot of money.\\n\\nIf you use either Apache Ignite 1.x or 2.0 along with the RDBMS for disk storage, then you will hit these limitations. It\'s just the way in-memory architectures are integrated with the disk.\\n\\nHowever, the limitations are **no longer relevant** for Apache Ignite 2.1! This version made a leap from in-memory to a **[memory-centric](https://apacheignite.readme.io/docs/what-is-ignite)** architecture that:\\n\\n![Cluster and Cylinders](https://files.readme.io/752653f-cluster_and_cylinders.png)\\n\\n- Keeps using RAM as a first memory tier for data and indexes -- giving all of the benefits you had before.\\n- Supports durability criteria by treating disk as a secondary and larger tier that works in a distributed fashion and seamlessly integrates with the whole memory architecture.\\n- Supports the instantaneous cluster restarts -- once your cluster is up and running there is no reason to wait for RAM\'s warmup, go ahead and turn on back your applications that can safely execute all operations including SQL. The data and indexes will be taken from disk.\\n\\nCurious about how Ignite achieved these huge advantages? Lifting the curtain...\\n\\n### Durable Memory Architecture\\n\\nThe Apache Ignite memory-centric platform is based on the [durable memory architecture](https://apacheignite.readme.io/docs/durable-memory) that allows storing and processing data and indexes both in-memory and on disk when the [Ignite Persistent Store](https://apacheignite.readme.io/docs/distributed-persistent-store) is enabled. The memory architecture helps to achieve in-memory performance with the durability of the disk using all of the resources available in the cluster.\\n\\nThe durable memory is built and operates in a way similar to the virtual memory of operating systems such as Linux. However, the one significant difference between these two types of architectures is that the durable memory one always keeps the whole data set and indexes on the disk -- if the Ignite Persistent Store is enabled -- while the virtual memory uses the disk for swapping purposes only.\\n\\n### Ignite Persistent Store\\n\\n[Persistent Store](https://apacheignite.readme.io/docs/distributed-persistent-store) is a distributed ACID and SQL-compliant disk store that transparently integrates with the durable memory as an optional disk layer (SSD, Flash, 3D XPoint). Having the store enabled, you no longer need to keep all of the data in memory or warm-up the RAM after a whole cluster restart. The persistent store will keep the superset of data and all the SQL indexes on the disk making Ignite fully operational from the disk.\\n\\n### The Upshot\\n\\nTired of hooking up Ignite with an RDBMS? Go ahead and download Apache Ignite 2.1, enable Ignite Persistent Store, and launch your first durable Ignite cluster that distributes data sets and workloads relying on the performance of RAM and durability of the disk!\\n\\nFinally, Apache Ignite 2.1 can boast about another achievements in .NET, C++, SQL and Machine Learning. Go ahead and discover them!"},{"id":"/2017/05/05/apache-ignite-2-0-redesigned","metadata":{"permalink":"/blog/2017/05/05/apache-ignite-2-0-redesigned","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-05-05-apache-ignite-2-0-redesigned.mdx","source":"@site/blog/2017-05-05-apache-ignite-2-0-redesigned.mdx","title":"Apache Ignite 2.0: Redesigned Off-heap Memory, DDL and Machine Learning","description":"We released the long-awaited Apache Ignite version 2.0 on May 5. The community spent almost a year incorporating tremendous changes to the legacy Apache Ignite 1.x architecture. And all of that effort paid off. Our collective blood, sweat (and perhaps even a few tears) opened up new and exciting opportunities for the Apache Ignite project.","date":"2017-05-05T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"data","permalink":"/blog/tags/data"},{"inline":true,"label":"grid","permalink":"/blog/tags/grid"},{"inline":true,"label":"ignite","permalink":"/blog/tags/ignite"},{"inline":true,"label":"imdb","permalink":"/blog/tags/imdb"},{"inline":true,"label":"learning","permalink":"/blog/tags/learning"},{"inline":true,"label":"machine","permalink":"/blog/tags/machine"},{"inline":true,"label":"rdbms","permalink":"/blog/tags/rdbms"},{"inline":true,"label":"sql","permalink":"/blog/tags/sql"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":3.56,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 2.0: Redesigned Off-heap Memory, DDL and Machine Learning","authors":["denis"],"date":"2017-05-05T00:00:00.000Z","tags":["apache","data","grid","ignite","imdb","learning","machine","rdbms","sql","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.1 - A Leap from In-Memory to Memory-Centric Architecture","permalink":"/blog/2017/07/27/apache-ignite-2-1-a"},"nextItem":{"title":"Presenting Apache Ignite SQL Grid at Big Data Bootcamp","permalink":"/blog/2017/03/13/presenting-apache-ignite-sql-grid"}},"content":"We released the long-awaited Apache Ignite version 2.0 on May 5. The community spent almost a year incorporating tremendous changes to the legacy Apache Ignite 1.x architecture. And all of that effort paid off. Our collective blood, sweat (and perhaps even a few tears) opened up new and exciting opportunities for the Apache Ignite project.\\n\\nHave I piqued your interest about this new release yet? Let\'s walk through some of the main new features that have appeared under the hood of Apache Ignite 2.0.\\n\\n\x3c!--truncate--\x3e\\n\\n### Reengineered Off-Heap Memory Architecture.\\n\\nThe platform\'s entire memory architecture was reengineered from scratch. In a nutshell, all of the data and indexes are now stored in a completely new manageable off-heap memory that has no issues with memory fragmentation, accelerates SQL Grid significantly and helps your application easily tolerate Java GC pauses.\\n\\nTake a peek at the illustration below and try to guess what\'s changed. Afterward, please read [this documentation](https://apacheignite.readme.io/docs/page-memory) to see if your eye caught everything that\'s new.\\n\\n![Page Memory Architecture](https://files.readme.io/0bf1bbf-Page-Memory-Diagram-v3.png)\\n\\nHere\'s something extremely noteworthy: the architecture now integrates seamlessly with disk drives. Why do we care about this? Stay tuned!\\n\\n### Data Definition Language.\\n\\nThis release introduces support for Data Definition Language (DDL) as a part of its SQL Grid functionality. Now you can define -- and, what\'s more important, alter -- indexes in runtime without the need to restart your cluster. Apache Ignite users have long awaited this feature! Even more exciting news: users can leverage this with standard SQL commands like CREATE or DROP index. This is only the beginning! Go to [this page](https://apacheignite.readme.io/docs/distributed-ddl) to learn more about current DDL support.\\n\\n### Machine Learning Grid Beta - Distributed Algebra.\\n\\nApache Ignite is about more than in-memory storage. And it\'s not just one more product for distributed computations or real-time streaming. It\'s much, much more than that. It\'s a hot blend of well-integrated distributed and highly concurrent modules that turned Apache Ignite into what is today: A robust data-fabric and framework with the goal of making your application thrive and outperform even the best of expectations.\\n\\nBut there was one thing missing until now. Drumroll, please: machine-learning support!\\n\\nWith Apache Ignite 2.0 you can check project\'s own [distributed algebra implementation](https://apacheignite.readme.io/docs/machine-learning). The distributed algebra is the foundation of the entire component. And soon you can expect to get distributed versions of widely used regression algorithms, decision trees and more.\\n\\n### Spring Data Integration.\\n\\n[Spring Data integration](https://apacheignite-mix.readme.io/docs/spring-data) allows the interaction of an Apache Ignite cluster using the well-known and highly adopted Spring Data Framework. You can connect to the cluster by means of Spring Data repositories and start executing distributed SQL queries as well as simple CRUD operations.\\n\\n### Rocket MQ\\n\\nAre you using Rocket MQ in your project and need to push data from the Rocket to Ignite? [Here is](https://apacheignite-mix.readme.io/docs/rocketmq-streamer) an easy solution.\\n\\n### Hibernate 5.\\n\\nHibernate L2 cache users have been anticipating support of Hibernate 5 on Apache Ignite for quite a long time. Apache Ignite 2.0 grants [this desire](https://apacheignite-mix.readme.io/docs/hibernate-l2-cache). The integration now supports Hibernate 5 and contains a number of bug fixes and improvements.\\n\\n### Ignite.NET\\n\\nIgnite.NET has been enhanced with an addition of a [plugin system](https://apacheignite-net.readme.io/docs/plugins) that allows the writing and embedding 3rd party .NET components into Ignite.NET.\\n\\n### Ignite.C++\\n\\nThe Ignite.C++ part of the community finally came up with a way to execute arbitrary C++ code on remote cluster machines.\\n\\nThis approach was initially tested for [continuous queries](https://apacheignite-cpp.readme.io/docs/continuous-queries). You can now register continuous queries\' remote filters on any cluster node you like. Going forward you can expect support for the Ignite.C++ compute grid and more.\\n\\nWant to learn more? Please join me June 7 for a [webinar](https://www.gridgain.com/resources/webinars/apacher-ignitetm-whats-new-version-20) titled, \\"Apache Ignite: What\'s New in Version 2.0.\\" I hope to see you there!\\n\\nP.S. Just in case you can\'t wait until June... [here\'s](https://ignite.apache.org/releases/ignite2/2.0.0/release_notes.html) a full list of the changes inside Apache Ignite 2.0."},{"id":"/2017/03/13/presenting-apache-ignite-sql-grid","metadata":{"permalink":"/blog/2017/03/13/presenting-apache-ignite-sql-grid","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-03-13-presenting-apache-ignite-sql-grid.mdx","source":"@site/blog/2017-03-13-presenting-apache-ignite-sql-grid.mdx","title":"Presenting Apache Ignite SQL Grid at Big Data Bootcamp","description":"Apache Ignite community welcomes you to attend Big Data Bootcamp on March 27th, 28th and 29th 2017 in Santa Clara, USA.","date":"2017-03-13T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":1.66,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Presenting Apache Ignite SQL Grid at Big Data Bootcamp","authors":["denis"],"date":"2017-03-13T00:00:00.000Z","tags":["apache","archived"]},"unlisted":false,"prevItem":{"title":"Apache Ignite 2.0: Redesigned Off-heap Memory, DDL and Machine Learning","permalink":"/blog/2017/05/05/apache-ignite-2-0-redesigned"},"nextItem":{"title":"Apache Ignite 1.9 Released","permalink":"/blog/2017/03/07/apache-ignite-1-9-released"}},"content":"Apache Ignite community welcomes you to attend [Big Data Bootcamp](http://globalbigdataconference.com/santa-clara/big-data-bootcamp/event-79.html) on March 27th, 28th and 29th 2017 in Santa Clara, USA.\\n\\nThe conference gathers experts and vendors from Big Data realm in sunny California who will be covering a variety of Big Data products and technologies, including, but not limited to, Hadoop, Spark, NoSQL, Data Science, Machine Learning, Artificial Intelligence & Deep Learning.\\n\\nApache Ignite will be introduced at the conference by its PMC chair and committer - Denis Magda.\\n\\n\x3c!--truncate--\x3e\\n\\nAs all we know, in-memory data grids bring exceptional performance and scalability gains to applications built on top of them. The applications truly achieve 10x more performance improvement and become easily scalable and fault-tolerant thanks to the unique data grids architecture. However, because of this particular architecture, a majority of data grids have to sacrifice traditional SQL support requiring application developers to completely rewrite their SQL-based code to support data grid specific APIs. This, however, is not true for Apache Ignite.\\n\\nIn this presentation, Denis will introduce Apache Ignite SQL Grid component that combines the best of two worlds - performance and scalability of data grids and traditional ANSI-99 SQL support of relational databases. Moreover, Denis will take an existing application that works with a relational database and will show how to run it on top of Apache Ignite with minimum efforts.\\n\\nThe talk is called **[\\"Apache Ignite SQL Grid: Hot Blend of Traditional SQL and Swift Data Grid\\"](http://globalbigdataconference.com/santa-clara/big-data-bootcamp-79/speaker-details/denis-magda-41504.html)** and takes place at 1:00 PM - 1:40PM on March 28. Refer to [Big Data Bootcamp\'s agenda](http://globalbigdataconference.com/santa-clara/big-data-bootcamp/schedule-79.html) for more details.\\n\\nFinally, use promotional code SPEAKER to receive $200 discount on or before March 15th by registering at [the conference site](http://globalbigdataconference.com/santa-clara/big-data-bootcamp/attendee-registration-79.html).\\n\\nSee you at the conference!"},{"id":"/2017/03/07/apache-ignite-1-9-released","metadata":{"permalink":"/blog/2017/03/07/apache-ignite-1-9-released","editUrl":"https://github.com/apache/ignite-website/tree/master/blog/2017-03-07-apache-ignite-1-9-released.mdx","source":"@site/blog/2017-03-07-apache-ignite-1-9-released.mdx","title":"Apache Ignite 1.9 Released","description":"Apache Ignite community is pleased to announce Apache Ignite 1.9 - the next minor release of a well-known in-memory data fabric. The release, as usual, encompasses many bug fixes, performance improvements and fresh features. Below you can see a description of the most significant updates.","date":"2017-03-07T00:00:00.000Z","tags":[{"inline":true,"label":"apache","permalink":"/blog/tags/apache"},{"inline":true,"label":"archived","permalink":"/blog/tags/archived"}],"readingTime":2.62,"hasTruncateMarker":true,"authors":[{"name":"Denis Magda","title":"Apache Ignite PMC Member","url":"https://github.com/dmagda","imageURL":"https://github.com/dmagda.png","key":"denis","page":null}],"frontMatter":{"title":"Apache Ignite 1.9 Released","authors":["denis"],"date":"2017-03-07T00:00:00.000Z","tags":["apache","archived"]},"unlisted":false,"prevItem":{"title":"Presenting Apache Ignite SQL Grid at Big Data Bootcamp","permalink":"/blog/2017/03/13/presenting-apache-ignite-sql-grid"}},"content":"Apache Ignite community is pleased to announce Apache Ignite 1.9 - the next minor release of a well-known in-memory data fabric. The release, as usual, encompasses many bug fixes, performance improvements and fresh features. Below you can see a description of the most significant updates.\\n\\n**Kubernetes Support**\\n\\nApache Ignite was integrated with Kubernetes which is a modern open source container cluster manager. The integration helps to simplify a deployment of an Apache Ignite cluster in environments managed by Kubernetes and let the latter care of resources management, cluster\'s scalability and lifecycle.\\n\\n\x3c!--truncate--\x3e\\n\\nFor instance, you\'re no longer need to monitor a cluster state constantly to be sure that the number of cluster nodes doesn\'t go, let\'s say, below 4. If Kubernetes sees that one cluster node is disconnected and only 3 are left then it will start one more automatically to meet the deployment requirements.\\n\\nRefer to [Kubernetes Deployment Getting Started](https://apacheignite.readme.io/docs/kubernetes-deployment) if this is the feature of interest for you.\\n\\n**Performance Optimizations and Benchmarks Automation**\\n\\nApache Ignite 1.9 can boast of much better performance for core cache operations and SQL queries in compare to the previous Apache Ignite 1.8 release. In general, we observe up to 40% performance increase for particular operations.\\n\\nIt\'s no longer a challenge to reproduce the performance numbers. Starting with Apache Ignite 1.9 release all the benchmarks are delivered in every Apache Ignite distribution and can be easily executed in your own environment.\\n\\n**Data Modification Language and Queries Parallelism**\\n\\nThe community keeps spending significant time improving [SQL Grid](https://apacheignite.readme.io/docs/sql-grid) component that empowers Apache Ignite users with in-memory database capabilities.\\n\\nIn this release, DML (Data Modification Language) support was expanded to the level of [Ignite.NET](https://apacheignite-net.readme.io/docs/distributed-dml) and [Ignite.C++](https://apacheignite-cpp.readme.io/docs/distributed-dml) APIs. Plus, a [streaming mode](https://apacheignite.readme.io/docs/jdbc-driver#streaming-mode) was introduced for DML allowing to execute DML operations even faster for specific scenarios like initial data preloading.\\n\\nOne more SQL Grid related optimization makes it possible to parallelize a query execution on every Ignite node where the query has been mapped. By default, a query is executed in a single thread on every participating node. However, for a variety of OLAP use cases it might be a bottleneck and this is where the [query parallelism](https://apacheignite.readme.io/docs/sql-performance-and-debugging#section-query-parallelism) can help out.\\n\\n**Ignite.NET**\\n\\nApache Ignite implemented .NET TransactionScope API allowing to work with distributed Apache Ignite transactions fully relaying on standard interfaces available in .NET Framework. Refer to [this documentation page](https://apacheignite-net.readme.io/docs/transactionscope-api) for more information.\\n\\n**Ignite.C++**\\n\\nIgnite.C++ introduced support for well-known [continuous queries API](https://apacheignite-cpp.readme.io/docs/continuous-queries). Now, you can listen to data modifications happened on Apache Ignite\'s distributed caches side from your C++ applications.\\n\\n**Spark**\\n\\nIgnite\'s spark integration was upgraded to the latest Spark version. Presently, you can leverage from Ignite Shared RDDs in applications using latest Spark version.\\n\\n**Give a Try**\\n\\nGo and grab the latest 1.9 release from our [main site](https://ignite.apache.org/download). Looking forward to your feedback!"}]}}')}}]);