"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[6717],{11470:(e,n,t)=>{t.d(n,{A:()=>v});var o=t(96540),s=t(34164),i=t(17559),a=t(23104),r=t(56347),l=t(205),c=t(57485),d=t(31682),u=t(70679);function h(e){return o.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,o.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:n,children:t}=e;return(0,o.useMemo)(()=>{const e=n??function(e){return h(e).map(({props:{value:e,label:n,attributes:t,default:o}})=>({value:e,label:n,attributes:t,default:o}))}(t);return function(e){const n=(0,d.XI)(e,(e,n)=>e.value===n.value);if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[n,t])}function b({value:e,tabValues:n}){return n.some(n=>n.value===e)}function m({queryString:e=!1,groupId:n}){const t=(0,r.W6)(),s=function({queryString:e=!1,groupId:n}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!n)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return n??null}({queryString:e,groupId:n});return[(0,c.aZ)(s),(0,o.useCallback)(e=>{if(!s)return;const n=new URLSearchParams(t.location.search);n.set(s,e),t.replace({...t.location,search:n.toString()})},[s,t])]}function x(e){const{defaultValue:n,queryString:t=!1,groupId:s}=e,i=p(e),[a,r]=(0,o.useState)(()=>function({defaultValue:e,tabValues:n}){if(0===n.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!b({value:e,tabValues:n}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${n.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const t=n.find(e=>e.default)??n[0];if(!t)throw new Error("Unexpected error: 0 tabValues");return t.value}({defaultValue:n,tabValues:i})),[c,d]=m({queryString:t,groupId:s}),[h,x]=function({groupId:e}){const n=function(e){return e?`docusaurus.tab.${e}`:null}(e),[t,s]=(0,u.Dv)(n);return[t,(0,o.useCallback)(e=>{n&&s.set(e)},[n,s])]}({groupId:s}),j=(()=>{const e=c??h;return b({value:e,tabValues:i})?e:null})();(0,l.A)(()=>{j&&r(j)},[j]);return{selectedValue:a,selectValue:(0,o.useCallback)(e=>{if(!b({value:e,tabValues:i}))throw new Error(`Can't select invalid tab value=${e}`);r(e),d(e),x(e)},[d,x,i]),tabValues:i}}var j=t(92303);const g={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=t(74848);function f({className:e,block:n,selectedValue:t,selectValue:o,tabValues:i}){const r=[],{blockElementScrollPositionUntilNextRender:l}=(0,a.a_)(),c=e=>{const n=e.currentTarget,s=r.indexOf(n),a=i[s].value;a!==t&&(l(n),o(a))},d=e=>{let n=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const t=r.indexOf(e.currentTarget)+1;n=r[t]??r[0];break}case"ArrowLeft":{const t=r.indexOf(e.currentTarget)-1;n=r[t]??r[r.length-1];break}}n?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,s.A)("tabs",{"tabs--block":n},e),children:i.map(({value:e,label:n,attributes:o})=>(0,y.jsx)("li",{role:"tab",tabIndex:t===e?0:-1,"aria-selected":t===e,ref:e=>{r.push(e)},onKeyDown:d,onClick:c,...o,className:(0,s.A)("tabs__item",g.tabItem,o?.className,{"tabs__item--active":t===e}),children:n??e},e))})}function N({lazy:e,children:n,selectedValue:t}){const i=(Array.isArray(n)?n:[n]).filter(Boolean);if(e){const e=i.find(e=>e.props.value===t);return e?(0,o.cloneElement)(e,{className:(0,s.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:i.map((e,n)=>(0,o.cloneElement)(e,{key:n,hidden:e.props.value!==t}))})}function w(e){const n=x(e);return(0,y.jsxs)("div",{className:(0,s.A)(i.G.tabs.container,"tabs-container",g.tabList),children:[(0,y.jsx)(f,{...n,...e}),(0,y.jsx)(N,{...n,...e})]})}function v(e){const n=(0,j.A)();return(0,y.jsx)(w,{...e,children:h(e.children)},String(n))}},19365:(e,n,t)=>{t.d(n,{A:()=>a});t(96540);var o=t(34164);const s={tabItem:"tabItem_Ymn6"};var i=t(74848);function a({children:e,hidden:n,className:t}){return(0,i.jsx)("div",{role:"tabpanel",className:(0,o.A)(s.tabItem,t),hidden:n,children:e})}},28453:(e,n,t)=>{t.d(n,{R:()=>a,x:()=>r});var o=t(96540);const s={},i=o.createContext(s);function a(e){const n=o.useContext(i);return o.useMemo(function(){return"function"==typeof e?e(n):{...n,...e}},[n,e])}function r(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(s):e.components||s:a(e.components),o.createElement(i.Provider,{value:n},e.children)}},67930:(e,n,t)=>{t.d(n,{A:()=>o});const o=t.p+"assets/images/compute_job_statuses-53d7f77902c262ae8b36669ac7d8ef26.png"},71001:(e,n,t)=>{t.r(n),t.d(n,{assets:()=>d,contentTitle:()=>c,default:()=>p,frontMatter:()=>l,metadata:()=>o,toc:()=>u});const o=JSON.parse('{"id":"develop/work-with-data/compute","title":"Distributed Computing","description":"Apache Ignite lets you run your own code on the cluster in a distributed, balanced, and fault-tolerant way.","source":"@site/docs/develop/work-with-data/compute.md","sourceDirName":"develop/work-with-data","slug":"/develop/work-with-data/compute","permalink":"/suggested-site/docs/ignite3/3.1.0/develop/work-with-data/compute","draft":false,"unlisted":false,"editUrl":"https://github.com/apache/ignite-3/tree/main/docs/docs/develop/work-with-data/compute.md","tags":[],"version":"current","frontMatter":{"id":"compute","title":"Distributed Computing"},"sidebar":"tutorialSidebar","previous":{"title":"Streaming Data","permalink":"/suggested-site/docs/ignite3/3.1.0/develop/work-with-data/streaming"},"next":{"title":"Object Serialization","permalink":"/suggested-site/docs/ignite3/3.1.0/develop/work-with-data/serialization"}}');var s=t(74848),i=t(28453),a=t(11470),r=t(19365);const l={id:"compute",title:"Distributed Computing"},c=void 0,d={},u=[{value:"Compute Job Code Deployment",id:"compute-job-code-deployment",level:2},{value:"Configuring Jobs",id:"configuring-jobs",level:2},{value:"Job Target",id:"job-target",level:3},{value:"Job Descriptor",id:"job-descriptor",level:3},{value:"Deployment Unit Information",id:"deployment-unit-information",level:3},{value:"Executing Jobs",id:"executing-jobs",level:2},{value:"Single Node Execution",id:"single-node-execution",level:3},{value:"Multiple Node Execution",id:"multiple-node-execution",level:3},{value:"Colocated Execution",id:"colocated-execution",level:3},{value:"Using Qualified Table Names",id:"using-qualified-table-names",level:2},{value:".NET Compute Jobs",id:"net-compute-jobs",level:2},{value:".NET Compute Requirements",id:"net-compute-requirements",level:3},{value:"Implementing .NET Compute Jobs",id:"implementing-net-compute-jobs",level:3},{value:"Running .NET Compute Jobs",id:"running-net-compute-jobs",level:3},{value:"Job Ownership",id:"job-ownership",level:2},{value:"Job Execution States",id:"job-execution-states",level:2},{value:"Possible States and Transitions",id:"possible-states-and-transitions",level:3},{value:"Cancelling Executing Jobs",id:"cancelling-executing-jobs",level:3},{value:"Job Priority",id:"job-priority",level:3},{value:"Job Retries",id:"job-retries",level:3},{value:"Job Failover",id:"job-failover",level:2},{value:"Worker Node Shutdown",id:"worker-node-shutdown",level:3},{value:"Coordinator Node Shutdown",id:"coordinator-node-shutdown",level:3},{value:"Client Disconnect",id:"client-disconnect",level:3},{value:"MapReduce Tasks",id:"mapreduce-tasks",level:2},{value:"Understanding MapReduce Tasks",id:"understanding-mapreduce-tasks",level:3},{value:"Creating a Mapper Class",id:"creating-a-mapper-class",level:3},{value:"Executing a MapReduce Task",id:"executing-a-mapreduce-task",level:3}];function h(e){const n={a:"a",admonition:"admonition",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",table:"table",tbody:"tbody",td:"td",th:"th",thead:"thead",tr:"tr",ul:"ul",...(0,i.R)(),...e.components};return(0,s.jsxs)(s.Fragment,{children:[(0,s.jsx)(n.p,{children:"Apache Ignite lets you run your own code on the cluster in a distributed, balanced, and fault-tolerant way."}),"\n",(0,s.jsx)(n.p,{children:"Tasks can run on a single node, multiple nodes, or across the entire cluster, and you can choose between synchronous and asynchronous execution."}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["Apache Ignite compute engine now supports jobs implemented both in Java and in .NET. As .NET compute jobs require a bit of extra setup, see the ",(0,s.jsx)(n.a,{href:"#net-compute-jobs",children:".NET Compute Jobs"})," subsection for details."]})}),"\n",(0,s.jsxs)(n.p,{children:["In addition to standard compute tasks, Apache Ignite supports ",(0,s.jsx)(n.a,{href:"#colocated-execution",children:"Colocated Execution"}),". This means your tasks can run directly on the nodes that store the required data, reducing network overhead and improving performance.\nThe cluster also supports ",(0,s.jsx)(n.a,{href:"#mapreduce-tasks",children:"MapReduce Tasks"}),", allowing for efficient processing of large datasets. In this case, tasks will be executed on nodes that hold the data required for them."]}),"\n",(0,s.jsxs)(n.p,{children:["When sending code and data between nodes, objects are converted into a transferable format so they can be accurately rebuilt. Apache Ignite automatically handles marshalling for common types like tuples, POJOs, and native types, but for more complex or custom objects, you may need to implement your own ",(0,s.jsx)(n.a,{href:"./serialization",children:"marshalling"})," logic."]}),"\n",(0,s.jsx)(n.h2,{id:"compute-job-code-deployment",children:"Compute Job Code Deployment"}),"\n",(0,s.jsxs)(n.p,{children:["Before submitting your compute job, ensure that the required code is ",(0,s.jsx)(n.a,{href:"./code-deployment",children:"deployed"})," to the nodes where it will execute."]}),"\n",(0,s.jsxs)(n.p,{children:["If you are using ",(0,s.jsx)(n.a,{href:"/3.1.0/getting-started/embedded-mode",children:"embedded nodes"}),", any code that is included in the project classpath will also be available to your compute jobs."]}),"\n",(0,s.jsx)(n.h2,{id:"configuring-jobs",children:"Configuring Jobs"}),"\n",(0,s.jsxs)(n.p,{children:["In Apache Ignite, compute job's execution is defined by two key components: ",(0,s.jsx)(n.code,{children:"JobTarget"})," and ",(0,s.jsx)(n.code,{children:"JobDescriptor"}),". These components determine on which nodes the job will run and how it will be structured, including input and output types, marshallers, and the deployed class that represents the job."]}),"\n",(0,s.jsx)(n.h3,{id:"job-target",children:"Job Target"}),"\n",(0,s.jsxs)(n.p,{children:["Before submitting a job, you must create a ",(0,s.jsx)(n.code,{children:"JobTarget"})," object that specifies which nodes will execute the job. Job target can point to a specific node, any node on the cluster, or start a ",(0,s.jsx)(n.a,{href:"#colocated-execution",children:"colocated"})," compute job, that will be executed on nodes that hold a specific key. The following methods are available:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"JobTarget.anyNode()"})," - the job will be executed on any of the specified nodes."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"JobTarget.node()"})," - the job will be executed on the specific node."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"JobTarget.colocated()"})," - the job will be executed on a node that holds the specified key."]}),"\n"]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:["Use the ",(0,s.jsx)(n.code,{children:"BroadcastJobTarget"})," object instead in case you want to execute a job across ",(0,s.jsx)(n.a,{href:"#multiple-node-execution",children:"multiple nodes"}),"."]})}),"\n",(0,s.jsx)(n.h3,{id:"job-descriptor",children:"Job Descriptor"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"JobDescriptor"})," object contains all the details required for job execution. The following arguments must be provided:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:"The job descriptor is created using a builder that specifies the input type for the job arguments, the expected output type, and the fully qualified name of the job class to execute."}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"units"})," takes your deployment unit. You create it with the unit's name and specify ",(0,s.jsx)(n.code,{children:"Version.LATEST"})," so that your job always runs the most recently deployed version."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"resultClass"})," sets the expected result type so the system can correctly process the job's output."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"argumentMarshaller"})," and ",(0,s.jsx)(n.code,{children:"resultMarshaller"})," defines how to serialize the job's input argument and output result. For common types, you can omit the marshallers and pass ",(0,s.jsx)(n.code,{children:"null"})," to the builder since Apache Ignite automatically handles marshalling."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Examples below assumes that the ",(0,s.jsx)(n.code,{children:"NodeNameJob"})," class has been deployed to the node by using ",(0,s.jsx)(n.a,{href:"./code-deployment",children:"code deployment"}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"If you are working with common types, you don't need to define custom marshallers. Apache Ignite will handle them automatically. The following example shows a simpler job descriptor that uses built-in marshalling:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'String result = client.compute().execute(\n    JobTarget.anyNode(client.cluster().nodes()),\n    JobDescriptor.builder(WordPrintJob.class)\n        .units(new DeploymentUnit(DEPLOYMENT_UNIT_NAME, DEPLOYMENT_UNIT_VERSION))\n        .resultClass(String.class)\n        .build(),\n    "Hello, Ignite!"\n);\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["This example shows how to create a custom job descriptor for a job that takes a user-defined ",(0,s.jsx)(n.code,{children:"MyJobArgument"}),", runs on a random cluster node, and returns a ",(0,s.jsx)(n.code,{children:"MyJobResult"})," object using custom marshallers:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'MyJobResult result = client.compute().execute(\n    JobTarget.anyNode(client.cluster().nodes()),\n    JobDescriptor.<MyJobArgument, MyJobResult>builder(WordPrintJob.class)\n        .units(new DeploymentUnit(DEPLOYMENT_UNIT_NAME, DEPLOYMENT_UNIT_VERSION))\n        .resultClass(MyJobResult.class)\n        .argumentMarshaller(new ArgMarshaller())\n        .resultMarshaller(new ResultMarshaller())\n        .build(),\n    new MyJobArgument("Hello, Ignite!")\n);\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"For more details on configuring jobs refer to the corresponding API section."}),"\n",(0,s.jsx)(n.h3,{id:"deployment-unit-information",children:"Deployment Unit Information"}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"JobExecutionContext"})," object contains the information about the deployment units the job is using as a collection of ",(0,s.jsx)(n.code,{children:"DeploymentUnitInfo"})," for each deployment unit involved in the job."]}),"\n",(0,s.jsxs)(n.p,{children:["Each ",(0,s.jsx)(n.code,{children:"DeploymentUnitInfo"})," object provides the following information:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"name()"})," - The name of the deployment unit"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"version()"})," - The version of the deployment unit"]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"path()"})," - The filesystem path to the deployment unit contents"]}),"\n"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'public class DiagnosticJob implements ComputeJob<Void, String> {\n    @Override\n    public CompletableFuture<String> executeAsync(JobExecutionContext context, Void input) {\n        // Access deployment unit information\n        String deploymentInfo = context.deploymentUnits().stream()\n            .map(unit -> String.format("%s:%s at %s",\n                unit.name(),\n                unit.version(),\n                unit.path()))\n            .collect(Collectors.joining(", "));\n\n        return CompletableFuture.completedFuture(deploymentInfo);\n    }\n}\n'})}),"\n",(0,s.jsx)(n.h2,{id:"executing-jobs",children:"Executing Jobs"}),"\n",(0,s.jsx)(n.p,{children:"Apache Ignite compute jobs can run on a specific node, any node, or using a colocated approach when job is executed on the node holding the relevant data key."}),"\n",(0,s.jsx)(n.h3,{id:"single-node-execution",children:"Single Node Execution"}),"\n",(0,s.jsx)(n.p,{children:"Often, you need to perform a job on one node in the cluster. In this case, there are multiple ways to start job execution:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"submitAsync()"})," - sends the job to the cluster and returns a future that will be completed with the ",(0,s.jsx)(n.code,{children:"JobExecution"})," object when the job is submitted for execution."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"executeAsync()"})," - sends the job to the cluster and returns a future that will be completed when job execution result is ready."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"execute()"})," - sends the job to the cluster and waits for the result of job execution."]}),"\n"]}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'try (IgniteClient client = IgniteClient.builder()\n        .addresses("127.0.0.1:10800")\n        .build()\n) {\n\n    System.out.println("\\nConfiguring compute job...");\n\n    JobDescriptor<String, Void> job = JobDescriptor.builder(WordPrintJob.class)\n            .units(new DeploymentUnit(DEPLOYMENT_UNIT_NAME, DEPLOYMENT_UNIT_VERSION))\n            .build();\n\n    JobTarget jobTarget = JobTarget.anyNode(client.clusterNodes());\n\n\n    for (String word : "Print words using runnable".split(" ")) {\n\n        System.out.println("\\nExecuting compute job for word \'" + word + "\'...");\n\n        client.compute().execute(jobTarget, job, word);\n    }\n}\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'ICompute compute = Client.Compute;\nIList<IClusterNode> nodes = await Client.GetClusterNodesAsync();\n\nIJobExecution<string> execution = await compute.SubmitAsync(\nJobTarget.AnyNode(nodes),\nnew JobDescriptor<string, string>("org.example.NodeNameJob"),\narg: "Hello");\n\nstring result = await execution.GetResultAsync();\n'})})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'using namespace ignite;\n\ncompute comp = client.get_compute();\nstd::vector<cluster_node> nodes = client.get_nodes();\n\n// Unit `unitName:1.1.1` contains NodeNameJob class.\nauto job_desc = job_descriptor::builder("org.company.package.NodeNameJob")\n.deployment_units({deployment_unit{"unitName", "1.1.1"}})\n.build();\n\njob_execution execution = comp.submit(job_target::any_node(nodes), job_desc, {std::string("Hello")}, {});\nstd::string result = execution.get_result()->get<std::string>();\n'})})})]}),"\n",(0,s.jsx)(n.h3,{id:"multiple-node-execution",children:"Multiple Node Execution"}),"\n",(0,s.jsxs)(n.p,{children:["To execute the compute task on multiple nodes, you use the same methods as for single node execution, except instead of creating a ",(0,s.jsx)(n.code,{children:"JobTarget"})," object to designate execution nodes you use the ",(0,s.jsx)(n.code,{children:"BroadcastJobTarget"})," and specify the list of nodes that the job must be executed on."]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"BroadcastJobTarget"})," object can specify the following:"]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"BroadcastJobTarget.nodes()"})," - the job will be executed on all nodes in the list."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"BroadcastJobTarget.table()"})," - the job will be executed on all nodes that hold partitions of the specified table."]}),"\n"]}),"\n",(0,s.jsx)(n.p,{children:"You can control what nodes the task is executed on by setting the list of nodes:"}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'try (IgniteClient client = IgniteClient.builder()\n        .addresses("127.0.0.1:10800")\n        .build()\n) {\n\n    System.out.println("\\nConfiguring compute job...");\n\n\n    JobDescriptor<String, Void> job = JobDescriptor.builder(HelloMessageJob.class)\n            .units(new DeploymentUnit(DEPLOYMENT_UNIT_NAME, DEPLOYMENT_UNIT_VERSION))\n            .build();\n\n    BroadcastJobTarget target = BroadcastJobTarget.nodes(client.cluster().nodes());\n\n\n    System.out.println("\\nExecuting compute job...");\n\n    client.compute().execute(target, job, "John");\n\n    System.out.println("\\nCompute job executed...");\n}\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'ICompute compute = Client.Compute;\nIList<IClusterNode> nodes = await Client.GetClusterNodesAsync();\n\nIBroadcastExecution<string> execution = await compute.SubmitBroadcastAsync(\nBroadcastJobTarget.Nodes(nodes),\nnew JobDescriptor<object, string>("org.example.NodeNameJob"),\narg: "Hello");\n\nforeach (IJobExecution<string> jobExecution in execution.JobExecutions)\n{\nstring jobResult = await jobExecution.GetResultAsync();\nConsole.WriteLine($"Job result from node {jobExecution.Node}: {jobResult}");\n}\n'})})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'using namespace ignite;\n\ncompute comp = client.get_compute();\nstd::vector<cluster_node> nodes = client.get_nodes();\n\n// Unit `unitName:1.1.1` contains NodeNameJob class.\nauto job_desc = job_descriptor::builder("org.company.package.NodeNameJob")\n.deployment_units({deployment_unit{"unitName", "1.1.1"}})\n.build();\n\nbroadcast_execution execution = comp.submit_broadcast(broadcast_job_target::nodes(nodes), job_desc, {std::string("Hello")}, {});\nfor (auto &exec: execution.get_job_executions()) {\nstd::string result = exec.get_result()->get<std::string>();\n}\n'})})})]}),"\n",(0,s.jsx)(n.h3,{id:"colocated-execution",children:"Colocated Execution"}),"\n",(0,s.jsx)(n.p,{children:"In Apache Ignite, you can execute colocated computations by specifying a job target that directs the task to run on the node holding the required data."}),"\n",(0,s.jsxs)(n.p,{children:["In the example below, the job runs on the node that owns the partition for the row in the ",(0,s.jsx)(n.code,{children:"accounts"})," table identified by the primary key ",(0,s.jsx)(n.code,{children:"accountNumber"}),".\nWe pass the key both to ",(0,s.jsx)(n.code,{children:"JobTarget.colocated()"})," to select the node and as the\njob argument, so the job knows which record to read."]}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'try (IgniteClient client = IgniteClient.builder()\n        .addresses("127.0.0.1:10800")\n        .build()) {\n\n    System.out.println("\\nConfiguring compute job...");\n\n    JobDescriptor<Integer, Void> job = JobDescriptor.builder(PrintAccountInfoJob.class)\n                    .units(new DeploymentUnit(DEPLOYMENT_UNIT_NAME, DEPLOYMENT_UNIT_VERSION))\n                    .build();\n\n    int accountNumber = ThreadLocalRandom.current().nextInt(ACCOUNTS_COUNT);\n\n    JobTarget jobTarget = JobTarget.colocated("accounts", accountKey(accountNumber));\n    client.compute().execute(jobTarget, job, accountNumber);\n}\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'string table = "Person";\nstring key = "John";\n\nIJobExecution<string> execution = await Client.Compute.SubmitAsync(\nJobTarget.Colocated(table, key),\nnew JobDescriptor<string, string>("org.example.NodeNameJob"),\narg: "Hello");\n\nstring result = await execution.GetResultAsync();\n'})})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'using namespace ignite;\n\ncompute comp = client.get_compute();\nstd::string table{"Person"};\nstd::string key{"John"};\n\n// Unit `unitName:1.1.1` contains NodeNameJob class.\nauto job_desc = job_descriptor::builder("org.company.package.NodeNameJob")\n.deployment_units({deployment_unit{"unitName", "1.1.1"}})\n.build();\n\njob_execution execution = comp.submit(job_target::colocated(table, key), job_desc, {std::string("Hello")}, {});\nstd::string result = execution.get_result()->get<std::string>();\n'})})})]}),"\n",(0,s.jsxs)(n.p,{children:["Alternatively, you can execute the compute job on all nodes in the cluster that hold partitions for the specified table by creating a ",(0,s.jsx)(n.code,{children:"BroadcastJobTarget.table()"})," target. In this case, Apache Ignite will automatically find all nodes that hold data partitions for the specified table and execute the job on all of them."]}),"\n",(0,s.jsx)(n.h2,{id:"using-qualified-table-names",children:"Using Qualified Table Names"}),"\n",(0,s.jsxs)(n.p,{children:["If you do not specify the table schema, the ",(0,s.jsx)(n.code,{children:"PUBLIC"})," schema will be used. To use a different schema, specify a fully qualified table name. You can provide it in a string or by creating the ",(0,s.jsx)(n.code,{children:"QualifiedName"})," object:"]}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'QualifiedName myTableName = QualifiedName.parse("PUBLIC.MY_QUALIFIED_TABLE");\nString executionResult = client.compute()\n.execute(\nJobTarget.colocated(myTableName, Tuple.create(Map.of("k", 1))),\nJobDescriptor.builder(NodeNameJob.class).build(),\nnull\n);\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.p,{children:"Not supported"})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.p,{children:"Not supported"})})]}),"\n",(0,s.jsxs)(n.p,{children:["Just like with execution on a single node, you can use the ",(0,s.jsx)(n.code,{children:"QualifiedName"})," object to specify a qualified table name and run a job on multiple nodes using ",(0,s.jsx)(n.code,{children:"BroadcastJobTarget"}),":"]}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'QualifiedName customSchemaTable = QualifiedName.parse("CUSTOM_SCHEMA.MY_QUALIFIED_TABLE");\n\nclient.compute().execute(BroadcastJobTarget.table(customSchemaTable), JobDescriptor.builder(HelloMessageJob.class).build(), null);\n'})})})}),"\n",(0,s.jsxs)(n.p,{children:["You can also use the ",(0,s.jsx)(n.code,{children:"of"})," method to instead specify the table name and the schema separately:"]}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'QualifiedName customSchemaTableName = QualifiedName.of("PUBLIC", "MY_TABLE");\n\nclient.compute().execute(BroadcastJobTarget.table(customSchemaTableName), JobDescriptor.builder(HelloMessageJob.class).build(), null);\n'})})})}),"\n",(0,s.jsx)(n.p,{children:"The provided names must follow SQL syntax rules for identifiers:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:'Identifier must start from a character in the "Lu", "Ll", "Lt", "Lm", "Lo", or "Nl" Unicode categories;'}),"\n",(0,s.jsxs)(n.li,{children:["Identifier characters (except for the first one) may be ",(0,s.jsx)(n.code,{children:"U+00B7"})," (middle dot), ",(0,s.jsx)(n.code,{children:"U+0331"}),' (underscore), or any character in the "Mn", "Mc", "Nd", "Pc", or "Cf" Unicode categories;']}),"\n",(0,s.jsx)(n.li,{children:"Identifiers that contain any other characters must be quoted with double-quotes;"}),"\n",(0,s.jsx)(n.li,{children:"Double-quote inside the identifier must be 2 double-quote chars."}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["Any unquoted names will be cast to upper case. In this case, ",(0,s.jsx)(n.code,{children:"Person"})," and ",(0,s.jsx)(n.code,{children:"PERSON"})," names are equivalent. To avoid this, add escaped quotes around the name. For example, ",(0,s.jsx)(n.code,{children:'\\"Person\\"'})," will be encoded as a case-sensitive ",(0,s.jsx)(n.code,{children:"Person"})," name. If the name contains the ",(0,s.jsx)(n.code,{children:"U+2033"})," (double quote) symbol, it must be escaped as ",(0,s.jsx)(n.code,{children:'""'})," (2 double quote symbols)."]}),"\n",(0,s.jsx)(n.h2,{id:"net-compute-jobs",children:".NET Compute Jobs"}),"\n",(0,s.jsxs)(n.p,{children:["When working with compute jobs written in .NET, resulting binaries (DLL files) should be deployed to server nodes and invoked by the assembly-qualified type name. Every deployment unit combination is loaded into a separate ",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/dotnet/core/dependency-loading/understanding-assemblyloadcontext",children:"AssemblyLoadContext"}),"."]}),"\n",(0,s.jsx)(n.p,{children:"You can have multiple versions of the same job (assembly) deployed to the cluster as Apache Ignite supports deployment unit isolation. One job can consist of multiple deployment units. Assemblies and types are looked up in the order you list them."}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsxs)(n.p,{children:[".NET compute jobs are executed in a separate process (",(0,s.jsx)(n.a,{href:"https://learn.microsoft.com/en-us/azure/architecture/patterns/sidecar",children:"Sidecar"}),") on the server node. The process is started on the first .NET job call and then reused for subsequent jobs."]})}),"\n",(0,s.jsxs)(n.p,{children:["Compute job classes may implement ",(0,s.jsx)(n.code,{children:"IDisposable"})," and ",(0,s.jsx)(n.code,{children:"IAsyncDisposable"})," interfaces. Apache Ignite will call ",(0,s.jsx)(n.code,{children:"Dispose"})," or ",(0,s.jsx)(n.code,{children:"DisposeAsync"})," after job execution whether it succeeds or fails."]}),"\n",(0,s.jsx)(n.h3,{id:"net-compute-requirements",children:".NET Compute Requirements"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsx)(n.li,{children:".NET 8 Runtime or later (not SDK) is required on each server node."}),"\n",(0,s.jsx)(n.li,{children:"When using ZIP, DEB, RPM installation, you have to install .NET runtime yourself. Apache Ignite Docker image includes .NET 8 runtime, so you can run .NET jobs in Docker out of the box."}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"implementing-net-compute-jobs",children:"Implementing .NET Compute Jobs"}),"\n",(0,s.jsx)(n.p,{children:"Below is an example on implementing a .NET compute job:"}),"\n",(0,s.jsxs)(n.ol,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:['First, prepare a "class library" project for the job implementation using ',(0,s.jsx)(n.code,{children:"dotnet new classlib"}),"."]}),"\n",(0,s.jsx)(n.admonition,{type:"tip",children:(0,s.jsx)(n.p,{children:"In most cases, it is better to use a separate project for compute jobs to reduce deployment size."})}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"dotnet new classlib -n MyComputeJobs\ncd MyComputeJobs\ndotnet add package Apache.Ignite\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Add a reference to ",(0,s.jsx)(n.code,{children:"Apache.Ignite"})," package to the class library project:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"dotnet add package Apache.Ignite\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Then create a class that implements ",(0,s.jsx)(n.code,{children:"IComputeJob<TArg, TRes>"})," interface, for example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'public class HelloJob : IComputeJob<string, string>\n{\npublic ValueTask<string> ExecuteAsync(IJobExecutionContext context, string arg, CancellationToken cancellationToken) =>\nValueTask.FromResult("Hello " + arg);\n}\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Publish the project by using the ",(0,s.jsx)(n.code,{children:"dotnet publish -c Release"})," command:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-bash",children:"dotnet publish -c Release\nmkdir deploy\ncp bin/Release/net8.0/MyComputeJobs.dll deploy/\n# Exclude Ignite assemblies; no subdirectories allowed\nignite cluster unit deploy --name MyDotNetJobsUnit --path ./deploy\n"})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Copy the resulting dll file and any extra dependencies to a separate directory, ",(0,s.jsx)(n.strong,{children:"excluding"})," Apache Ignite dlls."]}),"\n",(0,s.jsx)(n.admonition,{type:"note",children:(0,s.jsx)(n.p,{children:"The directory with the dll must not contain any subdirectories."})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["Use the Apache Ignite CLI command ",(0,s.jsx)(n.code,{children:"cluster unit deploy command"})," to ",(0,s.jsx)(n.a,{href:"./code-deployment",children:"deploy"})," the directory to the cluster as a deployment unit. The deployed code will be available on the cluster."]}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h3,{id:"running-net-compute-jobs",children:"Running .NET Compute Jobs"}),"\n",(0,s.jsxs)(n.p,{children:["You can execute .NET compute jobs from any client (.NET, Java, C++, etc) as long as you created a ",(0,s.jsx)(n.code,{children:"JobDescriptor"})," with the assembly-qualified job class name and set ",(0,s.jsx)(n.code,{children:"JobExecutionOptions"})," with ",(0,s.jsx)(n.code,{children:"JobExecutorType.DotNetSidecar"}),"."]}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"For example, this is how to run your job on a single node from .NET:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'var jobTarget = JobTarget.AnyNode(await client.GetClusterNodesAsync());\nvar jobDesc = new JobDescriptor<string, string>(\nJobClassName: typeof(HelloJob).AssemblyQualifiedName!,\nDeploymentUnits: [new DeploymentUnit("MyDeploymentUnit")],\nOptions: new JobExecutionOptions(ExecutorType: JobExecutorType.DotNetSidecar));\n\nIJobExecution<string> jobExec = await client.Compute.SubmitAsync(jobTarget, jobDesc, "world");\n'})}),"\n",(0,s.jsxs)(n.p,{children:["Alternatively, use the ",(0,s.jsx)(n.code,{children:"JobDescriptor.Of"})," shortcut method to create a job descriptor from a job instance:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'JobDescriptor<string, string> jobDesc = JobDescriptor.Of(new HelloJob())\nwith { DeploymentUnits = [new DeploymentUnit("MyDeploymentUnit")] };\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsxs)(n.p,{children:["You can call ",(0,s.jsx)(n.a,{href:"./compute",children:"Java computing jobs"})," from your .NET code, for example:"]}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'IList<IClusterNode> nodes = await client.GetClusterNodesAsync();\nIJobTarget<IEnumerable<IClusterNode>> jobTarget = JobTarget.AnyNode(nodes);\n\nvar jobDesc = new JobDescriptor<string, string>(JobClassName: "org.foo.bar.MyJob", DeploymentUnits: [new DeploymentUnit("MyDeploymentUnit")]);\n\nIJobExecution<string> jobExecution = await client.Compute.SubmitAsync(jobTarget, jobDesc, "Job Arg");\n\nstring jobResult = await jobExecution.GetResultAsync();\n'})}),"\n"]}),"\n",(0,s.jsxs)(n.li,{children:["\n",(0,s.jsx)(n.p,{children:"You can also run .NET compute jobs from Java client, for example:"}),"\n",(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'try (IgniteClient client = IgniteClient.builder().addresses("127.0.0.1:10800")\n.build()\n) {\n\nJobDescriptor<String, String> jobDesc = JobDescriptor.<String, String>builder().jobClassName("MyNamespace.HelloJob, MyComputeJobsAssembly").deploymentUnits(new DeploymentUnit("MyDeploymentUnit")).executionOptions(new JobExecutionOptions().executorType(JobExecutorType.DotNetSidecar)).build();\n\nJobTarget jobTarget = JobTarget.anyNode(client.clusterNodes());\nfor (String word : "Print words using runnable".split(" ")) {\n\n    System.out.println("\\nExecuting compute job for word \'" + word + "\'...");\n\n    client.compute().execute(jobTarget, job, word);\n    }\n}\n'})}),"\n"]}),"\n"]}),"\n",(0,s.jsx)(n.h2,{id:"job-ownership",children:"Job Ownership"}),"\n",(0,s.jsxs)(n.p,{children:["If the cluster has ",(0,s.jsx)(n.a,{href:"/3.1.0/configure-and-operate/configuration/config-authentication",children:"Authentication"})," enabled, compute jobs are executed by a specific user. If user permissions are configured on the cluster, the user needs the appropriate ",(0,s.jsx)(n.a,{href:"/3.1.0/configure-and-operate/configuration/config-cluster-security",children:"distributed computing permissions"})," to work with distributed computing jobs. Only users with ",(0,s.jsx)(n.code,{children:"JOBS_ADMIN"})," action can interact with jobs of other users."]}),"\n",(0,s.jsx)(n.h2,{id:"job-execution-states",children:"Job Execution States"}),"\n",(0,s.jsx)(n.p,{children:"When using asynchronous API, you can keep track of the status of the job on the server and react to status changes. For example:"}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'public static void example() throws ExecutionException, InterruptedException {\nIgniteClient client = IgniteClient.builder().addresses("127.0.0.1:10800").build();\n\nCompletableFuture<JobExecution<Void>> execution = client.compute().submitAsync(JobTarget.anyNode(client.cluster().nodes()), JobDescriptor.builder(WordPrintJob.class).build(), null);\n\nexecution.get().stateAsync().thenApply(state -> {\n                if (state.status() == FAILED) {\n                    System.out.println("\\nJob failed...");\n                }\n                return null;\n            });\n            System.out.println(execution.resultAsync().get());\n}\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'IList<IClusterNode> nodes = await Client.GetClusterNodesAsync();\n\nIJobExecution<string> execution = await Client.Compute.SubmitAsync(\n    JobTarget.AnyNode(nodes),\n    new JobDescriptor<string, string>("org.example.NodeNameJob"),\n    arg: "Hello");\n\nJobState? state = await execution.GetStateAsync();\n\nif (state?.Status == JobStatus.Failed)\n{\n    // Handle failure\n}\n\nstring result = await execution.GetResultAsync();\n'})})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'using namespace ignite;\n\ncompute comp = client.get_compute();\nstd::vector<cluster_node> nodes = client.get_nodes();\n\n// Unit `unitName:1.1.1` contains NodeNameJob class.\nauto job_desc = job_descriptor::builder("org.company.package.NodeNameJob")\n\t.deployment_units({deployment_unit{"unitName", "1.1.1"}})\n\t.build();\n\njob_execution execution = comp.submit(job_target::any_node(nodes), job_desc, {std::string("Hello")}, {});\n\nstd::optional<job_status> status = execution.get_status();\nif (status && status->state == job_state::FAILED)\n{\n    // Handle failure\n}\nstd::string result = execution.get_result()->get<std::string>();\n'})})})]}),"\n",(0,s.jsx)(n.h3,{id:"possible-states-and-transitions",children:"Possible States and Transitions"}),"\n",(0,s.jsx)(n.p,{children:"The diagram below depicts the possible transitions of job statuses:"}),"\n",(0,s.jsx)(n.p,{children:(0,s.jsx)(n.img,{alt:"Compute Job Statuses",src:t(67930).A+"",width:"1659",height:"728"})}),"\n",(0,s.jsx)(n.p,{children:"The table below lists the possible job statuses:"}),"\n",(0,s.jsxs)(n.table,{children:[(0,s.jsx)(n.thead,{children:(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.th,{children:"Status"}),(0,s.jsx)(n.th,{children:"Description"}),(0,s.jsx)(n.th,{children:"Transitions to"})]})}),(0,s.jsxs)(n.tbody,{children:[(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Queued"})}),(0,s.jsx)(n.td,{children:"The job was added to the queue and is waiting for execution."}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"Executing"}),", ",(0,s.jsx)(n.code,{children:"Canceled"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Executing"})}),(0,s.jsx)(n.td,{children:"The job is being executed."}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"Canceling"}),", ",(0,s.jsx)(n.code,{children:"Completed"}),", ",(0,s.jsx)(n.code,{children:"Queued"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Completed"})}),(0,s.jsx)(n.td,{children:"The job was executed successfully and the execution result was returned."}),(0,s.jsx)(n.td,{})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Failed"})}),(0,s.jsx)(n.td,{children:"The job was unexpectedly terminated during execution."}),(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Queued"})})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Canceling"})}),(0,s.jsx)(n.td,{children:"Job has received the cancel command, but is still running."}),(0,s.jsxs)(n.td,{children:[(0,s.jsx)(n.code,{children:"Completed"}),", ",(0,s.jsx)(n.code,{children:"Canceled"})]})]}),(0,s.jsxs)(n.tr,{children:[(0,s.jsx)(n.td,{children:(0,s.jsx)(n.code,{children:"Canceled"})}),(0,s.jsx)(n.td,{children:"Job was successfully cancelled."}),(0,s.jsx)(n.td,{})]})]})]}),"\n",(0,s.jsxs)(n.p,{children:["If all job execution threads are busy, new jobs received by the node are put into job queue according to their ",(0,s.jsx)(n.a,{href:"#job-priority",children:"Job Priority"}),". Apache Ignite sorts all incoming jobs first by priority, then by the time, executing jobs queued earlier first."]}),"\n",(0,s.jsx)(n.h3,{id:"cancelling-executing-jobs",children:"Cancelling Executing Jobs"}),"\n",(0,s.jsxs)(n.p,{children:["When the node receives the command to cancel the job in the ",(0,s.jsx)(n.code,{children:"Executing"})," status, it will immediately send an interrupt to the thread that is responsible for the job. In most cases, this will lead to the job being immediately canceled, however there are cases in which the job will continue. If this happens, the job will be in the ",(0,s.jsx)(n.code,{children:"Canceling"})," state. Depending on specific code being executed, the job may complete successfully, be canceled once the uninterruptible operation is finished, or remain in unfinished state (for example, if code is stuck in a loop). You can use the ",(0,s.jsx)(n.code,{children:"JobExecution.stateAsync()"})," method to keep track of what status the job is in, and react to status change."]}),"\n",(0,s.jsx)(n.p,{children:"To be able to cancel a compute job, you first create a cancel handler and retrieve a token from it. You can then use this token to cancel the compute job:"}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:"CancelHandle cancelHandle = CancelHandle.create();\nCancellationToken cancelToken = cancelHandle.token();\n\nCompletableFuture<Void> execution = client.compute().executeAsync(JobTarget.anyNode(client.clusterNodes()), JobDescriptor.builder(NodeNameJob.class).build(), cancelToken, null);\n\ncancelHandle.cancel();\n"})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:"var cts = new CancellationTokenSource();\nCancellationToken cancelToken = cts.Token;\n\nvar execution = client.Compute.ExecuteAsync(\nJobTarget.AnyNode(await client.GetClusterNodesAsync()),\nnew JobDescriptor(typeof(NodeNameJob)),\ncancelToken);\n\ncts.Cancel();\n"})})})]}),"\n",(0,s.jsxs)(n.p,{children:["Another way to cancel jobs is by using the SQL ",(0,s.jsx)(n.a,{href:"/3.1.0/sql/reference/data-types-and-functions/operational-commands#kill-compute",children:"KILL COMPUTE"})," command. The job id can be retrieved via the ",(0,s.jsx)(n.code,{children:"COMPUTE_JOBS"})," ",(0,s.jsx)(n.a,{href:"/3.1.0/configure-and-operate/monitoring/metrics-system-views",children:"system view"}),"."]}),"\n",(0,s.jsx)(n.h3,{id:"job-priority",children:"Job Priority"}),"\n",(0,s.jsxs)(n.p,{children:["You can specify a job priority by setting the ",(0,s.jsx)(n.code,{children:"JobExecutionOptions.priority"})," property. Jobs with a higher priority will be queued before jobs with lower priority (for example, a job with priority 4 will be executed before the job with priority 2)."]}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'public static void example() throws ExecutionException, InterruptedException {\ntry (IgniteClient client = IgniteClient.builder().addresses("127.0.0.1:10800").build()) {\n\n    // Create job execution options\n    JobExecutionOptions options = JobExecutionOptions.builder().priority(1).build();\n\n    String executionResult = client.compute().execute(JobTarget.anyNode(client.cluster().nodes()),\n            JobDescriptor.builder(HighPriorityJob.class).options(options).build(), null\n    );\n\n    System.out.println(executionResult);\n    }\n}\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'var options = JobExecutionOptions.Default with { Priority = 1 };\n\nIJobExecution<string> execution = await Client.Compute.SubmitAsync(\n    JobTarget.AnyNode(await Client.GetClusterNodesAsync()),\n    new JobDescriptor<string, string>("org.example.NodeNameJob", Options: options),\n    arg: "Hello");\n\nstring result = await execution.GetResultAsync();\n'})})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'using namespace ignite;\n\ncompute comp = client.get_compute();\nstd::vector<cluster_node> nodes = client.get_nodes();\n\n// Unit `unitName:1.1.1` contains NodeNameJob class.\nauto job_desc = job_descriptor::builder("org.company.package.NodeNameJob")\n\t.deployment_units({deployment_unit{"unitName", "1.1.1"}})\n\t.build();\n\njob_execution_options options{1, 0};\njob_execution execution = comp.submit(job_target::any_node(nodes), job_desc, {std::string("Hello")}, std::move(options));\nstd::string result = execution.get_result()->get<std::string>();\n'})})})]}),"\n",(0,s.jsx)(n.h3,{id:"job-retries",children:"Job Retries"}),"\n",(0,s.jsxs)(n.p,{children:["You can set the number the job will be retried on failure by setting the ",(0,s.jsx)(n.code,{children:"JobExecutionOptions.maxRetries"})," property. If set, the failed job will be retried the specified number of times before moving to ",(0,s.jsx)(n.code,{children:"Failed"})," state."]}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'public static void example() throws ExecutionException, InterruptedException {\ntry (IgniteClient client = IgniteClient.builder().addresses("127.0.0.1:10800").build()) {\n\n   // Create job execution options with maxRetries set to 5.\n    JobExecutionOptions options = JobExecutionOptions.builder()\n                                                          .maxRetries(5)\n                                                          .build();\n\n    String executionResult = client.compute().execute(JobTarget.anyNode(client.clusterNodes()),\n            JobDescriptor.builder(NodeNameJob.class).options(options).build(), null\n    );\n\n    System.out.println(executionResult);\n    }\n}\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'var options = JobExecutionOptions.Default with { MaxRetries = 5 };\n\nIJobExecution<string> execution = await Client.Compute.SubmitAsync(\n    JobTarget.AnyNode(await Client.GetClusterNodesAsync()),\n    new JobDescriptor<string, string>("org.example.NodeNameJob", Options: options),\n    arg: "Hello");\n\nstring result = await execution.GetResultAsync();\n'})})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-cpp",children:'using namespace ignite;\n\ncompute comp = client.get_compute();\nstd::vector<cluster_node> nodes = client.get_nodes();\n\n// Unit `unitName:1.1.1` contains NodeNameJob class.\nstd::vector<deployment_unit> units{deployment_unit{"unitName", "1.1.1"}};\n\njob_execution_options options{0, 5};\njob_execution execution = comp.submit(nodes, units, NODE_NAME_JOB, {std::string("Hello")}, std::move(options));\nstd::string result = execution.get_result()->get<std::string>();\n'})})})]}),"\n",(0,s.jsx)(n.h2,{id:"job-failover",children:"Job Failover"}),"\n",(0,s.jsx)(n.p,{children:"Apache Ignite implements mechanics to handle issues that happen during job execution. The following situations are handled:"}),"\n",(0,s.jsx)(n.h3,{id:"worker-node-shutdown",children:"Worker Node Shutdown"}),"\n",(0,s.jsx)(n.p,{children:"If the worker node is shut down, the coordinator node will redistribute all jobs assigned to worker to other viable nodes. If no nodes are found, the job will fail and an exception will be sent to the client."}),"\n",(0,s.jsx)(n.h3,{id:"coordinator-node-shutdown",children:"Coordinator Node Shutdown"}),"\n",(0,s.jsxs)(n.p,{children:["If the coordinator node shuts down, all jobs will be cancelled as soon as the node detects that the coordinator is shut down. Note that ",(0,s.jsx)(n.a,{href:"#cancelling-executing-jobs",children:"some jobs"})," may take a long time to cancel."]}),"\n",(0,s.jsx)(n.h3,{id:"client-disconnect",children:"Client Disconnect"}),"\n",(0,s.jsxs)(n.p,{children:["If the client disconnects, all jobs will be cancelled as soon as the coordinator node detects the disconnect. Note that ",(0,s.jsx)(n.a,{href:"#cancelling-executing-jobs",children:"some jobs"})," may take a long time to cancel."]}),"\n",(0,s.jsx)(n.h2,{id:"mapreduce-tasks",children:"MapReduce Tasks"}),"\n",(0,s.jsx)(n.p,{children:"Apache Ignite provides an API for performing MapReduce operations in the cluster. This allows you to split your computing task between multiple nodes before aggregating the result and returning it to the user."}),"\n",(0,s.jsx)(n.h3,{id:"understanding-mapreduce-tasks",children:"Understanding MapReduce Tasks"}),"\n",(0,s.jsxs)(n.p,{children:["A MapReduce task must be executed on a node that has a ",(0,s.jsx)(n.a,{href:"./code-deployment",children:"deployed"})," class implementing the ",(0,s.jsx)(n.code,{children:"MapReduceTask"})," interface. This interface provides a way to implement custom map and reduce logic. A node that receives the task becomes a coordinator node, that will be responsible for both mapping tasks to other nodes, reducing their results and returning the final result to the client."]}),"\n",(0,s.jsxs)(n.p,{children:["The class must implement two methods: ",(0,s.jsx)(n.code,{children:"splitAsync"})," and ",(0,s.jsx)(n.code,{children:"reduceAsync"}),"."]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"splitAsync()"})," method should be implemented to create compute jobs based on input parameters and map them to worker nodes. The method receives the execution context and your task arguments and returns a completable future containing the list of the job descriptors that will be sent to the worker nodes."]}),"\n",(0,s.jsxs)(n.p,{children:["The ",(0,s.jsx)(n.code,{children:"reduceAsync()"})," method is called during the reduce step, when all the jobs have completed. The method receives a map from the worker node to the completed job result and returns the final result of the computation."]}),"\n",(0,s.jsx)(n.h3,{id:"creating-a-mapper-class",children:"Creating a Mapper Class"}),"\n",(0,s.jsxs)(n.p,{children:["All MapReduce jobs must be submitted to a node that has an appropriate class ",(0,s.jsx)(n.a,{href:"./code-deployment",children:"deployed"}),". Below is an example of a map reduce job:"]}),"\n",(0,s.jsx)(a.A,{children:(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'public static class PhraseWordLengthCountMapReduceTask implements MapReduceTask<String, String, Integer, Integer> {\n    /** {@inheritDoc} */\n    @Override\n    public CompletableFuture<List<MapReduceJob<String, Integer>>> splitAsync(\n            TaskExecutionContext taskContext,\n            String input) {\n        assert input != null;\n\n        var job = JobDescriptor.builder(WordLengthJob.class)\n                .units(new DeploymentUnit(DEPLOYMENT_UNIT_NAME, DEPLOYMENT_UNIT_VERSION))\n                .build();\n\n        List<MapReduceJob<String, Integer>> jobs = new ArrayList<>();\n\n        for (String word : input.split(" ")) {\n            jobs.add(\n                    MapReduceJob.<String, Integer>builder()\n                            .jobDescriptor(job)\n                            .nodes(taskContext.ignite().cluster().nodes())\n                            .args(word)\n                            .build()\n            );\n        }\n\n        return completedFuture(jobs);\n    }\n\n    /** {@inheritDoc} */\n    @Override\n    public CompletableFuture<Integer> reduceAsync(TaskExecutionContext taskContext, Map<UUID, Integer> results) {\n        return completedFuture(results.values().stream()\n                .reduce(Integer::sum)\n                .orElseThrow());\n    }\n}\n'})})})}),"\n",(0,s.jsx)(n.h3,{id:"executing-a-mapreduce-task",children:"Executing a MapReduce Task"}),"\n",(0,s.jsx)(n.p,{children:"To execute the MapReduce task, you use one of the following methods:"}),"\n",(0,s.jsxs)(n.ul,{children:["\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"submitMapReduce()"})," - sends the MapReduce job to the cluster and returns the ",(0,s.jsx)(n.code,{children:"TaskExecution"})," object that can be used to monitor or modify the compute task execution."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"executeMapReduceAsync()"})," - sends the MapReduce job to the cluster in the cluster and gets the future for job execution results."]}),"\n",(0,s.jsxs)(n.li,{children:[(0,s.jsx)(n.code,{children:"executeMapReduce()"})," - sends the job to the cluster and waits for the result of job execution."]}),"\n"]}),"\n",(0,s.jsxs)(n.p,{children:["The node that the MapReduce task is sent to must have a class implementing the ",(0,s.jsx)(n.code,{children:"MapReduceTask"})," interface."]}),"\n",(0,s.jsxs)(a.A,{children:[(0,s.jsx)(r.A,{value:"java",label:"Java",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-java",children:'try (IgniteClient client = IgniteClient.builder().addresses("127.0.0.1:10800").build()) {\n\n    System.out.println("\\nConfiguring map reduce task...");\n\n\n    TaskDescriptor<String, Integer> taskDescriptor = TaskDescriptor.builder(PhraseWordLengthCountMapReduceTask.class)\n            .units(new DeploymentUnit(DEPLOYMENT_UNIT_NAME, DEPLOYMENT_UNIT_VERSION))\n            .build();\n\n\n    System.out.println("\\nExecuting map reduce task...");\n\n    String phrase = "Count characters using map reduce";\n\n    Integer result = client.compute().executeMapReduce(taskDescriptor, phrase);\n\n\n    System.out.println("\\nTotal number of characters in the words is \'" + result + "\'.");\n}\n'})})}),(0,s.jsx)(r.A,{value:"dotnet",label:".NET",children:(0,s.jsx)(n.pre,{children:(0,s.jsx)(n.code,{className:"language-csharp",children:'ICompute compute = Client.Compute;\nvar taskDescriptor = new TaskDescriptor<string, string>("com.example.MapReduceNodeNameTask");\nITaskExecution<string> exec = await compute.SubmitMapReduceAsync(taskDescriptor, "arg");\nstring result = await exec.GetResultAsync();\nConsole.WriteLine(result);\n'})})}),(0,s.jsx)(r.A,{value:"cpp",label:"C++",children:(0,s.jsx)(n.p,{children:"Not supported"})})]})]})}function p(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,s.jsx)(n,{...e,children:(0,s.jsx)(h,{...e})}):h(e)}}}]);