"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[4766],{11470:(e,t,a)=>{a.d(t,{A:()=>j});var n=a(96540),r=a(34164),s=a(17559),i=a(23104),l=a(56347),o=a(205),c=a(57485),u=a(31682),d=a(70679);function m(e){return n.Children.toArray(e).filter(e=>"\n"!==e).map(e=>{if(!e||(0,n.isValidElement)(e)&&function(e){const{props:t}=e;return!!t&&"object"==typeof t&&"value"in t}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)})?.filter(Boolean)??[]}function p(e){const{values:t,children:a}=e;return(0,n.useMemo)(()=>{const e=t??function(e){return m(e).map(({props:{value:e,label:t,attributes:a,default:n}})=>({value:e,label:t,attributes:a,default:n}))}(a);return function(e){const t=(0,u.XI)(e,(e,t)=>e.value===t.value);if(t.length>0)throw new Error(`Docusaurus error: Duplicate values "${t.map(e=>e.value).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e},[t,a])}function h({value:e,tabValues:t}){return t.some(t=>t.value===e)}function g({queryString:e=!1,groupId:t}){const a=(0,l.W6)(),r=function({queryString:e=!1,groupId:t}){if("string"==typeof e)return e;if(!1===e)return null;if(!0===e&&!t)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return t??null}({queryString:e,groupId:t});return[(0,c.aZ)(r),(0,n.useCallback)(e=>{if(!r)return;const t=new URLSearchParams(a.location.search);t.set(r,e),a.replace({...a.location,search:t.toString()})},[r,a])]}function b(e){const{defaultValue:t,queryString:a=!1,groupId:r}=e,s=p(e),[i,l]=(0,n.useState)(()=>function({defaultValue:e,tabValues:t}){if(0===t.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(e){if(!h({value:e,tabValues:t}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${e}" but none of its children has the corresponding value. Available values are: ${t.map(e=>e.value).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return e}const a=t.find(e=>e.default)??t[0];if(!a)throw new Error("Unexpected error: 0 tabValues");return a.value}({defaultValue:t,tabValues:s})),[c,u]=g({queryString:a,groupId:r}),[m,b]=function({groupId:e}){const t=function(e){return e?`docusaurus.tab.${e}`:null}(e),[a,r]=(0,d.Dv)(t);return[a,(0,n.useCallback)(e=>{t&&r.set(e)},[t,r])]}({groupId:r}),v=(()=>{const e=c??m;return h({value:e,tabValues:s})?e:null})();(0,o.A)(()=>{v&&l(v)},[v]);return{selectedValue:i,selectValue:(0,n.useCallback)(e=>{if(!h({value:e,tabValues:s}))throw new Error(`Can't select invalid tab value=${e}`);l(e),u(e),b(e)},[u,b,s]),tabValues:s}}var v=a(92303);const x={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var y=a(74848);function T({className:e,block:t,selectedValue:a,selectValue:n,tabValues:s}){const l=[],{blockElementScrollPositionUntilNextRender:o}=(0,i.a_)(),c=e=>{const t=e.currentTarget,r=l.indexOf(t),i=s[r].value;i!==a&&(o(t),n(i))},u=e=>{let t=null;switch(e.key){case"Enter":c(e);break;case"ArrowRight":{const a=l.indexOf(e.currentTarget)+1;t=l[a]??l[0];break}case"ArrowLeft":{const a=l.indexOf(e.currentTarget)-1;t=l[a]??l[l.length-1];break}}t?.focus()};return(0,y.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,r.A)("tabs",{"tabs--block":t},e),children:s.map(({value:e,label:t,attributes:n})=>(0,y.jsx)("li",{role:"tab",tabIndex:a===e?0:-1,"aria-selected":a===e,ref:e=>{l.push(e)},onKeyDown:u,onClick:c,...n,className:(0,r.A)("tabs__item",x.tabItem,n?.className,{"tabs__item--active":a===e}),children:t??e},e))})}function I({lazy:e,children:t,selectedValue:a}){const s=(Array.isArray(t)?t:[t]).filter(Boolean);if(e){const e=s.find(e=>e.props.value===a);return e?(0,n.cloneElement)(e,{className:(0,r.A)("margin-top--md",e.props.className)}):null}return(0,y.jsx)("div",{className:"margin-top--md",children:s.map((e,t)=>(0,n.cloneElement)(e,{key:t,hidden:e.props.value!==a}))})}function f(e){const t=b(e);return(0,y.jsxs)("div",{className:(0,r.A)(s.G.tabs.container,"tabs-container",x.tabList),children:[(0,y.jsx)(T,{...t,...e}),(0,y.jsx)(I,{...t,...e})]})}function j(e){const t=(0,v.A)();return(0,y.jsx)(f,{...e,children:m(e.children)},String(t))}},19365:(e,t,a)=>{a.d(t,{A:()=>i});a(96540);var n=a(34164);const r={tabItem:"tabItem_Ymn6"};var s=a(74848);function i({children:e,hidden:t,className:a}){return(0,s.jsx)("div",{role:"tabpanel",className:(0,n.A)(r.tabItem,a),hidden:t,children:e})}},28453:(e,t,a)=>{a.d(t,{R:()=>i,x:()=>l});var n=a(96540);const r={},s=n.createContext(r);function i(e){const t=n.useContext(s);return n.useMemo(function(){return"function"==typeof e?e(t):{...t,...e}},[t,e])}function l(e){let t;return t=e.disableParentContext?"function"==typeof e.components?e.components(r):e.components||r:i(e.components),n.createElement(s.Provider,{value:t},e.children)}},29723:(e,t,a)=>{a.d(t,{A:()=>n});const n=a.p+"assets/images/data_streaming-6b2d018b11aa91d7b373e308efcd713f.png"},59464:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>u,contentTitle:()=>c,default:()=>p,frontMatter:()=>o,metadata:()=>n,toc:()=>d});const n=JSON.parse('{"id":"developers-guide/data-streamer","title":"Streaming Data","description":"{/*","source":"@site/versioned_docs/version-3.0.0/developers-guide/data-streamer.md","sourceDirName":"developers-guide","slug":"/developers-guide/data-streamer","permalink":"/suggested-site/docs/ignite3/3.0.0/developers-guide/data-streamer","draft":false,"unlisted":false,"tags":[],"version":"3.0.0","frontMatter":{"title":"Streaming Data","sidebar_label":"Streaming Data"},"sidebar":"tutorialSidebar","previous":{"title":"Performing Transactions","permalink":"/suggested-site/docs/ignite3/3.0.0/developers-guide/transactions"},"next":{"title":"Code Deployment","permalink":"/suggested-site/docs/ignite3/3.0.0/developers-guide/code-deployment/"}}');var r=a(74848),s=a(28453),i=a(11470),l=a(19365);const o={title:"Streaming Data",sidebar_label:"Streaming Data"},c=void 0,u={},d=[{value:"Using Data Streamer API",id:"using-data-streamer-api",level:2},{value:"Configuring Data Streamer",id:"configuring-data-streamer",level:3},{value:"Streaming Data",id:"streaming-data",level:3},{value:"Streaming with Receiver",id:"streaming-with-receiver",level:3},{value:"Examples",id:"examples",level:3},{value:"Updating Multiple Tables",id:"updating-multiple-tables",level:4},{value:"Distributed Computations",id:"distributed-computations",level:4},{value:"Custom Marshallers in .NET",id:"custom-marshallers-in-net",level:4},{value:"Tracking Failed Entries",id:"tracking-failed-entries",level:2},{value:"Tuning Memory Usage",id:"tuning-memory-usage",level:3}];function m(e){const t={a:"a",code:"code",h2:"h2",h3:"h3",h4:"h4",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,s.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:["\n","\n",(0,r.jsx)(t.p,{children:"Data streaming provides a fast, efficient method for loading, organizing, and distributing large volumes of data across your cluster.\nData streamer accepts a stream of data and distributes data entries across the cluster, where the processing takes place. Data streaming is available in all table views."}),"\n",(0,r.jsx)(t.p,{children:(0,r.jsx)(t.img,{alt:"Data streaming diagram",src:a(29723).A+"",width:"1278",height:"673"})}),"\n",(0,r.jsx)(t.p,{children:"Data streaming provides at-least-once delivery guarantee."}),"\n",(0,r.jsx)(t.h2,{id:"using-data-streamer-api",children:"Using Data Streamer API"}),"\n",(0,r.jsxs)(t.p,{children:["The ",(0,r.jsx)(t.a,{href:"https://ignite.apache.org/releases/3.0.0/javadoc/org/apache/ignite/table/DataStreamerTarget.html",children:"Data Streamer API"})," lets you load large amounts of data into your cluster quickly and reliably using a publisher\u2013subscriber model, where you create a publisher that streams your data entries to a table view, and the system distributes these entries across the cluster. You can configure how the data is processed via a ",(0,r.jsx)(t.code,{children:"DataStreamerOptions"})," object that allows to set batch sizes, auto-flush intervals, retry limits."]}),"\n",(0,r.jsx)(t.h3,{id:"configuring-data-streamer",children:"Configuring Data Streamer"}),"\n",(0,r.jsxs)(t.p,{children:[(0,r.jsx)(t.code,{children:"DataStreamerOptions"})," lets you fine-tune how data is streamed into your cluster by setting parameters for batching, retries, parallelism, and auto-flush timing:"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:"DataStreamerOptions options = DataStreamerOptions.builder()\n.pageSize(1000)\n.perPartitionParallelOperations(1)\n.autoFlushInterval(1000)\n.retryLimit(16)\n.build();\n"})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:"var options = new DataStreamerOptions\n{\n    PageSize = 1000,\n    RetryLimit = 8,\n    AutoFlushInterval = TimeSpan.FromSeconds(3)\n};\n"})})})]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"pageSize"}),": Specifies the number of entries to process in each page or chunk of data."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"perPartitionParallelOperations"}),": Determines the number of parallel operations allowed on each partition."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"autoFlushInterval"}),": Defines the time interval (in milliseconds) after which the system automatically flushes any incomplete buffers."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"retryLimit"}),": Specifies the maximum number of retry attempts for a failed data submission before giving up."]}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"streaming-data",children:"Streaming Data"}),"\n",(0,r.jsxs)(t.p,{children:["Before data is streamed to the cluster, each entry must be wrapped in an instance of the ",(0,r.jsx)(t.code,{children:"DataStreamerItem<T>"})," class. This wrapper allows you to perform ",(0,r.jsx)(t.code,{children:"PUT"})," and ",(0,r.jsx)(t.code,{children:"REMOVE"})," operations with data:"]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Use ",(0,r.jsx)(t.code,{children:"DataStreamerItem.of(entry)"})," to insert new entries into the table."]}),"\n"]}),"\n",(0,r.jsxs)(t.li,{children:["\n",(0,r.jsxs)(t.p,{children:["Use ",(0,r.jsx)(t.code,{children:"DataStreamerItem.removed(entry)"})," to delete existing ones."]}),"\n"]}),"\n"]}),"\n",(0,r.jsx)(t.p,{children:"Wrapped data then can be passed to a publisher and streamed to the table."}),"\n",(0,r.jsxs)(t.p,{children:["The example below demonstrates how to use ",(0,r.jsx)(t.a,{href:"/suggested-site/docs/ignite3/3.0.0/developers-guide/table-api#record-view",children:(0,r.jsx)(t.code,{children:"RecordView"})}),", create a publisher, configure the data streamer, insert account records into the existing ",(0,r.jsx)(t.code,{children:"accounts"})," table and then delete them:"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:'public class RecordViewPojoDataStreamerExample {\n    private static final int ACCOUNTS_COUNT = 1000;\n\n    public static void main(String[] args) throws Exception {\n        /**\n         * Assuming the \'accounts\' table already exists.\n         */\n        try (IgniteClient client = IgniteClient.builder()\n                .addresses("127.0.0.1:10800")\n                .build()) {\n            RecordView<Account> view = client.tables().table("accounts").recordView(Account.class);\n\n            streamAccountDataPut(view);\n            streamAccountDataRemove(view);\n        }\n    }\n\n    /**\n     * Streaming data using DataStreamerOperationType#PUT operation type.\n     */\n    private static void streamAccountDataPut(RecordView<Account> view) {\n        DataStreamerOptions options = DataStreamerOptions.builder()\n                .pageSize(1000)\n                .perPartitionParallelOperations(1)\n                .autoFlushInterval(1000)\n                .retryLimit(16)\n                .build();\n\n        CompletableFuture<Void> streamerFut;\n        try (var publisher = new SubmissionPublisher<DataStreamerItem<Account>>()) {\n            streamerFut = view.streamData(publisher, options);\n            ThreadLocalRandom rnd = ThreadLocalRandom.current();\n            for (int i = 0; i < ACCOUNTS_COUNT; i++) {\n                Account entry = new Account(i, "name" + i, rnd.nextLong(100_000), rnd.nextBoolean());\n                publisher.submit(DataStreamerItem.of(entry));\n            }\n        }\n        streamerFut.join();\n    }\n\n    /**\n     * Streaming data using DataStreamerOperationType#REMOVE operation type\n     */\n    private static void streamAccountDataRemove(RecordView<Account> view) {\n        DataStreamerOptions options = DataStreamerOptions.builder()\n                .pageSize(1000)\n                .perPartitionParallelOperations(1)\n                .autoFlushInterval(1000)\n                .retryLimit(16)\n                .build();\n\n        CompletableFuture<Void> streamerFut;\n        try (var publisher = new SubmissionPublisher<DataStreamerItem<Account>>()) {\n            streamerFut = view.streamData(publisher, options);\n            for (int i = 0; i < ACCOUNTS_COUNT; i++) {\n                Account entry = new Account(i);\n                publisher.submit(DataStreamerItem.removed(entry));\n            }\n        }\n        streamerFut.join();\n    }\n}\n'})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:'using Apache.Ignite;\nusing Apache.Ignite.Table;\n\nusing var client = await IgniteClient.StartAsync(new("localhost"));\nITable? table = await client.Tables.GetTableAsync("accounts");\nIRecordView<Account> view = table!.GetRecordView<Account>();\n\nvar options = new DataStreamerOptions\n{\n    PageSize = 10_000,\n    AutoFlushInterval = TimeSpan.FromSeconds(1),\n    RetryLimit = 32\n};\n\nawait view.StreamDataAsync(GetAccountsToAdd(5_000), options);\nawait view.StreamDataAsync(GetAccountsToRemove(1_000), options);\n\nasync IAsyncEnumerable<DataStreamerItem<Account>> GetAccountsToAdd(int count)\n{\n    for (int i = 0; i < count; i++)\n    {\n        yield return DataStreamerItem.Create(\n            new Account(i, $"Account {i}"));\n    }\n}\n\nasync IAsyncEnumerable<DataStreamerItem<Account>> GetAccountsToRemove(int count)\n{\n    for (int i = 0; i < count; i++)\n    {\n        yield return DataStreamerItem.Create(\n            new Account(i, string.Empty), DataStreamerOperationType.Remove);\n    }\n}\n\npublic record Account(int Id, string Name);\n'})})})]}),"\n",(0,r.jsx)(t.h3,{id:"streaming-with-receiver",children:"Streaming with Receiver"}),"\n",(0,r.jsx)(t.p,{children:"The Apache Ignite 3 streaming API supports advanced streaming scenarios by allowing you to create a custom receiver that defines server-side processing logic. Use a receiver when you need to process or transform data on the server, update multiple tables from a single data stream, or work with incoming data that does not match a table schema."}),"\n",(0,r.jsxs)(t.p,{children:["With a receiver, you can stream data in any format, as it is schema-agnostic.\nThe receiver also has access to the full Ignite 3 API through the ",(0,r.jsx)(t.a,{href:"https://ignite.apache.org/releases/3.0.0/javadoc/org/apache/ignite/table/DataStreamerReceiverContext.html",children:(0,r.jsx)(t.code,{children:"DataStreamerReceiverContext"})}),"."]}),"\n",(0,r.jsxs)(t.p,{children:["The data streamer controls data flow by requesting items only when partition buffers have space. ",(0,r.jsx)(t.code,{children:"DataStreamerOptions.perPartitionParallelOperations"})," controls how many buffers can be allocated per partition. When buffers are full, the streamer stops requesting more data until some items are processed.\nAdditionally, if a ",(0,r.jsx)(t.code,{children:"resultSubscriber"})," is specified, it also applies backpressure on the streamer. If the subscriber is slow at consuming results, the streamer reduces its request rate from the publisher accordingly."]}),"\n",(0,r.jsxs)(t.p,{children:["To use a receiver, you need to implement the ",(0,r.jsx)(t.a,{href:"https://ignite.apache.org/releases/3.0.0/javadoc/org/apache/ignite/table/DataStreamerReceiver.html",children:(0,r.jsx)(t.code,{children:"DataStreamerReceiver"})})," interface. The receiver's ",(0,r.jsx)(t.code,{children:"receive"})," method processes each batch of items streamed to the server, so you can apply custom logic and return results for each item as needed:"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:"@Nullable CompletableFuture<List<R>> receive(\nList<T> page,\nDataStreamerReceiverContext ctx,\n@Nullable A arg);\n\n"})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:"ValueTask<IList<TResult>?> ReceiveAsync(\nIList<TItem> page,\nTArg arg,\nIDataStreamerReceiverContext context,\nCancellationToken cancellationToken);\n"})})})]}),"\n",(0,r.jsxs)(t.ul,{children:["\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"page"}),": The current batch of data items to process."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"ctx"}),": The receiver context, which lets you interact with Ignite 3 API."]}),"\n",(0,r.jsxs)(t.li,{children:[(0,r.jsx)(t.code,{children:"arg"}),": An optional argument that can be used to pass custom parameters to your receiver logic."]}),"\n"]}),"\n",(0,r.jsx)(t.h3,{id:"examples",children:"Examples"}),"\n",(0,r.jsx)(t.h4,{id:"updating-multiple-tables",children:"Updating Multiple Tables"}),"\n",(0,r.jsx)(t.p,{children:"The following example demonstrates how to implement a receiver that processes data containing customer and address information, and updates two separate tables on the server:"}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsxs)(t.li,{children:["First, create the custom receiver that will extract data from the provided source and write it into two separate tables: ",(0,r.jsx)(t.code,{children:"customers"})," and ",(0,r.jsx)(t.code,{children:"addresses"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:'private static class TwoTableReceiver implements DataStreamerReceiver<Tuple, Void, Void> {\n@Override\npublic @Nullable CompletableFuture<List<Void>> receive(List<Tuple> page, DataStreamerReceiverContext ctx, @Nullable Void arg) {\n// List<Tuple> is the source data. Those tuples do not conform to any table and can have arbitrary data.\n\n            RecordView<Tuple> customersTable = ctx.ignite().tables().table("customers").recordView();\n            RecordView<Tuple> addressesTable = ctx.ignite().tables().table("addresses").recordView();\n\n            for (Tuple sourceItem : page) {\n                // For each source item, receiver extracts customer and address data and upserts it into respective tables.\n                Tuple customer = Tuple.create()\n                        .set("id", sourceItem.intValue("customerId"))\n                        .set("name", sourceItem.stringValue("customerName"))\n                        .set("addressId", sourceItem.intValue("addressId"));\n\n                Tuple address = Tuple.create()\n                        .set("id", sourceItem.intValue("addressId"))\n                        .set("street", sourceItem.stringValue("street"))\n                        .set("city", sourceItem.stringValue("city"));\n\n                customersTable.upsert(null, customer);\n                addressesTable.upsert(null, address);\n            }\n\n            return null;\n        }\n    }\n'})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:'class TwoTableReceiver : IDataStreamerReceiver<IIgniteTuple, object?, object>\n{\n    public async ValueTask<IList<object>?> ReceiveAsync(\n        IList<IIgniteTuple> page,\n        object? arg,\n        IDataStreamerReceiverContext context,\n        CancellationToken cancellationToken)\n    {\n        IRecordView<IIgniteTuple> customerTable = (await context.Ignite.Tables.GetTableAsync("customers"))!.RecordBinaryView;\n        IRecordView<IIgniteTuple> addressesTable = (await context.Ignite.Tables.GetTableAsync("addresses"))!.RecordBinaryView;\n\n        foreach (IIgniteTuple sourceItem in page)\n        {\n            // For each source item, the receiver extracts customer and address data and upserts it into respective tables.\n            var customer = new IgniteTuple\n            {\n                ["id"] = sourceItem["customerId"],\n                ["name"] = sourceItem["customerName"],\n                ["addressId"] = sourceItem["addressId"]\n            };\n\n            var address = new IgniteTuple\n            {\n                ["id"] = sourceItem["addressId"],\n                ["street"] = sourceItem["street"],\n                ["city"] = sourceItem["city"],\n            };\n\n            await customerTable.UpsertAsync(null, customer);\n            await addressesTable.UpsertAsync(null, address);\n        }\n\n        return null;\n    }\n}\n'})})})]}),"\n",(0,r.jsxs)(t.ol,{start:"2",children:["\n",(0,r.jsxs)(t.li,{children:["Create a descriptor that refers to your receiver implementation. This descriptor will be passed later to a ",(0,r.jsx)(t.code,{children:"SubmissionPublisher"})," when streaming data."]}),"\n"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:"DataStreamerReceiverDescriptor<Tuple, Void, Void> desc = DataStreamerReceiverDescriptor\n.builder(TwoTableReceiver.class)\n.build();\n"})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:"ReceiverDescriptor<IIgniteTuple, object?, object> desc = ReceiverDescriptor.Of(new TwoTableReceiver());\n"})})})]}),"\n",(0,r.jsxs)(t.ol,{start:"3",children:["\n",(0,r.jsxs)(t.li,{children:["Next, obtain the target table to partition the data for streaming. In this example we partition by ",(0,r.jsx)(t.code,{children:"customerId"})," to ensure the receiver is colocated with the customer data, enabling local upserts. Then define how to extract keys and payloads from the source, and stream the data using a ",(0,r.jsx)(t.code,{children:"SubmissionPublisher"}),"."]}),"\n"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:'// Example source data\nList<Tuple> sourceData = IntStream.range(1, 10)\n.mapToObj(i -> Tuple.create()\n.set("customerId", i)\n.set("customerName", "Customer " + i)\n.set("addressId", i)\n.set("street", "Street " + i)\n.set("city", "City " + i))\n.collect(Collectors.toList());\n\nCompletableFuture<Void> streamerFut;\n\nRecordView<Tuple> customersTable = client.tables().table("customers").recordView();\n\n// Extract the target table key from each source item; since the source has "customerId" but the target table uses "id", the function maps customerId to id accordingly.\nFunction<Tuple, Tuple> keyFunc = sourceItem -> Tuple.create().set("id", sourceItem.intValue("customerId"));\n\n// Extract the data payload sent to the receiver. In this case, we use the entire source item as the payload.\nFunction<Tuple, Tuple> payloadFunc = Function.identity();\n\n// Stream data using a publisher.\ntry (var publisher = new SubmissionPublisher<Tuple>()) {\n    streamerFut = customersTable.streamData(\n            publisher,\n            desc,\n            keyFunc,\n            payloadFunc,\n            null, // Optional receiver arguments\n            null, // Result subscriber\n            null // Options\n    );\n\n    for (Tuple item : sourceData) {\n        publisher.submit(item);\n    }\n}\n\nstreamerFut.join();\n'})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:'IAsyncEnumerable<IIgniteTuple> sourceData = GetSourceData();\n\nIRecordView<IIgniteTuple> customersTable = (await client.Tables.GetTableAsync("customers"))!.RecordBinaryView;\n\nIAsyncEnumerable<object> streamerResults = customersTable.StreamDataAsync(\nsourceData,\ndesc,\nx => new IgniteTuple { ["id"] = x["customerId"] },\nx => x,\nnull,\nDataStreamerOptions.Default,\nCancellationToken.None);\n\nawait foreach (object result in streamerResults)\n{\n// ...\n}\n\nstatic async IAsyncEnumerable<IIgniteTuple> GetSourceData()\n{\nawait Task.Yield(); // Simulate async enumeration.\n\n    for (int i = 0; i < 10; i++)\n    {\n        yield return new IgniteTuple\n        {\n            ["customerId"] = i,\n            ["customerName"] = $"Customer {i}",\n            ["addressId"] = i,\n            ["street"] = $"Street {i}",\n            ["city"] = $"City {i}"\n        };\n    }\n}\n'})})})]}),"\n",(0,r.jsx)(t.h4,{id:"distributed-computations",children:"Distributed Computations"}),"\n",(0,r.jsxs)(t.p,{children:["You can also use a streamer with a receiver to perform distributed computations, such as per-item calculations and ",(0,r.jsx)(t.a,{href:"/suggested-site/docs/ignite3/3.0.0/developers-guide/compute/#mapreduce-tasks",children:"map-reduce"})," tasks on the returned results."]}),"\n",(0,r.jsx)(t.p,{children:"This example demonstrates a simulated fraud detection process, which typically involves intensive processing of each transaction using ML models."}),"\n",(0,r.jsxs)(t.ol,{children:["\n",(0,r.jsx)(t.li,{children:"First, create a custom receiver that will handle fraud detection computations on the results:"}),"\n"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:'private static class FraudDetectorReceiver implements DataStreamerReceiver<Tuple, Void, Tuple> {\n@Override\npublic @Nullable CompletableFuture<List<Tuple>> receive(List<Tuple> page, DataStreamerReceiverContext ctx, @Nullable Void arg) {\nList<Tuple> results = new ArrayList<>(page.size());\n\n            for (Tuple tx : page) {\n                results.add(detectFraud(tx));\n            }\n\n            return CompletableFuture.completedFuture(results);\n        }\n\n        private static Tuple detectFraud(Tuple txInfo) {\n            // Simulate fraud detection processing.\n            double fraudRisk = Math.random();\n\n            // Add result to the tuple and return.\n            return txInfo.set("fraudRisk", fraudRisk);\n        }\n    }\n'})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:'class FraudDetectorReceiver : IDataStreamerReceiver<IIgniteTuple, object?, IIgniteTuple>\n{\n    public async ValueTask<IList<IIgniteTuple>?> ReceiveAsync(\n        IList<IIgniteTuple> page,\n        object? arg,\n        IDataStreamerReceiverContext context,\n        CancellationToken cancellationToken)\n    {\n        var result = new List<IIgniteTuple>(page.Count);\n\n        foreach (var tx in page)\n        {\n            IIgniteTuple resTuple = await DetectFraud(tx);\n            result.Add(resTuple);\n        }\n\n        return result;\n    }\n\n    private static async Task<IIgniteTuple> DetectFraud(IIgniteTuple transaction)\n    {\n        // Simulate fraud detection logic - add a random risk score to the tuple.\n        await Task.Delay(10);\n        transaction["fraudRisk"] = Random.Shared.NextDouble();\n        return transaction;\n    }\n}\n'})})})]}),"\n",(0,r.jsxs)(t.ol,{start:"2",children:["\n",(0,r.jsxs)(t.li,{children:["Next, stream a list of sample transactions across the cluster using a dummy table that partitions data by transaction ID and ",(0,r.jsx)(t.code,{children:"FraudDetectorReceiver"})," for fraud detection. Subscribe to the results to log each processed transaction, handle errors, and confirm when streaming completes:"]}),"\n"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:'public void runReceiverStreamProcessing() {\n\n    // Source data is a list of financial transactions.\n    // We distribute this processing across the cluster, then gather and return results.\n    List<Tuple> sourceData = IntStream.range(1, 10)\n                        .mapToObj(i -> Tuple.create()\n                        .set("txId", i)\n                        .set("txData", "{some-json-data}"))\n                        .collect(Collectors.toList());\n\n        DataStreamerReceiverDescriptor<Tuple, Void, Tuple> desc = DataStreamerReceiverDescriptor\n                .builder(FraudDetectorReceiver.class)\n                .build();\n\n        CompletableFuture<Void> streamerFut;\n\n        // Streaming requires a target table to partition data.\n        // Use a dummy table for this scenario, because we are not going to store any data.\n        TableDefinition txDummyTableDef = TableDefinition.builder("tx_dummy")\n                .columns(column("id", ColumnType.INTEGER))\n                .primaryKey("id")\n                .build();\n\n        Table dummyTable = client.catalog().createTable(txDummyTableDef);\n\n        // Source data has "txId" field, but target dummy table has "id" column, so keyFunc maps "txId" to "id".\n        Function<Tuple, Tuple> keyFunc = sourceItem -> Tuple.create().set("id", sourceItem.value("txId"));\n\n        // Payload function is used to extract the payload (data that goes to the receiver) from the source item.\n        // In our case, we want to use the whole source item as the payload.\n        Function<Tuple, Tuple> payloadFunc = Function.identity();\n\n        Flow.Subscriber<Tuple> resultSubscriber = new Flow.Subscriber<>() {\n            @Override\n            public void onSubscribe(Flow.Subscription subscription) {\n                subscription.request(Long.MAX_VALUE);\n            }\n\n            @Override\n            public void onNext(Tuple item) {\n                System.out.println("Transaction processed: " + item);\n            }\n\n            @Override\n            public void onError(Throwable throwable) {\n                System.err.println("Error during streaming: " + throwable.getMessage());\n            }\n\n            @Override\n            public void onComplete() {\n                System.out.println("Streaming completed.");\n            }\n        };\n\n        try (var publisher = new SubmissionPublisher<Tuple>()) {\n            streamerFut = dummyTable.recordView().streamData(\n                    publisher,\n                    desc,\n                    keyFunc,\n                    payloadFunc,\n                    null, // Arg\n                    resultSubscriber,\n                    null // Options\n            );\n\n            for (Tuple item : sourceData) {\n                publisher.submit(item);\n            }\n        }\n\n        streamerFut.join();\n    }\n'})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:'// Source data is a list of financial transactions.\n// We want to distribute this processing across the cluster, then gather and return results\nIAsyncEnumerable<IIgniteTuple> data = GetSourceData();\n\nReceiverDescriptor<IIgniteTuple, object?, IIgniteTuple> fraudDetectorReceiverDesc = ReceiverDescriptor.Of(new FraudDetectorReceiver());\n\n// Streaming requires a target table to partition data.\n// Use a dummy table for this scenario, because we are not going to store any data.\nawait client.Sql.ExecuteScriptAsync("CREATE TABLE IF NOT EXISTS TX_DUMMY (ID LONG)");\n\nITable dummyTable = await client.Tables.GetTableAsync("TX_DUMMY");\n\n// Source data has "txId" field, but target dummy table has "id" column, so keyFunc maps "txId" to "id".\nFunc<IIgniteTuple, IIgniteTuple> keyFunc = tuple => new IgniteTuple { ["id"] = tuple["txId"] };\n\n// Payload function is used to extract the payload (data that goes to the receiver) from the source item.\n// In our case, we want to use the whole source item as the payload.\nFunc<IIgniteTuple, IIgniteTuple> payloadFunc = tuple => tuple;\n\nIAsyncEnumerable<IIgniteTuple> results = dummyTable.RecordBinaryView.StreamDataAsync(\ndata,\nfraudDetectorReceiverDesc,\nkeyFunc,\npayloadFunc,\nreceiverArg: null);\n\nawait foreach (IIgniteTuple processedTx in results)\n{\nConsole.WriteLine("Transaction processed: " + processedTx);\n}\n\nasync IAsyncEnumerable<IIgniteTuple> GetSourceData()\n{\nawait Task.Yield(); // Simulate async data source.\n\n    for (int i = 0; i < 1000; i++)\n    {\n        yield return new IgniteTuple\n        {\n            ["txId"] = i,\n            ["txData"] = "{some-json-data}"\n        };\n    }\n}\n'})})})]}),"\n",(0,r.jsx)(t.h4,{id:"custom-marshallers-in-net",children:"Custom Marshallers in .NET"}),"\n",(0,r.jsxs)(t.p,{children:["In .NET, you can define custom marshallers by implementing the ",(0,r.jsx)(t.a,{href:"https://ignite.apache.org/releases/3.0.0/dotnetdoc/api/Apache.Ignite.Marshalling.IMarshaller-1.html",children:(0,r.jsx)(t.code,{children:"IMarshaller"})})," interface."]}),"\n",(0,r.jsxs)(t.p,{children:["For example, the code below demonstrates how to use ",(0,r.jsx)(t.code,{children:"JsonMarshaller"})," to serialize data, arguments, and results."]}),"\n",(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:'ITable? table = await client.Tables.GetTableAsync("my-table");\n\nReceiverDescriptor<MyData, MyArg, MyResult> receiverDesc = ReceiverDescriptor.Of(new MyReceiver());\n\nIAsyncEnumerable<MyData> data = Enumerable\n    .Range(1, 100)\n    .Select(x => new MyData(x, $"Name {x}"))\n    .ToAsyncEnumerable();\n\nIAsyncEnumerable<MyResult> results = table!.RecordBinaryView.StreamDataAsync(\n    data: data,\n    receiver: receiverDesc,\n    keySelector: dataItem => new IgniteTuple { ["id"] = dataItem.Id },\n    payloadSelector: dataItem => dataItem,\n    receiverArg: new MyArg("Some info"));\n\nawait foreach (MyResult result in results)\n{\n    Console.WriteLine(result);\n}\n\npublic record MyData(int Id, string Name);\n\npublic record MyArg(string Info);\n\npublic record MyResult(MyData Data, MyArg Arg);\n\npublic class MyReceiver : IDataStreamerReceiver<MyData, MyArg, MyResult>\n{\n    public IMarshaller<MyData> PayloadMarshaller =>\n        new JsonMarshaller<MyData>();\n\n    public IMarshaller<MyArg> ArgumentMarshaller =>\n        new JsonMarshaller<MyArg>();\n\n    public IMarshaller<MyResult> ResultMarshaller =>\n        new JsonMarshaller<MyResult>();\n\n    public ValueTask<IList<MyResult>?> ReceiveAsync(IList<MyData> page, MyArg arg, IDataStreamerReceiverContext context, CancellationToken cancellationToken)\n    {\n        IList<MyResult> results = page\n            .Select(data => new MyResult(data, arg))\n            .ToList();\n\n        return ValueTask.FromResult(results)!;\n    }\n}\n'})}),"\n",(0,r.jsx)(t.h2,{id:"tracking-failed-entries",children:"Tracking Failed Entries"}),"\n",(0,r.jsxs)(t.p,{children:["If the data streamer fails to process any entries, it collects the failed items in a ",(0,r.jsx)(t.code,{children:"DataStreamerException"}),". You can catch this exception and access the failed entries using the ",(0,r.jsx)(t.code,{children:"failedItems()"})," method, as shown in the example below."]}),"\n",(0,r.jsx)(t.p,{children:"You can catch both asynchronous errors during background streaming and immediate submission errors:"}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:'RecordView<Account> view = client.tables().table("accounts").recordView(Account.class);\n\nCompletableFuture<Void> streamerFut;\n\ntry (var publisher = new SubmissionPublisher<DataStreamerItem<Account>>()) {\nstreamerFut = view.streamData(publisher, options)\n.exceptionally(e -> {\nSystem.out.println("Failed items during background streaming: " +\n((DataStreamerException)e.getCause()).failedItems());\nreturn null;\n});\n\n    /** Trying to insert an account record. */\n    Account entry = new Account(1, "Account name", rnd.nextLong(100_000), rnd.nextBoolean());\n    publisher.submit(DataStreamerItem.of(entry));\n} catch (DataStreamerException e) {\n      /** Handle entries that failed during submission. */\n      System.out.println("Failed items during submission: " + e.failedItems());\n}\n\nstreamerFut.join();\n'})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:'ITable? table = await Client.Tables.GetTableAsync("my-table");\nIRecordView<IIgniteTuple> view = table!.RecordBinaryView;\nIList<IIgniteTuple> data = [new IgniteTuple { ["key"] = 1L, ["val"] = "v" }];\n\ntry\n{\nawait view.StreamDataAsync(data.ToAsyncEnumerable());\n}\ncatch (DataStreamerException e)\n{\nConsole.WriteLine("Failed items: " + string.Join(",", e.FailedItems));\n}\n'})})})]}),"\n",(0,r.jsx)(t.h3,{id:"tuning-memory-usage",children:"Tuning Memory Usage"}),"\n",(0,r.jsx)(t.p,{children:"The data streamer may require a significant amount of memory to handle the requests in an orderly manner. Depending on your environment, you may want to increase or reduce the amount of memory reserved by the data streamer."}),"\n",(0,r.jsxs)(t.p,{children:["For every node in the cluster, the streamer reserves an amount of memory equal to ",(0,r.jsx)(t.code,{children:"pageSize"})," (1000 entries by default) multiplied by ",(0,r.jsx)(t.code,{children:"perPartitionParallelOperations"})," (1 by default) setting. For example, a 10-partition table with default parameters and average entry size of 1KB will reserve 10MB for operations."]}),"\n",(0,r.jsxs)(t.p,{children:["You can change these options while creating a ",(0,r.jsx)(t.code,{children:"DataStreamerOptions"})," object:"]}),"\n",(0,r.jsxs)(i.A,{groupId:"programming-languages",children:[(0,r.jsx)(l.A,{value:"java",label:"Java",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-java",children:'RecordView<Tuple> view = client.tables().table("accounts").recordView();\nvar publisher = new SubmissionPublisher<Tuple>();\n\nvar options = DataStreamerOptions.builder()\n        .pageSize(10_000)\n        .perPartitionParallelOperations(10)\n        .build();\n\nstreamerFut = view.streamData(publisher, options);\n'})})}),(0,r.jsx)(l.A,{value:"dotnet",label:".NET",children:(0,r.jsx)(t.pre,{children:(0,r.jsx)(t.code,{className:"language-csharp",children:"// .NET streamer does not have a perPartitionParallelOperations option yet.\nvar options = new DataStreamerOptions\n{\nPageSize = 10_000\n};\n"})})})]}),"\n",(0,r.jsx)(t.p,{children:"Additionally, the data streamer periodically flushes incomplete buffers to ensure that messages are not delayed indefinitely. This is especially useful when a buffer fills slowly or never completely fills due to uneven data distribution."}),"\n",(0,r.jsxs)(t.p,{children:["This behavior is controlled by the ",(0,r.jsx)(t.code,{children:"autoFlushInterval"})," property, which is set to 5000 ms by default. You can also configure the ",(0,r.jsx)(t.code,{children:"retryLimit"})," parameter to define the maximum number of retry attempts for failed submissions, with a default value of 16."]})]})}function p(e={}){const{wrapper:t}={...(0,s.R)(),...e.components};return t?(0,r.jsx)(t,{...e,children:(0,r.jsx)(m,{...e})}):m(e)}}}]);