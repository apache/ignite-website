---
title: "Apache Ignite 2.5: Scaling to 1000s Nodes Clusters"
author: "Denis Magda"
date: 2018-05-31
tags:
    - apache
    - database
    - ignite
    - spark
    - sql
---

p
  | Apache Ignite was always appreciated by its users for two primary things it delivers - scalability and performance. Throughout the lifetime many distributed systems tend to do performance optimizations from a release to release while making scalability related improvements just a couple of times. It&apos;s not because the scalability is of no interest. Usually, scalability requirements are set and solved once by a distributed system and don&apos;t require significant additional interventions by engineers.
p
  | However, Apache Ignite grew to the point when the community decided to revisit its discovery subsystem that influences how well and far Ignite scales out. The goal was pretty clear - Ignite has to scale to 1000s of nodes as good as it scales to 100s now.
p
  | It took many months to get the task implemented. So, please join me in welcoming Apache Ignite 2.5 that now can be scaled easily to 1000s of nodes and goes with other exciting capabilities. Let&apos;s check out the most prominent ones.
  
h3
  
  | Massive Scalability
  

| There are two components of Ignite that were modified in Ignite 2.5 to improve its scalability capabilities. The first one is related to 1000s nodes clusters while the other is related to the way we train machine learning (ML) models in Ignite. Let&apos;s start with the first.
p
p
h4 Marrying Apache Ignite and ZooKeeper
p
p
  | Right, that 1000s nodes scalability goal was solved with the help of Apache ZooKeeper. Why did we turn to it?
p
  | Apache Ignite default TCP/IP Discovery organizes cluster nodes into a ring-topology form that has its advantages and disadvantages. For instance, on topologies with hundreds of cluster nodes, it can take many seconds why a system message traverse through all the nodes. As a result, necessary processing of events such as joining of new nodes or detecting of failed ones can take a while affecting overall cluster responsiveness and performance. That is a big deal if you&apos;d like to run 1000s nodes clusters.
p
  | The new ZooKeeper Discovery uses ZooKeeper as a single point of synchronization where Ignite nodes are exchanging discovery events through it. It solved the issue with long-to-be-processed discovery messages and, as a result, allowed Ignite scaling to large cluster topologies.
p
  a(href='https://apacheignite.readme.io/docs/zookeeper-discovery')
div(style='text-align:center;')
  a(href='https://apacheignite.readme.io/docs/zookeeper-discovery')
    img(src='https://blogs.apache.org/ignite/mediaresource/4b80632d-232d-4e4f-bd5e-9d91f0bc550f' width='450')
p
p
  | As a rule of thumb, keep using default 
  a(href='https://apacheignite.readme.io/docs/tcpip-discovery' target='_blank') TCP/IP Discovery
  |  if it&apos;s unlikely that your Ignite cluster scales beyond 300s nodes and switch to 
  a(href='https://apacheignite.readme.io/docs/zookeeper-discovery' target='_blank') ZooKeeper Discovery
  |  if that&apos;s the case.
p
h4 Machine Learning: Partition-Based Datasets
p
p
  | That&apos;s the second prominent feature of Ignite 2.5 that improves the way of how far you can scale your Ignite clusters to train ML models over terabytes or petabytes of data. The 
  a(href='https://apacheignite.readme.io/docs/ml-partition-based-dataset' target='_blank') partition-based datasets
  |  moved us closer to the implementation of Zero-ETL concept which implies that Ignite can be used as a single storage where ML models and algorithms are being improved iteratively and online without ETLing data back and forth between Ignite and another storage.
p
  | Read more about the datasets from 
  a(href='https://apacheignite.readme.io/docs/ml-partition-based-dataset' target='_blank') this
  |  documentation page.
p
h3 Genetic Algorithms

| Ignite&apos;s ML component is ramping up and in the version 2.5 it accepted a contribution of genetic algorithms (GAs) which help to solve optimization problems by simulating the process of biological evolution. GAs are excellent for searching through large and complex data sets for an optimal solution. Real world applications of GAs include automotive design, computer gaming, robotics, investments, traffic/shipment routing and more.
p
p
  | Refer to excessive articles of my community-mates Turik Campbell and Akmal B. Chaudhri which cover main benefits of GAs:
  
ul
  
  li
    
    a(href='https://www.linkedin.com/pulse/travel-like-macgyver-solve-knapsack-problem-ga-grid-turik-campbell/' target='_blank') Travel Like MacGyver: Solve Knapsack Problem with GA Grid
    
  
  li
    
    a(href='https://www.gridgain.com/resources/blog/genetic-algorithms-apacher-ignitetm' target='_blank') Genetic Algorithms with Apache&reg; Ignite
    
  
p
p
h3 Continuous Self-Healing and Consistency Checks

| It&apos;s a known fact that many companies and businesses trusted Ignite its mission-critical deployments and solutions. As a result, sometimes Ignite doesn&apos;t even have a right to &quot;misfire&quot; and should be able to handle critical or unpredictable situations automatically or provide facilities to do deal with them manually. 
p
p
  | With Ignite 2.5, we&apos;ve kicked off the realization of continuous self-healing concept that implies that no matter what happens with Ignite in production it should be able to tolerate unexpected failures and stay up and running. The following was done in 2.5:
  
ul
  
  li
    
    a(href='https://apacheignite.readme.io/docs/critical-failures-handling' target='_blank') Critical Failures Handling
    
  
  li
    
    a(href='https://apacheignite.readme.io/docs/transactions#section-long-running-transactions-termination' target='_blank') Long running transactions monitoring and termination
    
  
  li
    
    a(href='https://apacheignite.readme.io/docs/consistency-check-facilities' target='_blank') Data Consistency Check Facilities
    
  
p
p
h3 SQL: Security and Fast Data Loading
p
p
  | The community stays strong and determined in its goal of making Ignite SQL engine undistinguishable from SQL engines of famous and mature SQL database. What&apos;s the purpose? We want to make it easy for you to migrate from a relational database to Ignite, so that you can reuse all your skills gained before. Overall, this is what our SQL engine got in 2.5:
p
ul
  
  li
    
    | Fast data loading with 
    a(href='https://apacheignite-sql.readme.io/docs/copy' target='_blank') COPY
    |  command and 
    a(href='https://apacheignite-sql.readme.io/docs/jdbc-driver#section-streaming' target='_blank') streaming mode
    |  using SQL APIs.
    
  
  li
    
    a(href='https://apacheignite.readme.io/docs/transactions#section-long-running-transactions-termination' target='_blank') Long running transactions monitoring and termination
    
  
  li
    
    | Secured Ignite cluster. Use 
    a(href='https://apacheignite-sql.readme.io/docs/ddl' target='_blank') CREATE USER, DROP USER and ALTER USER
    |  commands to manage who is allowed to connect to your clusters.
    
  
p
p
h3 In-place Execution of Spark DataFrame Queries
p
p
  | Apache Spark users can applaud because the 
  a(href='https://issues.apache.org/jira/owse/IGNITE-7077' target='_blank') following ticket
  |  got merged in 2.5. In short, it means that from now on Ignite will be able to execute as many DataFrames SQL queries as it can in-place on Ignite servers side avoiding data movement from Ignite to Spark. The performance of your DataFrames queries should boost significantly. Enjoy!
p
h3 DEB and RPM packages
p
p
  | Last but not least, if you&apos;re a Linux user, now you can install the latest Ignite versions directly from DEB and RPM repositories. Refer to 
  a(href='https://apacheignite.readme.io/docs/getting-started#section-rpm-deb-packages-installation' target='_blank') how-to
  |  and share your feedback with us.
p
  | Finally, I have no more paper left to cover other optimizations and improvements. So, go ahead and check out our 
  a(href='https://ignite.apache.org/releases/2.5.0/release_notes.html' target='_blank') release notes
  | .
