"use strict";(globalThis.webpackChunkdocs=globalThis.webpackChunkdocs||[]).push([[167],{28453:(e,r,n)=>{n.d(r,{R:()=>s,x:()=>l});var t=n(96540);const a={},i=t.createContext(a);function s(e){const r=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function l(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(a):e.components||a:s(e.components),t.createElement(i.Provider,{value:r},e.children)}},86516:(e,r,n)=>{n.r(r),n.d(r,{assets:()=>c,contentTitle:()=>l,default:()=>h,frontMatter:()=>s,metadata:()=>t,toc:()=>o});const t=JSON.parse('{"id":"api-reference/native-clients/dotnet/data-streamer-api","title":"Data Streamer API","description":"The Data Streamer API provides high-throughput bulk data loading into Ignite tables. It automatically batches data into pages, distributes them across cluster nodes, and optionally processes them server-side through custom receivers.","source":"@site/docs/api-reference/native-clients/dotnet/data-streamer-api.md","sourceDirName":"api-reference/native-clients/dotnet","slug":"/api-reference/native-clients/dotnet/data-streamer-api","permalink":"/docs/ignite3/3.1.0/api-reference/native-clients/dotnet/data-streamer-api","draft":false,"unlisted":false,"tags":[],"version":"current","sidebarPosition":3,"frontMatter":{"title":"Data Streamer API","id":"data-streamer-api","sidebar_position":3},"sidebar":"tutorialSidebar","previous":{"title":"LINQ API","permalink":"/docs/ignite3/3.1.0/api-reference/native-clients/dotnet/linq-api"},"next":{"title":"SQL API","permalink":"/docs/ignite3/3.1.0/api-reference/native-clients/dotnet/sql-api"}}');var a=n(74848),i=n(28453);const s={title:"Data Streamer API",id:"data-streamer-api",sidebar_position:3},l="Data Streamer API",c={},o=[{value:"Key Concepts",id:"key-concepts",level:2},{value:"Streaming Targets",id:"streaming-targets",level:3},{value:"Server-Side Receivers",id:"server-side-receivers",level:3},{value:"Page-Based Processing",id:"page-based-processing",level:3},{value:"Usage Examples",id:"usage-examples",level:2},{value:"Basic Streaming",id:"basic-streaming",level:3},{value:"Streaming with Options",id:"streaming-with-options",level:3},{value:"Streaming to Key-Value View",id:"streaming-to-key-value-view",level:3},{value:"Custom Server-Side Receiver",id:"custom-server-side-receiver",level:3},{value:"Error Handling",id:"error-handling",level:3},{value:"Streaming with Cancellation",id:"streaming-with-cancellation",level:3},{value:"Streaming with Transformations",id:"streaming-with-transformations",level:3},{value:"Reference",id:"reference",level:2},{value:"IDataStreamerTarget&lt;T&gt; Interface",id:"idatastreamertargett-interface",level:3},{value:"DataStreamerOptions Class",id:"datastreameroptions-class",level:3},{value:"IDataStreamerReceiver&lt;TItem, TArg, TResult&gt; Interface",id:"idatastreamerreceivertitem-targ-tresult-interface",level:3},{value:"IDataStreamerReceiverContext Interface",id:"idatastreamerreceivercontext-interface",level:3},{value:"ReceiverDescriptor Class",id:"receiverdescriptor-class",level:3},{value:"DataStreamerItem&lt;T&gt; Type",id:"datastreameritemt-type",level:3}];function d(e){const r={code:"code",h1:"h1",h2:"h2",h3:"h3",header:"header",li:"li",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,i.R)(),...e.components};return(0,a.jsxs)(a.Fragment,{children:[(0,a.jsx)(r.header,{children:(0,a.jsx)(r.h1,{id:"data-streamer-api",children:"Data Streamer API"})}),"\n",(0,a.jsx)(r.p,{children:"The Data Streamer API provides high-throughput bulk data loading into Ignite tables. It automatically batches data into pages, distributes them across cluster nodes, and optionally processes them server-side through custom receivers."}),"\n",(0,a.jsx)(r.h2,{id:"key-concepts",children:"Key Concepts"}),"\n",(0,a.jsx)(r.p,{children:"Data streaming optimizes bulk loading by grouping records into pages and sending them to the cluster in batches. This reduces network round-trips and enables parallel processing across partitions."}),"\n",(0,a.jsx)(r.h3,{id:"streaming-targets",children:"Streaming Targets"}),"\n",(0,a.jsx)(r.p,{children:"Both IRecordView and IKeyValueView implement IDataStreamerTarget, allowing you to stream data directly to any table view. The streamer automatically routes data to the correct partition nodes."}),"\n",(0,a.jsx)(r.h3,{id:"server-side-receivers",children:"Server-Side Receivers"}),"\n",(0,a.jsx)(r.p,{children:"Receivers execute custom logic on the server for each page of streamed data. Use receivers to transform data, perform aggregations, or implement custom merge logic during loading. Receivers run colocated with the data for maximum performance."}),"\n",(0,a.jsx)(r.h3,{id:"page-based-processing",children:"Page-Based Processing"}),"\n",(0,a.jsx)(r.p,{children:"The streamer divides input data into pages based on DataStreamerOptions.PageSize. Each page is sent to the appropriate cluster node where a receiver processes all items in the page together. This batching reduces overhead and enables efficient bulk operations."}),"\n",(0,a.jsx)(r.h2,{id:"usage-examples",children:"Usage Examples"}),"\n",(0,a.jsx)(r.h3,{id:"basic-streaming",children:"Basic Streaming"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-csharp",children:'var table = await client.Tables.GetTableAsync("events");\nvar view = table.GetRecordView<Event>();\n\n// Generate data asynchronously\nasync IAsyncEnumerable<Event> GenerateEvents()\n{\n    for (int i = 0; i < 100000; i++)\n    {\n        yield return new Event\n        {\n            Id = i,\n            Timestamp = DateTime.UtcNow,\n            Type = "sensor_reading",\n            Value = Random.Shared.NextDouble() * 100\n        };\n    }\n}\n\n// Stream the data\nawait view.StreamDataAsync(GenerateEvents());\n'})}),"\n",(0,a.jsx)(r.h3,{id:"streaming-with-options",children:"Streaming with Options"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-csharp",children:"var options = new DataStreamerOptions\n{\n    PageSize = 1000,  // Items per page\n    RetryLimit = 16,  // Retry failed pages\n    AutoFlushInterval = TimeSpan.FromSeconds(1)\n};\n\nawait view.StreamDataAsync(GenerateEvents(), options);\n"})}),"\n",(0,a.jsx)(r.h3,{id:"streaming-to-key-value-view",children:"Streaming to Key-Value View"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-csharp",children:'var table = await client.Tables.GetTableAsync("metrics");\nvar kvView = table.GetKeyValueView<MetricKey, MetricValue>();\n\nasync IAsyncEnumerable<KeyValuePair<MetricKey, MetricValue>> GenerateMetrics()\n{\n    for (int i = 0; i < 50000; i++)\n    {\n        var key = new MetricKey { MetricId = i };\n        var value = new MetricValue\n        {\n            Name = $"metric_{i}",\n            Value = Random.Shared.NextDouble()\n        };\n        yield return new KeyValuePair<MetricKey, MetricValue>(key, value);\n    }\n}\n\nawait kvView.StreamDataAsync(GenerateMetrics());\n'})}),"\n",(0,a.jsx)(r.h3,{id:"custom-server-side-receiver",children:"Custom Server-Side Receiver"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-csharp",children:'// Define receiver that processes data on the server\npublic class AggregatingReceiver : IDataStreamerReceiver<SensorReading, string, int>\n{\n    public IMarshaller<SensorReading>? PayloadMarshaller => null;\n    public IMarshaller<string>? ArgumentMarshaller => null;\n    public IMarshaller<int>? ResultMarshaller => null;\n\n    public async ValueTask<IList<int>?> ReceiveAsync(\n        IList<SensorReading> page,\n        string arg,\n        IDataStreamerReceiverContext context,\n        CancellationToken cancellationToken)\n    {\n        // Process page on the server\n        var sum = 0;\n        var table = await context.Ignite.Tables.GetTableAsync("sensor_data");\n        var view = table.GetRecordView<SensorReading>();\n\n        foreach (var reading in page)\n        {\n            // Custom merge logic\n            var existing = await view.GetAsync(null, new SensorReading { SensorId = reading.SensorId });\n            if (existing.HasValue)\n            {\n                reading.Value += existing.Value.Value;\n            }\n            await view.UpsertAsync(null, reading);\n            sum += (int)reading.Value;\n        }\n\n        return new[] { sum };\n    }\n}\n\n// Register and use receiver\nvar receiverDescriptor = new ReceiverDescriptor<SensorReading, string, int>(\n    "AggregatingReceiver");\n\nvar results = view.StreamDataAsync(\n    data: GenerateReadings(),\n    receiver: receiverDescriptor,\n    keySelector: r => new SensorReading { SensorId = r.SensorId },\n    payloadSelector: r => r,\n    receiverArg: "aggregate_mode",\n    options: new DataStreamerOptions { PageSize = 100 });\n\nawait foreach (var sum in results)\n{\n    Console.WriteLine($"Page sum: {sum}");\n}\n'})}),"\n",(0,a.jsx)(r.h3,{id:"error-handling",children:"Error Handling"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-csharp",children:'var options = new DataStreamerOptions\n{\n    PageSize = 500,\n    RetryLimit = 16\n};\n\ntry\n{\n    await view.StreamDataAsync(GenerateEvents(), options);\n    Console.WriteLine("Streaming completed successfully");\n}\ncatch (Exception ex)\n{\n    Console.WriteLine($"Streaming failed: {ex.Message}");\n    // Handle failure (page that failed after retries)\n}\n'})}),"\n",(0,a.jsx)(r.h3,{id:"streaming-with-cancellation",children:"Streaming with Cancellation"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-csharp",children:'using var cts = new CancellationTokenSource();\ncts.CancelAfter(TimeSpan.FromMinutes(5));\n\ntry\n{\n    await view.StreamDataAsync(\n        GenerateEvents(),\n        options: new DataStreamerOptions { PageSize = 1000 },\n        cancellationToken: cts.Token);\n}\ncatch (OperationCanceledException)\n{\n    Console.WriteLine("Streaming cancelled");\n}\n'})}),"\n",(0,a.jsx)(r.h3,{id:"streaming-with-transformations",children:"Streaming with Transformations"}),"\n",(0,a.jsx)(r.pre,{children:(0,a.jsx)(r.code,{className:"language-csharp",children:"async IAsyncEnumerable<Event> GenerateAndTransform()\n{\n    await foreach (var rawEvent in LoadFromExternalSource())\n    {\n        // Transform during generation\n        yield return new Event\n        {\n            Id = rawEvent.Id,\n            Timestamp = DateTime.UtcNow,\n            Type = NormalizeType(rawEvent.Type),\n            Value = rawEvent.Value * 1.5\n        };\n    }\n}\n\nawait view.StreamDataAsync(GenerateAndTransform());\n"})}),"\n",(0,a.jsx)(r.h2,{id:"reference",children:"Reference"}),"\n",(0,a.jsx)(r.h3,{id:"idatastreamertargett-interface",children:"IDataStreamerTarget<T> Interface"}),"\n",(0,a.jsx)(r.p,{children:"Basic streaming methods:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"StreamDataAsync(IAsyncEnumerable<T> data, DataStreamerOptions?, CancellationToken)"})," - Stream raw data items"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"StreamDataAsync(IAsyncEnumerable<DataStreamerItem<T>> data, DataStreamerOptions?, CancellationToken)"})," - Stream with operation types"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"Receiver-based streaming:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"StreamDataAsync<TSource, TPayload, TArg, TResult>"})," - Stream with receiver that returns results per page"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"StreamDataAsync<TSource, TPayload, TArg>"})," - Stream with receiver (void results)"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"Parameters:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"data"})," - Async sequence of items to stream"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"receiver"})," - Server-side receiver descriptor"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"keySelector"})," - Function to extract key from source items"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"payloadSelector"})," - Function to extract payload from source items"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"receiverArg"})," - Argument passed to receiver"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"options"})," - Streaming configuration"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"cancellationToken"})," - Cancellation support"]}),"\n"]}),"\n",(0,a.jsx)(r.h3,{id:"datastreameroptions-class",children:"DataStreamerOptions Class"}),"\n",(0,a.jsx)(r.p,{children:"Configuration properties:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"PageSize"})," - Number of items per page (default: 1000)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"RetryLimit"})," - Maximum retry attempts for failed pages (default: 16)"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"AutoFlushInterval"})," - Time interval for automatic page flushing"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"The page size controls the granularity of batching. Larger pages reduce network overhead but increase memory usage and reduce parallelism across partitions."}),"\n",(0,a.jsx)(r.h3,{id:"idatastreamerreceivertitem-targ-tresult-interface",children:"IDataStreamerReceiver<TItem, TArg, TResult> Interface"}),"\n",(0,a.jsx)(r.p,{children:"Properties:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"PayloadMarshaller"})," - Optional custom marshaller for payload items"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"ArgumentMarshaller"})," - Optional custom marshaller for arguments"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"ResultMarshaller"})," - Optional custom marshaller for results"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"Methods:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"ReceiveAsync(IList<TItem> page, TArg arg, IDataStreamerReceiverContext context, CancellationToken)"})," - Process a page of items on the server"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"The receiver executes on the server node that owns the partition. It receives a page of items (controlled by PageSize), processes them with access to the full Ignite API through the context, and optionally returns results."}),"\n",(0,a.jsx)(r.h3,{id:"idatastreamerreceivercontext-interface",children:"IDataStreamerReceiverContext Interface"}),"\n",(0,a.jsx)(r.p,{children:"Properties:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"Ignite"})," - Access to full Ignite client API for server-side operations"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"Use the context to access tables, execute SQL, or perform other operations during data processing. The context operates within the server environment."}),"\n",(0,a.jsx)(r.h3,{id:"receiverdescriptor-class",children:"ReceiverDescriptor Class"}),"\n",(0,a.jsx)(r.p,{children:"Describes a server-side receiver:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"ReceiverDescriptor<TPayload, TArg, TResult>(string className)"})," - Create descriptor with class name"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"ReceiverDescriptor<TArg>(string className)"})," - Create descriptor for receivers with no result"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"The receiver must be deployed to the server before streaming. The class name identifies the receiver implementation on the server."}),"\n",(0,a.jsx)(r.h3,{id:"datastreameritemt-type",children:"DataStreamerItem<T> Type"}),"\n",(0,a.jsx)(r.p,{children:"Wraps streamed items with operation type:"}),"\n",(0,a.jsxs)(r.ul,{children:["\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"Data"})," - The data item"]}),"\n",(0,a.jsxs)(r.li,{children:[(0,a.jsx)(r.strong,{children:"OperationType"})," - Operation to perform (Put, Remove)"]}),"\n"]}),"\n",(0,a.jsx)(r.p,{children:"Use this when you need to stream mixed operations (inserts, updates, deletes) in a single stream."})]})}function h(e={}){const{wrapper:r}={...(0,i.R)(),...e.components};return r?(0,a.jsx)(r,{...e,children:(0,a.jsx)(d,{...e})}):d(e)}}}]);